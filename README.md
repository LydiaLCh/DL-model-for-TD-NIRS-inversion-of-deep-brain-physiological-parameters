```bash
```
### ğŸ“‚ Repository Structure
```
.
â”œâ”€â”€ __pycache__/
â”œâ”€â”€ .venv/
â”‚
â”œâ”€â”€ Best_paths/
â”œâ”€â”€ CNN_initial_saved_pytorch_model_weights/
â”‚
â”œâ”€â”€ Figs/
â”œâ”€â”€ JSON_logs/
â”œâ”€â”€ Model_evaluation_figs/
â”‚
â”œâ”€â”€ Pre-obtained_data/
â”‚   â”œâ”€â”€ dataset_homo_small.mat
â”‚   â”œâ”€â”€ DTOFs_Homo_raw.csv
â”‚   â””â”€â”€ DTOFs_Homo_labels.csv
â”‚
â”œâ”€â”€ DL_CNN_initial.ipynb
â”œâ”€â”€ DL_Full_Pipeline.ipynb
â”œâ”€â”€ DL_PostProcessing.ipynb
â”‚
â”œâ”€â”€ DTOF_plot.py
â”œâ”€â”€ DTOF_std_plot.py
â”‚
â”œâ”€â”€ DTOFs_whiteMC(in).csv
â”‚
â”œâ”€â”€ training_core.py
â””â”€â”€ README.md
```

ğŸ§­ Directory and File Descriptions
ğŸ“ Pre-obtained data/

Contains all input datasets used by the deep-learning pipeline.

dataset_homo_small.mat
Primary dataset used in the current pipeline.
MATLAB v7.3 (HDF5) file containing:

```
X  # DTOFs (N, T)
y  # optical property labels [Î¼a, Î¼sâ€²]
t  # time vector
```

DTOFs (X)

optical property labels (y = [Î¼a, Î¼sâ€²])

time vector (t)

DTOFs_Homo_raw.csv, DTOFs_Homo_labels.csv
Legacy CSV-based DTOF and label files retained for reference and comparison.

ğŸ““ Jupyter Notebooks

DL_CNN_initial.ipynb
Baseline implementation of the CNN inversion framework.
Includes dataset loading, preprocessing, model definition, training, and validation.

DL_Full_Pipeline.ipynb
Extended pipeline including experiment logging, checkpointing, and full evaluation.

DL_PostProcessing.ipynb
Analysis and visualisation of trained model outputs, including error metrics and plots.

ğŸ§  Model & Training Code

training_core.py
Core reusable Python module containing:

DTOFDataset definition

CNN architecture (Net)

training and validation loops

evaluation utilities

CNN_initial_saved_pytorch_model_weights/
Saved PyTorch checkpoints (.pt) storing trained model weights.

ğŸ“Š Visualisation & Evaluation

Figs/
Training and validation loss curves.

Model evaluation figs/
Prediction vs ground-truth plots, RMSE/MAE summaries, and diagnostic figures.

DTOF_plot.py, DTOF_std_plot.py
Utility scripts for inspecting DTOFs and preprocessing effects.

ğŸ—‚ï¸ Logging & Reproducibility

JSON logs/
Structured experiment logs capturing:

preprocessing configurations

training hyperparameters

evaluation metrics

Best paths/
Stores selected best-performing configurations or optimisation results.

âš™ï¸ Environment & Metadata

.venv/
Local Python virtual environment used for dependency isolation.

__pycache__/
Auto-generated Python bytecode (safe to ignore).


ğŸ“˜ DTOF Deep Learning Pipeline for Optical Property Inversion

This repository implements a complete, reproducible deep-learning framework for estimating absorption (Î¼a) and reduced scattering (Î¼sâ€²) from Monte Carloâ€“simulated DTOFs.

ğŸ” Project Overview

Time-Domain Near-Infrared Spectroscopy (TD-NIRS) captures Distribution of Time-of-Flight (DTOF) curves that encode tissue optical properties.
This project builds a CNN-based inversion model trained on MCX-simulated DTOFs to recover underlying optical properties.

The pipeline includes:

Full data preprocessing and normalisation

Multi-channel DTOF construction (raw, temporal masks, hybrid)

A flexible CNN architecture with auto-detected flattening dimension

A complete training loop with validation, checkpointing, and GPU support

An evaluation module providing MAE / RMSE metrics

A structured instruction manual describing reproducible usage

ğŸ§± Core System Components
1. DTOFDataset

Handles the full preprocessing workflow:

Load DTOFs from CSV

Extract (Î¼a, Î¼sâ€²) labels from column headers

Apply Savitzkyâ€“Golay filtering

Clip negative floating-point noise

Standardise each DTOF to zero mean and unit variance

Construct 1, 3, or 4 input channels via:

Raw DTOF

Early/Mid/Late temporal masks

Combined hybrid features

Output per sample:

signal â†’ (C, T)   # channels Ã— time samples  
target â†’ (Î¼a, Î¼sâ€²)

2. CNN Architecture

A domain-inspired 1D convolutional network consisting of:

Three Conv1d â†’ BatchNorm â†’ ReLU â†’ MaxPool blocks

Automatic flatten-size detection via dummy forward pass

Fully connected regressor head producing:

[Î¼a, Î¼sâ€²]

The architecture supports variable input channels (1, 3, or 4).

3. Training Infrastructure

Features:

PyTorch training loop

Train/validation dataloaders

MSE loss over (Î¼a, Î¼sâ€²)

Adam optimiser

GPU/CPU device selection

Best-model checkpointing (best_dtof_cnn.pth)

Loss curve logging and plotting

Output of epoch-wise training + validation losses

4. Evaluation Module

The ModelEvaluator collects:

Prediction vectors across validation set

Ground-truth labels

MAE for Î¼a and Î¼sâ€²

RMSE for Î¼a and Î¼sâ€²

Optional sample-prediction previews

MAPE is computed internally but not used due to instability near small Î¼a values.


ğŸ““ DL_CNN_initial.ipynb â€” Deep Learning Inversion Pipeline

This notebook implements the end-to-end deep learning pipeline for inverting Monte Carloâ€“simulated DTOFs into tissue optical properties: absorption (Î¼a) and reduced scattering (Î¼sâ€²).

It provides a fully reproducible workflow covering data loading, preprocessing, model training, validation, and evaluation, and serves as the reference implementation for the CNN-based inversion framework used throughout this project.

ğŸ” Overview

Time-Domain Near-Infrared Spectroscopy (TD-NIRS) produces Distribution of Time-of-Flight (DTOF) curves that encode information about tissue optical properties across photon pathlengths.

In this notebook, a 1D convolutional neural network (CNN) is trained on MCX-simulated DTOFs to recover the underlying optical parameters.
The design explicitly incorporates temporal sensitivity (early / mid / late photons) and dynamic-range stabilisation via logarithmic transforms.

ğŸ§± Core Components
1. DTOFDataset

The DTOFDataset class encapsulates the full preprocessing pipeline and ensures consistent, reproducible data handling.

Data source

MATLAB v7.3 (.mat) files loaded via h5py

Required variables:

X: DTOFs (N, T)

y: labels (Î¼a, Î¼sâ€²)

t: time vector (seconds, converted internally to ns)

Preprocessing steps

Convert time axis from seconds â†’ nanoseconds

Crop DTOFs to a fixed temporal window

Apply Savitzkyâ€“Golay smoothing

Clip numerical noise and negative values

Construct multiple input representations:

raw reflectance

log-transformed reflectance

optional raw + log concatenation

Channel construction modes

single: full DTOF

early_mid_late: three temporally gated channels

hybrid_4ch: full DTOF + early / mid / late masks

Output per sample

signal â†’ (C, T)   # channels Ã— time samples
label  â†’ (Î¼a, Î¼sâ€²)

2. CNN Architecture

The inversion model is a domain-inspired 1D CNN designed for long temporal signals.

Architecture

Three convolutional blocks:

Conv1d â†’ BatchNorm â†’ ReLU â†’ MaxPool

Automatic flatten-dimension detection via a dummy forward pass

Fully connected regression head producing:

[log(Î¼a), log(Î¼sâ€²)]


Key properties

Supports variable input channel counts (1, 3, 4, or 8)

No activation on final layer (required for log-space regression)

Input length inferred dynamically from dataset configuration

3. Training Infrastructure

The notebook implements a complete and robust training loop using PyTorch.

Features

Train / validation split using dataset indices (no data leakage)

Mini-batch training via DataLoader

Mean-Squared Error loss in log-parameter space

Adam optimiser

Automatic CPU / GPU device selection

Best-model checkpointing (.pt state dictionary)

Epoch-wise logging of:

training loss

validation loss

RMSE in original physical units

Training is performed on:

targets = log([Î¼a, Î¼sâ€²])


to stabilise optimisation across disparate parameter scales.

4. Evaluation and Metrics

Model performance is assessed using a dedicated evaluation routine.

Metrics reported

MAE for Î¼a and Î¼sâ€² (original units)

RMSE for Î¼a and Î¼sâ€² (original units)

Predictions are exponentiated back from log-space prior to evaluation:

Î¼Ì‚ = exp(model output)


MAPE is intentionally excluded due to instability for small Î¼a values.
