{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4502f69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDTOF Deep Learning Pipeline\\n\\nThis module implements a complete, modular DL pipeline for predicting\\nthe optical properties (μa, μs\\') of homogeneous tissue models from time resolved \\nDTOF signals. The system is designed for reproducible experimentation and supports highly flexible preprocessing and neural architecture configurations \\n\\nApplicability \\n\\nThis framework is intended for studies involving: \\n    * Monte Carlo simulated DTOFs (homogeneous or multilayer)\\n    * inversion of DTOFs to estimate μa, μs\\'\\n    * benchmarking the effects of preprocessing choices such as SG filters \\n    * deep learning architecture optimisation \\n    * systematic comparison of multi-channel DTOF representaitons \\n\\nSupported Model Variants \\n\\nThis pipeline allows dynamic selection of the number of input channels. 3 commonly used configurations are supported: \\n\\n    (1) Single channel DTOF:\\n        * DTOF cropped to 0-5 ns \\n        * Standardised after smoothing \\n        * Input shape: (1, T)\\n\\n    (2) 3 channel temporal bin model: \\n        * Early, mid, and late temporal masks (0 - 0.5 ns, 0.5 - 4 ns, 4 -5 ns)\\n        * Each bin multiplied with the DTOF to form 3 channels \\n        * Input shape: (3, T)\\n\\n    (3) 4 channel hybrid model:\\n        * Channel 1: Full DTOF (0 - 0.5 ns)\\n        * Channel 2-4: Early, mid, late temporal bins\\n        * Input shape: (4, T)\\n\\nChannel configuration is selected from the CONFIG block and handled automatically by the DTOFDataset \\n\\nPipeline Components \\n\\nThis module consists of: \\n\\n1. CONFIG dictionary: \\n    Centralises all experiment-level parameters including: \\n        - preprocessing settings (SG frame / order, clipping, cropping)\\n        - number of input channels \\n        - temporal mask definitions \\n        - CNN architecture (layer widths, output dimensions)\\n        - learning rate, batch size, epochs \\n\\n2. DTOFDataset: \\n    Implements the preprocessing chain: \\n        - CSV loading \\n        - Savitzky-Golay smoothing \\n        - negative-value clipping \\n        - mean / std standardisation \\n        - crop to 0 - 5 ns\\n        - dynamic construction of 1, 3, or 4 input channels \\n        - returns (signal, [mua, mus])\\n\\n3. Net (CNN architecture): \\n    * Input channels match CONFIG[\"in_channels\"]\\n    * 3 Conv blocks with BatchNorm, ReLU, and pooling \\n    * Automatic flatten dimension calculatino \\n    * Fully connected regression head configurable via CONFIG \\n    * Output dimension fixed at 2 (μa, μs′)\\n\\n4. Training loop: \\n    * GPU/CPU detection \\n    * Train/validation loss computation \\n    * best-model checkpoint saving \\n    * optional printing of sample predictions \\n    * automatic plotting of train/val loss curves (PNG)\\n\\n5. Evaluation and logging: \\n    Provides: \\n        - MAE and RMSE for μa, μs′\\n        - prediction vs.ground truth arrays \\n        - JSON logging of each run\\'s configuration and metrics \\n        - loss curve visualisation per run \\nDependencies \\n\\nRequired: \\n    * torch \\n    * numpy\\n    * pandas \\n    * scipy (Savitzky-Golay filtering)\\n    * matplotlib (loss curve plotting)\\n\\nRecommended: \\n    * seaborn (optional visualisation enhancements)\\n\\nInputs & Outputs \\n\\nInputs: \\n    * DTOFs_Homo_raw.csv - raw DTOF data with time in column 0\\n    * DTOFs_Homo_labels.csv - extracted (μa, μs\\') labels \\n\\nOutputs: \\n    * training and validation loss curves .png\\n    * MAE / RMSE metrics \\n    * prediction arrays for downstream plotting \\n    * JSON log for all runs\\n\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DTOF Deep Learning Pipeline\n",
    "\n",
    "This module implements a complete, modular DL pipeline for predicting\n",
    "the optical properties (μa, μs') of homogeneous tissue models from time resolved \n",
    "DTOF signals. The system is designed for reproducible experimentation and supports highly flexible preprocessing and neural architecture configurations \n",
    "\n",
    "Applicability \n",
    "\n",
    "This framework is intended for studies involving: \n",
    "    * Monte Carlo simulated DTOFs (homogeneous or multilayer)\n",
    "    * inversion of DTOFs to estimate μa, μs'\n",
    "    * benchmarking the effects of preprocessing choices such as SG filters \n",
    "    * deep learning architecture optimisation \n",
    "    * systematic comparison of multi-channel DTOF representaitons \n",
    "\n",
    "Supported Model Variants \n",
    "\n",
    "This pipeline allows dynamic selection of the number of input channels. 3 commonly used configurations are supported: \n",
    "\n",
    "    (1) Single channel DTOF:\n",
    "        * DTOF cropped to 0-5 ns \n",
    "        * Standardised after smoothing \n",
    "        * Input shape: (1, T)\n",
    "\n",
    "    (2) 3 channel temporal bin model: \n",
    "        * Early, mid, and late temporal masks (0 - 0.5 ns, 0.5 - 4 ns, 4 -5 ns)\n",
    "        * Each bin multiplied with the DTOF to form 3 channels \n",
    "        * Input shape: (3, T)\n",
    "    \n",
    "    (3) 4 channel hybrid model:\n",
    "        * Channel 1: Full DTOF (0 - 0.5 ns)\n",
    "        * Channel 2-4: Early, mid, late temporal bins\n",
    "        * Input shape: (4, T)\n",
    "\n",
    "Channel configuration is selected from the CONFIG block and handled automatically by the DTOFDataset \n",
    "\n",
    "Pipeline Components \n",
    "\n",
    "This module consists of: \n",
    "\n",
    "1. CONFIG dictionary: \n",
    "    Centralises all experiment-level parameters including: \n",
    "        - preprocessing settings (SG frame / order, clipping, cropping)\n",
    "        - number of input channels \n",
    "        - temporal mask definitions \n",
    "        - CNN architecture (layer widths, output dimensions)\n",
    "        - learning rate, batch size, epochs \n",
    "\n",
    "2. DTOFDataset: \n",
    "    Implements the preprocessing chain: \n",
    "        - CSV loading \n",
    "        - Savitzky-Golay smoothing \n",
    "        - negative-value clipping \n",
    "        - mean / std standardisation \n",
    "        - crop to 0 - 5 ns\n",
    "        - dynamic construction of 1, 3, or 4 input channels \n",
    "        - returns (signal, [mua, mus])\n",
    "\n",
    "3. Net (CNN architecture): \n",
    "    * Input channels match CONFIG[\"in_channels\"]\n",
    "    * 3 Conv blocks with BatchNorm, ReLU, and pooling \n",
    "    * Automatic flatten dimension calculatino \n",
    "    * Fully connected regression head configurable via CONFIG \n",
    "    * Output dimension fixed at 2 (μa, μs′)\n",
    "\n",
    "4. Training loop: \n",
    "    * GPU/CPU detection \n",
    "    * Train/validation loss computation \n",
    "    * best-model checkpoint saving \n",
    "    * optional printing of sample predictions \n",
    "    * automatic plotting of train/val loss curves (PNG)\n",
    "\n",
    "5. Evaluation and logging: \n",
    "    Provides: \n",
    "        - MAE and RMSE for μa, μs′\n",
    "        - prediction vs.ground truth arrays \n",
    "        - JSON logging of each run's configuration and metrics \n",
    "        - loss curve visualisation per run \n",
    "Dependencies \n",
    "\n",
    "Required: \n",
    "    * torch \n",
    "    * numpy\n",
    "    * pandas \n",
    "    * scipy (Savitzky-Golay filtering)\n",
    "    * matplotlib (loss curve plotting)\n",
    "\n",
    "Recommended: \n",
    "    * seaborn (optional visualisation enhancements)\n",
    "\n",
    "Inputs & Outputs \n",
    "\n",
    "Inputs: \n",
    "    * DTOFs_Homo_raw.csv - raw DTOF data with time in column 0\n",
    "    * DTOFs_Homo_labels.csv - extracted (μa, μs') labels \n",
    "\n",
    "Outputs: \n",
    "    * training and validation loss curves .png\n",
    "    * MAE / RMSE metrics \n",
    "    * prediction arrays for downstream plotting \n",
    "    * JSON log for all runs\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c54dd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb53820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Single configuration: initial starting point\n",
    "\n",
    "CONFIG = {\n",
    "    \"csv_path\": \"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/Pre-obtained data/DTOFs_Homo_raw.csv\", \n",
    "    \"label_csv_path\": \"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/Pre-obtained data/DTOFs_Homo_labels.csv\", \n",
    "\n",
    "    # Preprocessing \n",
    "    \"sg_window\": 21, \n",
    "    \"sg_order\": 1, \n",
    "    \"eps\": 1e-8, \n",
    "    \"crop_t_max\": 5.0,      # crop DTOF to 0-5ns\n",
    "\n",
    "    # Channels: \"single\", \"early_mid_late\", \"hybrid_4ch\"\n",
    "    \"channel_mode\": \"single\",\n",
    "\n",
    "    # Data split + loader\n",
    "    \"train_frac\": 0.8,\n",
    "    \"batch_size\": 32,\n",
    "\n",
    "    # Model\n",
    "    \"in_channels\": 1,            # will be overwritten based on dataset.C\n",
    "    \"output_dim\": 2,             # mua + mus\n",
    "    \"hidden_fc\": [128, 64],\n",
    "\n",
    "    # Training\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 20,\n",
    "\n",
    "    # Outputs / logging\n",
    "    \"run_name\": \"exp_single_w21_o1\",\n",
    "    \"save_dir\": \"JSON logs\",\n",
    "    \"log_path\": \"JSON logs/dtof_runs_log.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "efddff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Label extraction helper\n",
    "\n",
    "def extract_labels_from_dtof_csv(csv_path: str, label_csv_path: str):\n",
    "    \"\"\"\n",
    "    Extracts (mua, mus) labels from DTOF column headers in the raw CSV.\n",
    "\n",
    "    Expects column names: \"mua: 0.005  mus: 2.0\"\n",
    "    Writes a CSV of labels with columns [\"mua\", \"mus\"].\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    dtof_columns = df.columns[1:]  # skip time column\n",
    "    labels = []\n",
    "\n",
    "    for col in dtof_columns:\n",
    "            col_clean = str(col).strip()\n",
    "            match = re.search(r\"mua:\\s*([0-9.]+)\\s+mus:\\s*([0-9.]+)\", col_clean)\n",
    "            if not match:\n",
    "                raise ValueError(f\"Could not parse mua/mus from column '{col}'\")\n",
    "            mua_val = float(match.group(1))\n",
    "            mus_val = float(match.group(2))\n",
    "            labels.append((mua_val, mus_val))   \n",
    "    \n",
    "    label_df = pd.DataFrame(labels, columns=[\"mua\", \"mus\"])\n",
    "    label_df.to_csv(label_csv_path, index=False)\n",
    "    print(f\"[INFO] Saved labels to {label_csv_path} (N={len(label_df)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0153f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DTOFDataset: preprocessing + channel construction \n",
    "\n",
    "class DTOFDataset(Dataset):\n",
    "    \"\"\"\n",
    "    DTOF dataset with preprocessing and flexible channel configurations.\n",
    "\n",
    "    Preprocessing:\n",
    "        - load CSV\n",
    "        - crop time axis to [0, crop_t_max]\n",
    "        - Savitzky-Golay smoothing\n",
    "        - negative-value clipping\n",
    "        - per-trace standardisation\n",
    "        - channel construction:\n",
    "            * \"single\"        -> 1 channel, full DTOF\n",
    "            * \"early_mid_late\"-> 3 channels (early/mid/late masks)\n",
    "            * \"hybrid_4ch\"    -> 4 channels (full + 3 masks)\n",
    "\n",
    "    Returns:\n",
    "        signal: (C, T) tensor (C = n. of channels)\n",
    "        label:  (2,) tensor [mua, mus]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path: str, labels: np.ndarray, cfg: dict):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Time and DTOFs\n",
    "        time_full = df.iloc[:, 0].values               # (T_full,)\n",
    "        dtof_full = df.iloc[:, 1:].values.T            # (N, T_full)\n",
    "        N, T_full = dtof_full.shape\n",
    "\n",
    "        # Crop time axis\n",
    "        t_mask = (time_full >= 0.0) & (time_full <= cfg[\"crop_t_max\"])\n",
    "        time = time_full[t_mask]                       # (T,)\n",
    "        dtof = dtof_full[:, t_mask]                    # (N, T)\n",
    "\n",
    "        # Savitzky–Golay smoothing\n",
    "        dtof_smooth = savgol_filter(\n",
    "            dtof,\n",
    "            cfg[\"sg_window\"],\n",
    "            cfg[\"sg_order\"],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Clip negatives and standardise\n",
    "        eps = cfg[\"eps\"]\n",
    "        dtof_smooth[dtof_smooth < 0] = eps\n",
    "\n",
    "        mean = dtof_smooth.mean(axis=1, keepdims=True)\n",
    "        std = dtof_smooth.std(axis=1, keepdims=True)\n",
    "        #dtof_std = (dtof_smooth - mean) / (std + eps)  # (N, T)\n",
    "\n",
    "        # Build channels\n",
    "        channels = self.build_channels(time, dtof_smooth, cfg[\"channel_mode\"])\n",
    "        # channels: (N, C, T)\n",
    "\n",
    "        self.signals = torch.tensor(channels, dtype=torch.float32)  # (N,C,T)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)     # (N,2)\n",
    "\n",
    "        self.N, self.C, self.T = self.signals.shape\n",
    "\n",
    "    def build_channels(self, t: np.ndarray, dtof: np.ndarray, mode: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Construct channels based on the chosen mode:\n",
    "            \"single\"         -> 1 channel, full DTOF\n",
    "            \"early_mid_late\" -> 3 masked channels\n",
    "            \"hybrid_4ch\"     -> 1 full + 3 masked = 4 channels\n",
    "        \"\"\"\n",
    "        N, T = dtof.shape\n",
    "\n",
    "        if mode == \"single\":\n",
    "            # (N, 1, T)\n",
    "            return dtof[:, None, :]\n",
    "\n",
    "        # Define early/mid/late masks within cropped time\n",
    "        early = ((t >= 0.0) & (t < 0.5)).astype(float)\n",
    "        mid = ((t >= 0.5) & (t < 4.0)).astype(float)\n",
    "        late = ((t >= 4.0) & (t <= self.cfg[\"crop_t_max\"])).astype(float)\n",
    "        masks = np.stack([early, mid, late], axis=0)  # (3, T)\n",
    "\n",
    "        if mode == \"early_mid_late\":\n",
    "            # Multiply each DTOF by masks to get 3 channels\n",
    "            out = dtof[:, None, :] * masks[None, :, :]  # (N,3,T)\n",
    "            return out\n",
    "\n",
    "        if mode == \"hybrid_4ch\":\n",
    "            # Channel 1: full DTOF\n",
    "            ch_full = dtof[:, None, :]                   # (N,1,T)\n",
    "            ch_bins = dtof[:, None, :] * masks[None, :, :]  # (N,3,T)\n",
    "            return np.concatenate([ch_full, ch_bins], axis=1)  # (N,4,T)\n",
    "\n",
    "        raise ValueError(f\"Unknown channel_mode: {mode}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.signals[idx], self.labels[idx]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c67272cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CNN Model (Net) with flexible in_channels and FC head \n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    1D CNN for DTOF-based regression to (μa, μs').\n",
    "\n",
    "    - Supports variable input channels (C) from CONFIG[\"in_channels\"]\n",
    "    - Uses three conv blocks with BatchNorm, ReLU, MaxPool\n",
    "    - Automatically computes flatten dimension\n",
    "    - FC layers controlled by CONFIG[\"hidden_fc\"]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg: dict, input_length: int):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        C = cfg[\"in_channels\"]\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(C, 32, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(32, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        # Determine flatten dim automatically\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, C, input_length)  # (1,C,T)\n",
    "            feat = self._forward_features(dummy)\n",
    "            flatten_dim = feat.shape[1]  # (1, flatten_dim)\n",
    "\n",
    "        # Build FC head from cfg[\"hidden_fc\"]\n",
    "        fc_layers = []\n",
    "        last = flatten_dim\n",
    "        for h in cfg[\"hidden_fc\"]:\n",
    "            fc_layers += [nn.Linear(last, h), nn.ReLU()]\n",
    "            last = h\n",
    "\n",
    "        fc_layers.append(nn.Linear(last, cfg[\"output_dim\"]))\n",
    "        self.fc = nn.Sequential(*fc_layers)\n",
    "\n",
    "    def _forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.flatten(1)  # (batch, -1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self._forward_features(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b5481a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Training loop with loss tracking, prediction inspection & plotting \n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    loss_fn: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    cfg: dict,\n",
    "    device: torch.device\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model with tracking of train/val MSE loss curves, saving best model,\n",
    "    and basic prediction inspection on the first validation batch.\n",
    "    \"\"\"\n",
    "    num_epochs = cfg[\"epochs\"]\n",
    "    save_dir   = cfg[\"save_dir\"]\n",
    "    run_name   = cfg[\"run_name\"]\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    train_losses = []  # MSE(train) per epoch\n",
    "    val_losses   = []  # MSE(val) per epoch\n",
    "    best_val     = float(\"inf\")\n",
    "    best_path    = os.path.join(save_dir, f\"{run_name}_best.pth\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # ----- TRAIN -----\n",
    "        model.train()\n",
    "        running_train = 0.0\n",
    "\n",
    "        for signals, labels in train_loader:\n",
    "            signals = signals.to(device)\n",
    "            labels  = labels.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(signals)            # (B, 2)\n",
    "            loss  = loss_fn(preds, labels)    # this is MSE\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train += loss.item()\n",
    "\n",
    "        epoch_train = running_train / len(train_loader)\n",
    "        train_losses.append(epoch_train)\n",
    "\n",
    "        # ----- VALIDATION -----\n",
    "        model.eval()\n",
    "        running_val = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (signals, labels) in enumerate(val_loader):\n",
    "                signals = signals.to(device)\n",
    "                labels  = labels.to(device).float()\n",
    "\n",
    "                preds = model(signals)\n",
    "                loss  = loss_fn(preds, labels)  # MSE on val\n",
    "                running_val += loss.item()\n",
    "\n",
    "                if epoch == 0 and batch_idx == 0:\n",
    "                    print(\"\\n[VAL SAMPLE] First batch predictions vs labels:\")\n",
    "                    print(\"Preds (μa, μs'):\\n\", preds[:5].cpu())\n",
    "                    print(\"Labels (μa, μs'):\\n\", labels[:5].cpu())\n",
    "                    print(\"Abs error:\\n\", (preds[:5] - labels[:5]).abs().cpu())\n",
    "                    print(\"---------------------------------------------------\")\n",
    "\n",
    "        epoch_val = running_val / len(val_loader)\n",
    "        val_losses.append(epoch_val)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train MSE: {epoch_train:.4f} | Val MSE: {epoch_val:.4f}\")\n",
    "\n",
    "        if epoch_val < best_val:\n",
    "            best_val = epoch_val\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "\n",
    "    # ----- Plot MSE vs epoch (train + val) -----\n",
    "    fig_path = os.path.join(save_dir, f\"{run_name}_loss_curves.png\")\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train MSE\")\n",
    "    plt.plot(val_losses,   label=\"Val MSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE loss\")\n",
    "    plt.title(f\"MSE vs. Epoch: {run_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    results = {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\":   val_losses,\n",
    "        \"best_val\":     best_val,\n",
    "        \"best_path\":    best_path,\n",
    "        \"loss_plot\":    fig_path,\n",
    "    }\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5699a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Evaluation and visualisation of performance (MAE / RMSE, percentage error)\n",
    "class ModelEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on a DataLoader and compute MAE/RMSE for (μa, μs'),\n",
    "    plus percentage error plots vs actual values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, device: torch.device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate(self, data_loader: DataLoader, cfg: dict):\n",
    "        all_preds  = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in data_loader:\n",
    "                signals = signals.to(self.device)\n",
    "                labels  = labels.to(self.device).float()\n",
    "\n",
    "                preds = self.model(signals)\n",
    "\n",
    "                all_preds.append(preds.cpu())\n",
    "                all_labels.append(labels.cpu())\n",
    "\n",
    "        all_preds  = torch.cat(all_preds,  dim=0)  # (N,2)\n",
    "        all_labels = torch.cat(all_labels, dim=0)  # (N,2)\n",
    "\n",
    "        # Basic metrics: MAE and RMSE\n",
    "        abs_err = torch.abs(all_preds - all_labels)\n",
    "        sq_err  = (all_preds - all_labels) ** 2\n",
    "\n",
    "        mae  = abs_err.mean(dim=0)             # (2,)\n",
    "        rmse = torch.sqrt(sq_err.mean(dim=0))  # (2,)\n",
    "\n",
    "        # ---------- Percentage error vs Actual ----------\n",
    "        preds_np  = all_preds.numpy()\n",
    "        labels_np = all_labels.numpy()\n",
    "\n",
    "        # Avoid division by very small numbers\n",
    "        eps = 1e-8\n",
    "        denom = np.maximum(np.abs(labels_np), eps)  # (N,2)\n",
    "\n",
    "        pct_error = 100.0 * (preds_np - labels_np) / denom  # signed %\n",
    "        abs_pct_error = np.abs(pct_error)                   # absolute %\n",
    "\n",
    "        # Scatter plots: Actual vs % error for μa and μs′\n",
    "        save_dir = cfg[\"save_dir\"]\n",
    "        run_name = cfg[\"run_name\"]\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # error vs true μa plot\n",
    "        fig_mua = os.path.join(save_dir, f\"{run_name}_pct_error_mua.png\")\n",
    "        x = labels_np[:, 0]            # true μa\n",
    "        y = abs_pct_error[:, 0]        # absolute percentage error\n",
    "\n",
    "        plt.figure()\n",
    "        plt.scatter(x, y, s=10, alpha=0.6, label=\"Absolute % error\")\n",
    "\n",
    "        # Exponential model\n",
    "        def _exp_model(x, a, b, c):\n",
    "            return a * np.exp(-b * x) + c\n",
    "\n",
    "        # Fit curve\n",
    "        try:\n",
    "            popt, _ = curve_fit(_exp_model, x, y, p0=[100, 1.0, 0.0], maxfev=5000)\n",
    "            x_fit = np.linspace(min(x), max(x), 300)\n",
    "            y_fit = _exp_model(x_fit, *popt)\n",
    "            plt.plot(\n",
    "                x_fit, y_fit, \"r-\", linewidth=2,\n",
    "                label=f\"Fit: a·exp(-b·x) + c\\n\"\n",
    "                    f\"a={popt[0]:.2f}, b={popt[1]:.2f}, c={popt[2]:.2f}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] μa exponential fit failed:\", e)\n",
    "\n",
    "        plt.xlabel(\"True μa\")\n",
    "        plt.ylabel(\"Absolute % error\")\n",
    "        plt.title(f\"Percentage error vs Actual μa: {run_name}\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_mua, dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        # error vs true μs′ plot\n",
    "        fig_mus = os.path.join(save_dir, f\"{run_name}_pct_error_mus.png\")\n",
    "        x = labels_np[:, 1]            # true μs'\n",
    "        y = abs_pct_error[:, 1]        # absolute percentage error\n",
    "\n",
    "        plt.figure()\n",
    "        plt.scatter(x, y, s=10, alpha=0.6, label=\"Absolute % error\")\n",
    "\n",
    "        # Exponential model\n",
    "        def _exp_model(x, a, b, c):\n",
    "            return a * np.exp(-b * x) + c\n",
    "\n",
    "        # Fit curve\n",
    "        try:\n",
    "            popt, _ = curve_fit(_exp_model, x, y, p0=[100, 0.5, 0.0], maxfev=5000)\n",
    "            x_fit = np.linspace(min(x), max(x), 300)\n",
    "            y_fit = _exp_model(x_fit, *popt)\n",
    "            plt.plot(\n",
    "                x_fit, y_fit, \"r-\", linewidth=2,\n",
    "                label=f\"Fit: a·e^(-b·x) + c\\n\"\n",
    "                    f\"a={popt[0]:.2f}, b={popt[1]:.2f}, c={popt[2]:.2f}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] μs' exponential fit failed:\", e)\n",
    "\n",
    "        plt.xlabel(\"True μs'\")\n",
    "        plt.ylabel(\"Absolute % error\")\n",
    "        plt.title(f\"Percentage error vs Actual μs': {run_name}\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_mus, dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        metrics = {\n",
    "            \"MAE\": mae.numpy(),          # [MAE_mua, MAE_mus]\n",
    "            \"RMSE\": rmse.numpy(),        # [RMSE_mua, RMSE_mus]\n",
    "            \"preds\": preds_np,\n",
    "            \"labels\": labels_np,\n",
    "            \"pct_error\": pct_error,      # signed %\n",
    "            \"abs_pct_error\": abs_pct_error,\n",
    "            \"pct_error_plots\": {\n",
    "                \"mua\": fig_mua,\n",
    "                \"mus\": fig_mus,\n",
    "            }\n",
    "        }\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5d56a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Logging of runs (config + metrics) to JSON \n",
    "\n",
    "def log_run(cfg, results, log_path):\n",
    "    \"\"\"\n",
    "    Append a run entry to a JSON log file, including config and metrics.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "\n",
    "    # Handle both old ('best_path') and new ('model_path') keys safely\n",
    "    model_path = results.get(\"model_path\", results.get(\"best_path\", None))\n",
    "\n",
    "    entry = {\n",
    "        \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "        \"run_name\": cfg[\"run_name\"],\n",
    "        \"sg_window\": cfg[\"sg_window\"],\n",
    "        \"sg_order\": cfg[\"sg_order\"],\n",
    "        \"channel_mode\": cfg[\"channel_mode\"],\n",
    "        \"crop_t_max\": cfg[\"crop_t_max\"],\n",
    "        \"hidden_fc\": cfg[\"hidden_fc\"],\n",
    "        \"lr\": cfg[\"lr\"],\n",
    "        \"epochs\": cfg[\"epochs\"],\n",
    "        \"batch_size\": cfg[\"batch_size\"],\n",
    "        \"best_val\": results[\"best_val\"],\n",
    "        \"loss_plot\": results[\"loss_plot\"],\n",
    "        \"model_path\": model_path,\n",
    "    }\n",
    "\n",
    "    # to store MAE / RMSE \n",
    "    if \"val_metrics\" in results:\n",
    "        entry[\"MAE\"] = results[\"val_metrics\"][\"MAE\"].tolist()\n",
    "        entry[\"RMSE\"] = results[\"val_metrics\"][\"RMSE\"].tolist()\n",
    "        entry[\"pct_error_plots\"] = results[\"val_metrics\"][\"pct_error_plots\"]\n",
    "\n",
    "    if os.path.exists(log_path):\n",
    "        with open(log_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        data.append(entry)\n",
    "    else:\n",
    "        data = [entry]\n",
    "\n",
    "    with open(log_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3e79159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_in_channels(mode: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns number of input channels for the CNN depending on the preprocessing mode.\n",
    "\n",
    "    mode options:\n",
    "        \"single\"          -> 1 channel  (raw DTOF only)\n",
    "        \"early_mid_late\"  -> 3 channels (masked temporal bins)\n",
    "        \"hybrid_4ch\"      -> 4 channels (raw + 3 temporal bins)\n",
    "    \"\"\"\n",
    "    if mode == \"single\":\n",
    "        return 1\n",
    "    elif mode == \"early_mid_late\":\n",
    "        return 3\n",
    "    elif mode == \"hybrid_4ch\":\n",
    "        return 4\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown channel_mode: {mode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "228a0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Single experiment runner\n",
    "\n",
    "def run_experiment(cfg):\n",
    "\n",
    "    # Work on a copy of the cfg to avoid mutating the single CONFIG instantiation to allow for debugging / individual run visualisation \n",
    "    cfg = dict(cfg)\n",
    "\n",
    "    # 1. Build dataset + loaders\n",
    "    labels = pd.read_csv(cfg[\"label_csv_path\"]).values # shape (N, 2)\n",
    "    dataset = DTOFDataset(\n",
    "        csv_path=cfg[\"csv_path\"],\n",
    "        labels=labels, # shape (N,2)\n",
    "        cfg = cfg, \n",
    "    )\n",
    "\n",
    "    n_train = int(0.8 * len(dataset))\n",
    "    n_val = len(dataset) - n_train\n",
    "    train_dataset, val_dataset = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=cfg[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    # 2. Build model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Derive in_channels from channel_mode and store in cfg for Net (the copy)\n",
    "    in_channels = get_in_channels(cfg[\"channel_mode\"])\n",
    "    cfg[\"in_channels\"] = in_channels\n",
    "\n",
    "    model = Net(\n",
    "        cfg = cfg, \n",
    "        input_length = dataset.T, \n",
    "    ).to(device)\n",
    "\n",
    "    # Loss + optimizer\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg[\"lr\"])\n",
    "\n",
    "    # 3. Training Loop\n",
    "    best_val = float(\"inf\")       \n",
    "    save_path = None                 \n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(cfg[\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for signals, labels in train_loader:\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(signals)\n",
    "            loss = loss_fn(preds, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_running = 0.0\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in val_loader:\n",
    "                signals = signals.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                preds = model(signals)\n",
    "                val_running += loss_fn(preds, labels).item()\n",
    "\n",
    "        val_loss = val_running / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # ---- Save best model ----\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            save_path = f\"Best paths/{cfg['run_name']}_best.pth\"   \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    # ---- Plot curves for this run ----\n",
    "    fig_path = f\"Model evaluation figs/{cfg['run_name']}_loss_curves.png\"\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train MSE\")\n",
    "    plt.plot(val_losses, label=\"Val MSE\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.title(f\"Loss Curves: {cfg['run_name']}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # ---- Evaluate best model on validation set with ModelEvaluator ----\n",
    "    # Rebuild best model and load best weights\n",
    "    best_model = Net(\n",
    "        cfg=cfg,\n",
    "        input_length=dataset.T,\n",
    "    ).to(device)\n",
    "\n",
    "    if save_path is not None:\n",
    "        best_model.load_state_dict(torch.load(save_path, map_location=device))\n",
    "\n",
    "    evaluator = ModelEvaluator(model=best_model, device=device)\n",
    "\n",
    "    eval_cfg = {\n",
    "        \"run_name\": cfg[\"run_name\"],\n",
    "        \"save_dir\": cfg.get(\"eval_save_dir\", \"Model evaluation figs\"),\n",
    "    }\n",
    "\n",
    "    val_metrics = evaluator.evaluate(val_loader, cfg=eval_cfg)\n",
    "\n",
    "    # 4. Return results (including metrics)\n",
    "    return {\n",
    "        \"run_name\": cfg[\"run_name\"],\n",
    "        \"best_val\": best_val,         # validation MSE at best epoch\n",
    "        \"model_path\": save_path,      # path to best model weights\n",
    "        \"cfg\": cfg,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"loss_plot\": fig_path,\n",
    "        \"val_metrics\": val_metrics,   # MAE, RMSE, % errors, plot paths\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abf7abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Simple grid search over a few configurations \n",
    "\n",
    "def grid_search():\n",
    "    base_cfg = CONFIG\n",
    "\n",
    "    windows = [11, 21, 31, 41]\n",
    "    orders  = [1,  2,  3,  4]\n",
    "    modes   = [\"single\", \"early_mid_late\", \"hybrid_4ch\"]\n",
    "    lrs     = [1e-3, 3e-4]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for w in windows:\n",
    "        for o in orders:\n",
    "            for mode in modes:\n",
    "                for lr in lrs:\n",
    "                    cfg = dict(base_cfg)\n",
    "                    cfg[\"sg_window\"]   = w\n",
    "                    cfg[\"sg_order\"]    = o\n",
    "                    cfg[\"channel_mode\"] = mode\n",
    "                    cfg[\"lr\"]          = lr\n",
    "                    cfg[\"run_name\"]    = f\"{mode}_w{w}_o{o}_lr{lr}\"\n",
    "\n",
    "                    print(f\"\\n=== Running {cfg['run_name']} ===\")\n",
    "                    res = run_experiment(cfg)\n",
    "\n",
    "                    # Attach best_val directly at top-level for convenience (already done in res)\n",
    "                    results.append(res)\n",
    "\n",
    "                    # log run to JSON (now includes val_metrics)\n",
    "                    log_run(cfg, res, cfg[\"log_path\"])\n",
    "\n",
    "    # Sort by validation loss (MSE). NOTE: key name is 'best_val', not 'val_loss'.\n",
    "    results_sorted = sorted(results, key=lambda x: x[\"best_val\"])\n",
    "\n",
    "    print(\"\\n==================== GRID SEARCH SUMMARY ====================\")\n",
    "    for r in results_sorted[:10]:  # print top 10\n",
    "        best_val = r[\"best_val\"]\n",
    "        mae      = r[\"val_metrics\"][\"MAE\"]   # [MAE_mua, MAE_mus]\n",
    "        rmse     = r[\"val_metrics\"][\"RMSE\"]  # [RMSE_mua, RMSE_mus]\n",
    "\n",
    "        print(\n",
    "            f\"{r['run_name']} | \"\n",
    "            f\"val_MSE={best_val:.6f} | \"\n",
    "            f\"MAE=(μa={mae[0]:.4f}, μs'={mae[1]:.4f}) | \"\n",
    "            f\"RMSE=(μa={rmse[0]:.4f}, μs'={rmse[1]:.4f})\"\n",
    "        )\n",
    "\n",
    "    best = results_sorted[0]\n",
    "    print(\"\\nBEST MODEL (by val MSE):\")\n",
    "    print(best[\"run_name\"])\n",
    "    print(f\"  val_MSE = {best['best_val']:.6f}\")\n",
    "    print(f\"  model_path = {best['model_path']}\")\n",
    "    print(f\"  loss_plot  = {best['loss_plot']}\")\n",
    "    print(f\"  MAE  = {best['val_metrics']['MAE']}\")\n",
    "    print(f\"  RMSE = {best['val_metrics']['RMSE']}\")\n",
    "\n",
    "    return results_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8717d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] μs' exponential fit failed: Optimal parameters not found: Number of calls to function has reached maxfev = 5000.\n",
      "exp_single_w21_o1 0.04363725893199444\n"
     ]
    }
   ],
   "source": [
    "# Single experiment run \n",
    "if __name__ == \"__main__\":\n",
    "    run_info = run_experiment(CONFIG)\n",
    "    print(run_info[\"run_name\"], run_info[\"best_val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9db27c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running single_w11_o1_lr0.001 ===\n",
      "\n",
      "=== Running single_w11_o1_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w11_o1_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w11_o1_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w11_o1_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w11_o1_lr0.0003 ===\n",
      "\n",
      "=== Running single_w11_o2_lr0.001 ===\n",
      "\n",
      "=== Running single_w11_o2_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w11_o2_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w11_o2_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w11_o2_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w11_o2_lr0.0003 ===\n",
      "\n",
      "=== Running single_w11_o3_lr0.001 ===\n",
      "\n",
      "=== Running single_w11_o3_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w11_o3_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w11_o3_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w11_o3_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w11_o3_lr0.0003 ===\n",
      "\n",
      "=== Running single_w11_o4_lr0.001 ===\n",
      "\n",
      "=== Running single_w11_o4_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w11_o4_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w11_o4_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w11_o4_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w11_o4_lr0.0003 ===\n",
      "\n",
      "=== Running single_w21_o1_lr0.001 ===\n",
      "\n",
      "=== Running single_w21_o1_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w21_o1_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w21_o1_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w21_o1_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w21_o1_lr0.0003 ===\n",
      "\n",
      "=== Running single_w21_o2_lr0.001 ===\n",
      "\n",
      "=== Running single_w21_o2_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w21_o2_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w21_o2_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w21_o2_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w21_o2_lr0.0003 ===\n",
      "\n",
      "=== Running single_w21_o3_lr0.001 ===\n",
      "\n",
      "=== Running single_w21_o3_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w21_o3_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w21_o3_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w21_o3_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w21_o3_lr0.0003 ===\n",
      "\n",
      "=== Running single_w21_o4_lr0.001 ===\n",
      "\n",
      "=== Running single_w21_o4_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w21_o4_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w21_o4_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w21_o4_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w21_o4_lr0.0003 ===\n",
      "\n",
      "=== Running single_w31_o1_lr0.001 ===\n",
      "\n",
      "=== Running single_w31_o1_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w31_o1_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w31_o1_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w31_o1_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w31_o1_lr0.0003 ===\n",
      "\n",
      "=== Running single_w31_o2_lr0.001 ===\n",
      "\n",
      "=== Running single_w31_o2_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w31_o2_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w31_o2_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w31_o2_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w31_o2_lr0.0003 ===\n",
      "\n",
      "=== Running single_w31_o3_lr0.001 ===\n",
      "\n",
      "=== Running single_w31_o3_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w31_o3_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w31_o3_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w31_o3_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w31_o3_lr0.0003 ===\n",
      "[WARN] μs' exponential fit failed: Optimal parameters not found: Number of calls to function has reached maxfev = 5000.\n",
      "\n",
      "=== Running single_w31_o4_lr0.001 ===\n",
      "\n",
      "=== Running single_w31_o4_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w31_o4_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w31_o4_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w31_o4_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w31_o4_lr0.0003 ===\n",
      "\n",
      "=== Running single_w41_o1_lr0.001 ===\n",
      "\n",
      "=== Running single_w41_o1_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w41_o1_lr0.001 ===\n",
      "[WARN] μs' exponential fit failed: Optimal parameters not found: Number of calls to function has reached maxfev = 5000.\n",
      "\n",
      "=== Running early_mid_late_w41_o1_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w41_o1_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w41_o1_lr0.0003 ===\n",
      "\n",
      "=== Running single_w41_o2_lr0.001 ===\n",
      "\n",
      "=== Running single_w41_o2_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w41_o2_lr0.001 ===\n",
      "[WARN] μs' exponential fit failed: Optimal parameters not found: Number of calls to function has reached maxfev = 5000.\n",
      "\n",
      "=== Running early_mid_late_w41_o2_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w41_o2_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w41_o2_lr0.0003 ===\n",
      "\n",
      "=== Running single_w41_o3_lr0.001 ===\n",
      "\n",
      "=== Running single_w41_o3_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w41_o3_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w41_o3_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w41_o3_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w41_o3_lr0.0003 ===\n",
      "\n",
      "=== Running single_w41_o4_lr0.001 ===\n",
      "\n",
      "=== Running single_w41_o4_lr0.0003 ===\n",
      "\n",
      "=== Running early_mid_late_w41_o4_lr0.001 ===\n",
      "\n",
      "=== Running early_mid_late_w41_o4_lr0.0003 ===\n",
      "\n",
      "=== Running hybrid_4ch_w41_o4_lr0.001 ===\n",
      "\n",
      "=== Running hybrid_4ch_w41_o4_lr0.0003 ===\n",
      "\n",
      "==================== GRID SEARCH SUMMARY ====================\n",
      "hybrid_4ch_w31_o3_lr0.0003 | val_MSE=0.026983 | MAE=(μa=0.0304, μs'=0.1914) | RMSE=(μa=0.0388, μs'=0.2283)\n",
      "single_w41_o1_lr0.001 | val_MSE=0.037232 | MAE=(μa=0.0791, μs'=0.1579) | RMSE=(μa=0.0840, μs'=0.2569)\n",
      "single_w31_o4_lr0.001 | val_MSE=0.041102 | MAE=(μa=0.0243, μs'=0.2313) | RMSE=(μa=0.0339, μs'=0.2951)\n",
      "hybrid_4ch_w11_o1_lr0.001 | val_MSE=0.041589 | MAE=(μa=0.0191, μs'=0.1501) | RMSE=(μa=0.0279, μs'=0.3115)\n",
      "hybrid_4ch_w41_o3_lr0.0003 | val_MSE=0.041669 | MAE=(μa=0.0218, μs'=0.2098) | RMSE=(μa=0.0272, μs'=0.2940)\n",
      "early_mid_late_w41_o1_lr0.001 | val_MSE=0.041866 | MAE=(μa=0.0515, μs'=0.2117) | RMSE=(μa=0.0601, μs'=0.2997)\n",
      "early_mid_late_w31_o4_lr0.001 | val_MSE=0.042386 | MAE=(μa=0.0255, μs'=0.2224) | RMSE=(μa=0.0315, μs'=0.2978)\n",
      "early_mid_late_w41_o2_lr0.001 | val_MSE=0.043284 | MAE=(μa=0.0180, μs'=0.1676) | RMSE=(μa=0.0257, μs'=0.2818)\n",
      "single_w41_o4_lr0.001 | val_MSE=0.044704 | MAE=(μa=0.0342, μs'=0.2033) | RMSE=(μa=0.0426, μs'=0.3087)\n",
      "single_w21_o1_lr0.001 | val_MSE=0.044908 | MAE=(μa=0.0299, μs'=0.2031) | RMSE=(μa=0.0381, μs'=0.3113)\n",
      "\n",
      "BEST MODEL (by val MSE):\n",
      "hybrid_4ch_w31_o3_lr0.0003\n",
      "  val_MSE = 0.026983\n",
      "  model_path = Best paths/hybrid_4ch_w31_o3_lr0.0003_best.pth\n",
      "  loss_plot  = Model evaluation figs/hybrid_4ch_w31_o3_lr0.0003_loss_curves.png\n",
      "  MAE  = [0.03042994 0.19143018]\n",
      "  RMSE = [0.03882584 0.2283369 ]\n",
      "\n",
      "BEST MODEL FROM GRID SEARCH:\n",
      "hybrid_4ch_w31_o3_lr0.0003 0.02698253033061822\n"
     ]
    }
   ],
   "source": [
    "# Run grid search \n",
    "if __name__ == \"__main__\": \n",
    "    results = grid_search()\n",
    "\n",
    "    # print the best configuration \n",
    "    best = min(results, key=lambda r: r[\"best_val\"])\n",
    "    print(\"\\nBEST MODEL FROM GRID SEARCH:\")\n",
    "    print(best[\"run_name\"], best[\"best_val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04544216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Overall top 5 runs (across all channel modes):\n",
      "================================================================================\n",
      "  - run_name: early_mid_late_w11_o4_lr0.001\n",
      "    channel_mode: early_mid_late\n",
      "    sg_window: 11, sg_order: 4\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.020709\n",
      "    MAE: (n/a)\n",
      "    RMSE: (n/a)\n",
      "    model_path: Best paths/early_mid_late_w11_o4_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/early_mid_late_w11_o4_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: single_w31_o3_lr0.0003\n",
      "    channel_mode: single\n",
      "    sg_window: 31, sg_order: 3\n",
      "    lr: 0.0003, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.023788\n",
      "    MAE: (n/a)\n",
      "    RMSE: (n/a)\n",
      "    model_path: Best paths/single_w31_o3_lr0.0003_best.pth\n",
      "    loss_plot: Model evaluation figs/single_w31_o3_lr0.0003_loss_curves.png\n",
      "\n",
      "  - run_name: hybrid_4ch_w31_o3_lr0.0003\n",
      "    channel_mode: hybrid_4ch\n",
      "    sg_window: 31, sg_order: 3\n",
      "    lr: 0.0003, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.026983\n",
      "    MAE: (μa=0.0304, μs'=0.1914)\n",
      "    RMSE: (μa=0.0388, μs'=0.2283)\n",
      "    model_path: Best paths/hybrid_4ch_w31_o3_lr0.0003_best.pth\n",
      "    loss_plot: Model evaluation figs/hybrid_4ch_w31_o3_lr0.0003_loss_curves.png\n",
      "\n",
      "  - run_name: hybrid_4ch_w11_o1_lr0.001\n",
      "    channel_mode: hybrid_4ch\n",
      "    sg_window: 11, sg_order: 1\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.033427\n",
      "    MAE: (n/a)\n",
      "    RMSE: (n/a)\n",
      "    model_path: Best paths/hybrid_4ch_w11_o1_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/hybrid_4ch_w11_o1_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: hybrid_4ch_w21_o4_lr0.001\n",
      "    channel_mode: hybrid_4ch\n",
      "    sg_window: 21, sg_order: 4\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.033898\n",
      "    MAE: (n/a)\n",
      "    RMSE: (n/a)\n",
      "    model_path: Best paths/hybrid_4ch_w21_o4_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/hybrid_4ch_w21_o4_lr0.001_loss_curves.png\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Top 5 runs per channel_mode:\n",
      "================================================================================\n",
      "\n",
      ">>> channel_mode = 'single'\n",
      "  - run_name: single_w31_o3_lr0.0003\n",
      "    channel_mode: single\n",
      "    sg_window: 31, sg_order: 3\n",
      "    lr: 0.0003, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.023788\n",
      "    MAE: (n/a)\n",
      "    RMSE: (n/a)\n",
      "    model_path: Best paths/single_w31_o3_lr0.0003_best.pth\n",
      "    loss_plot: Model evaluation figs/single_w31_o3_lr0.0003_loss_curves.png\n",
      "\n",
      "  - run_name: single_w41_o1_lr0.001\n",
      "    channel_mode: single\n",
      "    sg_window: 41, sg_order: 1\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.037232\n",
      "    MAE: (μa=0.0791, μs'=0.1579)\n",
      "    RMSE: (μa=0.0840, μs'=0.2569)\n",
      "    model_path: Best paths/single_w41_o1_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/single_w41_o1_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: single_w31_o3_lr0.001\n",
      "    channel_mode: single\n",
      "    sg_window: 31, sg_order: 3\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.038855\n",
      "    MAE: (n/a)\n",
      "    RMSE: (n/a)\n",
      "    model_path: Best paths/single_w31_o3_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/single_w31_o3_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: single_w41_o2_lr0.001\n",
      "    channel_mode: single\n",
      "    sg_window: 41, sg_order: 2\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.039716\n",
      "    MAE: (n/a)\n",
      "    RMSE: (n/a)\n",
      "    model_path: Best paths/single_w41_o2_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/single_w41_o2_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: single_w31_o4_lr0.001\n",
      "    channel_mode: single\n",
      "    sg_window: 31, sg_order: 4\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.041102\n",
      "    MAE: (μa=0.0243, μs'=0.2313)\n",
      "    RMSE: (μa=0.0339, μs'=0.2951)\n",
      "    model_path: Best paths/single_w31_o4_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/single_w31_o4_lr0.001_loss_curves.png\n",
      "\n",
      "\n",
      ">>> channel_mode = 'hybrid_4ch'\n",
      "  - run_name: hybrid_4ch_w31_o3_lr0.0003\n",
      "    channel_mode: hybrid_4ch\n",
      "    sg_window: 31, sg_order: 3\n",
      "    lr: 0.0003, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.026983\n",
      "    MAE: (μa=0.0304, μs'=0.1914)\n",
      "    RMSE: (μa=0.0388, μs'=0.2283)\n",
      "    model_path: Best paths/hybrid_4ch_w31_o3_lr0.0003_best.pth\n",
      "    loss_plot: Model evaluation figs/hybrid_4ch_w31_o3_lr0.0003_loss_curves.png\n",
      "\n",
      "  - run_name: hybrid_4ch_w11_o1_lr0.001\n",
      "    channel_mode: hybrid_4ch\n",
      "    sg_window: 11, sg_order: 1\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.033427\n",
      "    MAE: (n/a)\n",
      "    RMSE: (n/a)\n",
      "    model_path: Best paths/hybrid_4ch_w11_o1_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/hybrid_4ch_w11_o1_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: hybrid_4ch_w21_o4_lr0.001\n",
      "    channel_mode: hybrid_4ch\n",
      "    sg_window: 21, sg_order: 4\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.033898\n",
      "    MAE: (n/a)\n",
      "    RMSE: (n/a)\n",
      "    model_path: Best paths/hybrid_4ch_w21_o4_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/hybrid_4ch_w21_o4_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: hybrid_4ch_w11_o1_lr0.001\n",
      "    channel_mode: hybrid_4ch\n",
      "    sg_window: 11, sg_order: 1\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.041589\n",
      "    MAE: (μa=0.0191, μs'=0.1501)\n",
      "    RMSE: (μa=0.0279, μs'=0.3115)\n",
      "    model_path: Best paths/hybrid_4ch_w11_o1_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/hybrid_4ch_w11_o1_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: hybrid_4ch_w41_o3_lr0.0003\n",
      "    channel_mode: hybrid_4ch\n",
      "    sg_window: 41, sg_order: 3\n",
      "    lr: 0.0003, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.041669\n",
      "    MAE: (μa=0.0218, μs'=0.2098)\n",
      "    RMSE: (μa=0.0272, μs'=0.2940)\n",
      "    model_path: Best paths/hybrid_4ch_w41_o3_lr0.0003_best.pth\n",
      "    loss_plot: Model evaluation figs/hybrid_4ch_w41_o3_lr0.0003_loss_curves.png\n",
      "\n",
      "\n",
      ">>> channel_mode = 'early_mid_late'\n",
      "  - run_name: early_mid_late_w11_o4_lr0.001\n",
      "    channel_mode: early_mid_late\n",
      "    sg_window: 11, sg_order: 4\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.020709\n",
      "    MAE: (n/a)\n",
      "    RMSE: (n/a)\n",
      "    model_path: Best paths/early_mid_late_w11_o4_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/early_mid_late_w11_o4_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: early_mid_late_w41_o1_lr0.001\n",
      "    channel_mode: early_mid_late\n",
      "    sg_window: 41, sg_order: 1\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.041866\n",
      "    MAE: (μa=0.0515, μs'=0.2117)\n",
      "    RMSE: (μa=0.0601, μs'=0.2997)\n",
      "    model_path: Best paths/early_mid_late_w41_o1_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/early_mid_late_w41_o1_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: early_mid_late_w31_o4_lr0.001\n",
      "    channel_mode: early_mid_late\n",
      "    sg_window: 31, sg_order: 4\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.042386\n",
      "    MAE: (μa=0.0255, μs'=0.2224)\n",
      "    RMSE: (μa=0.0315, μs'=0.2978)\n",
      "    model_path: Best paths/early_mid_late_w31_o4_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/early_mid_late_w31_o4_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: early_mid_late_w41_o1_lr0.001\n",
      "    channel_mode: early_mid_late\n",
      "    sg_window: 41, sg_order: 1\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.042503\n",
      "    MAE: (n/a)\n",
      "    RMSE: (n/a)\n",
      "    model_path: Best paths/early_mid_late_w41_o1_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/early_mid_late_w41_o1_lr0.001_loss_curves.png\n",
      "\n",
      "  - run_name: early_mid_late_w41_o2_lr0.001\n",
      "    channel_mode: early_mid_late\n",
      "    sg_window: 41, sg_order: 2\n",
      "    lr: 0.001, epochs: 20, batch_size: 32\n",
      "    best_val (MSE): 0.043284\n",
      "    MAE: (μa=0.0180, μs'=0.1676)\n",
      "    RMSE: (μa=0.0257, μs'=0.2818)\n",
      "    model_path: Best paths/early_mid_late_w41_o2_lr0.001_best.pth\n",
      "    loss_plot: Model evaluation figs/early_mid_late_w41_o2_lr0.001_loss_curves.png\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
