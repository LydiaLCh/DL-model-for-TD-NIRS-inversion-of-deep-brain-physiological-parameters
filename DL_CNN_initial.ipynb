{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b73156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import random \n",
    "import torch \n",
    "from torch import nn \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset, DataLoader,Subset\n",
    "from scipy.signal import savgol_filter \n",
    "import h5py\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ef4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Savitzky Golay filter parameters \n",
    "order = 1\n",
    "frame_length = 21\n",
    "eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b40d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b358256",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTOFDataset(Dataset):\n",
    "    \"\"\"\n",
    "        DTOF dataset for MATLAB v7.3 (.mat, HDF5) files.\n",
    "\n",
    "        Required datasets inside .mat:\n",
    "            X : (Nt, N) or (N, Nt)  reflectance DTOFs\n",
    "            y : (2, N)  or (N, 2)   [mua, mus']\n",
    "            t : (Nt,)              time vector in seconds (~1e-12 resolution)\n",
    "\n",
    "        Preprocessing:\n",
    "            - convert t from seconds -> ns\n",
    "            - crop [0, crop_t_max] ns\n",
    "            - Savitzky–Golay smoothing\n",
    "            - clip small values to eps\n",
    "            - input representation:\n",
    "                * \"raw\"      -> use reflectance (smoothed+clipped)\n",
    "                * \"log\"      -> use log(reflectance)\n",
    "                * \"raw_log\"  -> concatenate raw and log along channel dimension\n",
    "            - channel construction:\n",
    "                * \"single\"         -> 1 channel (full)\n",
    "                * \"early_mid_late\" -> 3 channels (early/mid/late masks)\n",
    "                * \"hybrid_4ch\"     -> 4 channels (full + early/mid/late masks)\n",
    "\n",
    "        Returns:\n",
    "            signal: (C, T) float32 tensor\n",
    "            label:  (2,) float32 tensor [mua, mus']  (raw labels for now)\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, mat_path: str, cfg: dict):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # ---------- load HDF5 (.mat v7.3) ----------\n",
    "        with h5py.File(mat_path, \"r\") as f:\n",
    "            X = np.array(f[\"X\"], dtype=np.float32)\n",
    "            y = np.array(f[\"y\"], dtype=np.float32)\n",
    "            t = np.array(f[\"t\"], dtype=np.float32).squeeze()\n",
    "\n",
    "        # ---------- normalise shapes ----------\n",
    "        # X -> (N, Nt)\n",
    "        if X.shape[0] == t.shape[0]:\n",
    "            X = X.T\n",
    "\n",
    "        # y -> (N, 2)\n",
    "        if y.shape[0] == 2:\n",
    "            y = y.T\n",
    "\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError(f\"Expected X to be 2D, got {X.shape}\")\n",
    "        if y.ndim != 2 or y.shape[1] != 2:\n",
    "            raise ValueError(f\"Expected y to be (N,2), got {y.shape}\")\n",
    "        if t.ndim != 1:\n",
    "            raise ValueError(f\"Expected t to be (Nt,), got {t.shape}\")\n",
    "        if X.shape[1] != t.shape[0]:\n",
    "            raise ValueError(f\"X and t mismatch: X Nt={X.shape[1]} vs t Nt={t.shape[0]}\")\n",
    "\n",
    "        # ---------- time: seconds -> ns ----------\n",
    "        t_ns = t * 1e9\n",
    "\n",
    "        # ---------- crop ----------\n",
    "        crop_t_max = float(cfg[\"crop_t_max\"])  # ns\n",
    "        t_mask = (t_ns >= 0.0) & (t_ns <= crop_t_max)\n",
    "        if not np.any(t_mask):\n",
    "            raise ValueError(\n",
    "                f\"Cropping removed all points. \"\n",
    "                f\"t_ns range=[{t_ns.min():.3g}, {t_ns.max():.3g}] ns, crop_t_max={crop_t_max}\"\n",
    "            )\n",
    "\n",
    "        t_ns = t_ns[t_mask]              # (T,)\n",
    "        dtof = X[:, t_mask]              # (N,T)\n",
    "\n",
    "        N, T = dtof.shape\n",
    "\n",
    "        # ---------- Savitzky–Golay ----------\n",
    "        sg_window = int(cfg[\"sg_window\"])\n",
    "        sg_order = int(cfg[\"sg_order\"])\n",
    "\n",
    "        # enforce validity (odd, > order, <= T)\n",
    "        if sg_window % 2 == 0:\n",
    "            sg_window += 1\n",
    "        if sg_window <= sg_order:\n",
    "            sg_window = sg_order + 2\n",
    "            if sg_window % 2 == 0:\n",
    "                sg_window += 1\n",
    "        if sg_window > T:\n",
    "            sg_window = T if (T % 2 == 1) else (T - 1)\n",
    "\n",
    "        if sg_window >= 3:\n",
    "            dtof = savgol_filter(dtof, sg_window, sg_order, axis=1)\n",
    "\n",
    "        # ---------- clip ----------\n",
    "        eps = float(cfg.get(\"eps\", 1e-12))\n",
    "        dtof[dtof < eps] = eps\n",
    "\n",
    "        # ---------- choose representation ----------\n",
    "        input_rep = cfg.get(\"input_rep\", \"log\")  # \"raw\" | \"log\" | \"raw_log\"\n",
    "\n",
    "        dtof_raw = dtof.astype(np.float32)\n",
    "        dtof_log = np.log(dtof_raw).astype(np.float32)\n",
    "\n",
    "        # ---------- build channels ----------\n",
    "        if input_rep == \"raw\":\n",
    "            channels = self.build_channels(t_ns, dtof_raw, cfg[\"channel_mode\"])  # (N,C,T)\n",
    "\n",
    "        elif input_rep == \"log\":\n",
    "            channels = self.build_channels(t_ns, dtof_log, cfg[\"channel_mode\"])  # (N,C,T)\n",
    "\n",
    "        elif input_rep == \"raw_log\":\n",
    "            ch_raw = self.build_channels(t_ns, dtof_raw, cfg[\"channel_mode\"])    # (N,C,T)\n",
    "            ch_log = self.build_channels(t_ns, dtof_log, cfg[\"channel_mode\"])    # (N,C,T)\n",
    "            channels = np.concatenate([ch_raw, ch_log], axis=1)                  # (N,2C,T)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown input_rep: {input_rep}\")\n",
    "\n",
    "        # ---------- to torch ----------\n",
    "        self.signals = torch.tensor(channels, dtype=torch.float32)  # (N,C,T)\n",
    "        self.labels = torch.tensor(y, dtype=torch.float32)          # (N,2)\n",
    "\n",
    "        self.N, self.C, self.T = self.signals.shape\n",
    "\n",
    "    def build_channels(self, t_ns: np.ndarray, dtof: np.ndarray, mode: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Channel masks in ns:\n",
    "            early: 0–0.5 ns\n",
    "            mid:   0.5–4 ns\n",
    "            late:  4–crop_t_max ns\n",
    "        \"\"\"\n",
    "        N, T = dtof.shape\n",
    "        crop_t_max = float(self.cfg[\"crop_t_max\"])\n",
    "\n",
    "        if mode == \"single\":\n",
    "            return dtof[:, None, :]  # (N,1,T)\n",
    "\n",
    "        early = ((t_ns >= 0.0) & (t_ns < 0.5)).astype(np.float32)\n",
    "        mid   = ((t_ns >= 0.5) & (t_ns < 4.0)).astype(np.float32)\n",
    "        late  = ((t_ns >= 4.0) & (t_ns <= crop_t_max)).astype(np.float32)\n",
    "\n",
    "        masks = np.stack([early, mid, late], axis=0)  # (3,T)\n",
    "\n",
    "        if mode == \"early_mid_late\":\n",
    "            return dtof[:, None, :] * masks[None, :, :]  # (N,3,T)\n",
    "\n",
    "        if mode == \"hybrid_4ch\":\n",
    "            full = dtof[:, None, :]                         # (N,1,T)\n",
    "            gated = dtof[:, None, :] * masks[None, :, :]    # (N,3,T)\n",
    "            return np.concatenate([full, gated], axis=1)    # (N,4,T)\n",
    "\n",
    "        raise ValueError(f\"Unknown channel_mode: {mode}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.signals[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e584e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN for 1D DTOF signals with flexible input channels.\n",
    "\n",
    "    Channel counts (C) depend on:\n",
    "        channel_mode:\n",
    "            - \"single\"         -> 1\n",
    "            - \"early_mid_late\" -> 3\n",
    "            - \"hybrid_4ch\"     -> 4\n",
    "        input_rep:\n",
    "            - \"raw\" / \"log\"    -> multiplier 1\n",
    "            - \"raw_log\"        -> multiplier 2\n",
    "\n",
    "    So:\n",
    "        C = base_C * (2 if input_rep == \"raw_log\" else 1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg: dict, input_length: int = 3000, output_dim: int = 2):\n",
    "        super().__init__()\n",
    "\n",
    "        base_C = {\"single\": 1, \"early_mid_late\": 3, \"hybrid_4ch\": 4}[cfg[\"channel_mode\"]]\n",
    "        mult = 2 if cfg.get(\"input_rep\", \"log\") == \"raw_log\" else 1\n",
    "        in_channels = base_C * mult\n",
    "\n",
    "        # Convolution blocks\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=32, kernel_size=7, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(16)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        # Compute flattened feature size dynamically\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, input_length)\n",
    "            feat = self._forward_features(dummy)\n",
    "            self.flatten_dim = feat.shape[1]\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        # Block 1\n",
    "        x = self.pool1(self.act(self.bn1(self.conv1(x))))\n",
    "        # Block 2\n",
    "        x = self.pool2(self.act(self.bn2(self.conv2(x))))\n",
    "        # Block 3\n",
    "        x = self.pool3(self.act(self.bn3(self.conv3(x))))\n",
    "        # Flatten\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a581ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    save_path=None,\n",
    "    eps=1e-12,\n",
    "    print_every=1,\n",
    "    exp_clip=20.0,   # exp(20) ~ 4.85e8, safety for overflow\n",
    "):\n",
    "    model.to(device)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # -------------------------\n",
    "        # TRAIN\n",
    "        # -------------------------\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        tr_sum_sq = torch.zeros(2, device=device)\n",
    "        tr_count = 0\n",
    "\n",
    "        for signals, labels in train_loader:\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device).float()                 # (B,2)\n",
    "\n",
    "            log_labels = torch.log(labels.clamp_min(eps))      # (B,2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds_log = model(signals).view_as(log_labels)     # (B,2)\n",
    "            loss = loss_fn(preds_log, log_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # RMSE in original units\n",
    "            with torch.no_grad():\n",
    "                preds_lin = torch.exp(preds_log.clamp(-exp_clip, exp_clip))\n",
    "                err = preds_lin - labels\n",
    "                tr_sum_sq += (err ** 2).sum(dim=0)\n",
    "                tr_count += labels.shape[0]\n",
    "\n",
    "        train_loss = running_loss / max(1, len(train_loader))\n",
    "        train_rmse = torch.sqrt(tr_sum_sq / max(1, tr_count)).detach().cpu().numpy()\n",
    "\n",
    "        # -------------------------\n",
    "        # VALIDATE\n",
    "        # -------------------------\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "\n",
    "        va_sum_sq = torch.zeros(2, device=device)\n",
    "        va_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in val_loader:\n",
    "                signals = signals.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                log_labels = torch.log(labels.clamp_min(eps))\n",
    "                preds_log = model(signals).view_as(log_labels)\n",
    "\n",
    "                loss = loss_fn(preds_log, log_labels)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "                preds_lin = torch.exp(preds_log.clamp(-exp_clip, exp_clip))\n",
    "                err = preds_lin - labels\n",
    "                va_sum_sq += (err ** 2).sum(dim=0)\n",
    "                va_count += labels.shape[0]\n",
    "\n",
    "        val_loss = val_running_loss / max(1, len(val_loader))\n",
    "        val_rmse = torch.sqrt(va_sum_sq / max(1, va_count)).detach().cpu().numpy()\n",
    "\n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "            print(f\"Train Loss (log-MSE): {train_loss:.6f} | Train RMSE [mua, mus]: {train_rmse}\")\n",
    "            print(f\"Val   Loss (log-MSE): {val_loss:.6f} | Val   RMSE [mua, mus]: {val_rmse}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            if save_path is not None:\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\" -> Best validation so far, saved.\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1bb93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_val_loaders(dataset, batch_size=32, val_frac=0.2, seed=42, shuffle_train=True):\n",
    "    n = len(dataset)\n",
    "    idx = np.arange(n)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    split = int(n * (1 - val_frac))\n",
    "    train_idx = idx[:split]\n",
    "    val_idx = idx[split:]\n",
    "\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle_train)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5483d70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: torch.Size([8, 3000]) torch.Size([2])\n",
      "model out: torch.Size([1, 2])\n",
      "signals: torch.Size([32, 8, 3000])\n",
      "labels: torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "# Trial run\n",
    "\n",
    "matlab_path = \"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/Pre-obtained data/dataset_homo_small.mat\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = {\n",
    "        \"crop_t_max\": 6.0,\n",
    "        \"sg_window\": frame_length,\n",
    "        \"sg_order\": order,\n",
    "        \"eps\": 1e-12,\n",
    "        \"channel_mode\": \"hybrid_4ch\",  # \"single\" | \"early_mid_late\" | \"hybrid_4ch\"\n",
    "        \"input_rep\": \"raw_log\",        # \"raw\" | \"log\" | \"raw_log\"\n",
    "    }\n",
    "\n",
    "    ds = DTOFDataset(matlab_path, cfg)\n",
    "    x, y = ds[0]\n",
    "    print(\"sample:\", x.shape, y.shape)\n",
    "\n",
    "    model = Net(cfg, input_length=ds.T, output_dim=2).to(device)\n",
    "    out = model(x.unsqueeze(0))\n",
    "    print(\"model out:\", out.shape)\n",
    "\n",
    "    train_loader, val_loader = make_train_val_loaders(ds, batch_size=32, val_frac=0.2, seed=42)\n",
    "\n",
    "    signals, labels = next(iter(train_loader))\n",
    "    print(\"signals:\", signals.shape)  # (B, C, T)\n",
    "    print(\"labels:\", labels.shape)    # (B, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "414ed861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator: \n",
    "    \"\"\"\n",
    "    Evaluates a trained model that outputs log(mua), log(mus).\n",
    "    Reports MAE/RMSE in original units by exp().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, device, eps=1e-12):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.eps = eps\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        all_preds_lin = []\n",
    "        all_labels_lin = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in data_loader:\n",
    "                signals = signals.to(self.device)\n",
    "                labels = labels.to(self.device).float()              # (B,2) linear\n",
    "\n",
    "                preds_log = self.model(signals)                      # (B,2) log\n",
    "                preds_log = preds_log.view_as(labels)\n",
    "\n",
    "                preds_lin = torch.exp(preds_log)                     # back to linear\n",
    "\n",
    "                all_preds_lin.append(preds_lin.cpu())\n",
    "                all_labels_lin.append(labels.cpu())\n",
    "\n",
    "        preds = torch.cat(all_preds_lin, dim=0)\n",
    "        labs  = torch.cat(all_labels_lin, dim=0)\n",
    "\n",
    "        abs_err = torch.abs(preds - labs)\n",
    "        sq_err  = (preds - labs) ** 2\n",
    "\n",
    "        mae = abs_err.mean(dim=0)\n",
    "        rmse = torch.sqrt(sq_err.mean(dim=0))\n",
    "\n",
    "        return {\n",
    "            \"MAE\": mae.numpy(),\n",
    "            \"RMSE\": rmse.numpy(),\n",
    "            \"preds\": preds.numpy(),\n",
    "            \"labels\": labs.numpy(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5b12fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length =21 \n",
    "order = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15bd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Total samples: 500\n",
      "Train samples: 400\n",
      "Val samples  : 100\n",
      "Signal shape : torch.Size([8, 3000]) Label shape: torch.Size([2])\n",
      "Pre-train RMSE train [mua, mus]: [ 0.8705639 13.795304 ]\n",
      "Pre-train RMSE val   [mua, mus]: [ 0.88881505 13.737743  ]\n",
      "\n",
      "Epoch 1/3\n",
      "Train Loss (log-MSE): 2.147514 | Train RMSE [mua, mus]: [ 0.26125002 20.974863  ]\n",
      "Val   Loss (log-MSE): 3.363873 | Val   RMSE [mua, mus]: [ 0.17471175 12.410777  ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 2/3\n",
      "Train Loss (log-MSE): 0.292014 | Train RMSE [mua, mus]: [0.01910768 7.4966664 ]\n",
      "Val   Loss (log-MSE): 0.767043 | Val   RMSE [mua, mus]: [0.05236467 9.308151  ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 3/3\n",
      "Train Loss (log-MSE): 0.197030 | Train RMSE [mua, mus]: [0.01426826 4.5020103 ]\n",
      "Val   Loss (log-MSE): 0.517796 | Val   RMSE [mua, mus]: [0.03221161 5.2897    ]\n",
      " -> Best validation so far, saved.\n",
      "Post-train RMSE train [mua, mus]: [0.03507379 5.1658125 ]\n",
      "Post-train RMSE val   [mua, mus]: [0.03221161 5.2897    ]\n",
      "One-batch:\n",
      "  signals: torch.Size([32, 8, 3000])\n",
      "  labels : torch.Size([32, 2])\n",
      "  output : torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# TRIAL RUN\n",
    "# dataset -> split -> 1-3 epochs -> metrics sanity checks\n",
    "# ============================\n",
    "\n",
    "# Assumes these are already defined in your script:\n",
    "# - DTOFDataset (h5py loader, channel_mode + input_rep)\n",
    "# - Net (in_channels inferred from cfg)\n",
    "# - train_model (your log-label training loop)\n",
    "\n",
    "\n",
    "def make_train_val_loaders(dataset, batch_size=32, val_frac=0.2, seed=42):\n",
    "    n = len(dataset)\n",
    "    idx = np.arange(n)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    split = int(n * (1 - val_frac))\n",
    "    train_idx = idx[:split]\n",
    "    val_idx = idx[split:]\n",
    "\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def quick_eval_lin_rmse(model, loader, device, eps=1e-12, exp_clip=20.0):\n",
    "    \"\"\"Compute RMSE in original units on a loader (model outputs log-space).\"\"\"\n",
    "    model.eval()\n",
    "    sum_sq = torch.zeros(2, device=device)\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).float()  # linear labels\n",
    "            ylog = torch.log(y.clamp_min(eps))\n",
    "            plog = model(x).view_as(ylog)\n",
    "            plin = torch.exp(plog.clamp(-exp_clip, exp_clip))\n",
    "            err = plin - y\n",
    "            sum_sq += (err ** 2).sum(dim=0)\n",
    "            n += y.shape[0]\n",
    "    return torch.sqrt(sum_sq / max(1, n)).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Paths + config\n",
    "# ----------------------------\n",
    "mat_path = r\"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/Pre-obtained data/dataset_homo_small.mat\"\n",
    "\n",
    "cfg = {\n",
    "    \"crop_t_max\": 6.0,            # ns\n",
    "    \"sg_window\": 21,\n",
    "    \"sg_order\": 1,\n",
    "    \"eps\": 1e-12,\n",
    "    \"channel_mode\": \"hybrid_4ch\", # \"single\" | \"early_mid_late\" | \"hybrid_4ch\"\n",
    "    \"input_rep\": \"raw_log\",       # \"raw\" | \"log\" | \"raw_log\"\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Device\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Dataset + split\n",
    "# ----------------------------\n",
    "dataset = DTOFDataset(mat_path, cfg)\n",
    "train_loader, val_loader = make_train_val_loaders(dataset, batch_size=32, val_frac=0.2, seed=42)\n",
    "\n",
    "print(\"Total samples:\", len(dataset))\n",
    "print(\"Train samples:\", len(train_loader.dataset))\n",
    "print(\"Val samples  :\", len(val_loader.dataset))\n",
    "print(\"Signal shape :\", dataset[0][0].shape, \"Label shape:\", dataset[0][1].shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Model + optimizer\n",
    "# ----------------------------\n",
    "model = Net(cfg, input_length=dataset.T, output_dim=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Pre-train sanity RMSE (random model)\n",
    "# ----------------------------\n",
    "rmse0_train = quick_eval_lin_rmse(model, train_loader, device, eps=cfg[\"eps\"])\n",
    "rmse0_val = quick_eval_lin_rmse(model, val_loader, device, eps=cfg[\"eps\"])\n",
    "print(\"Pre-train RMSE train [mua, mus]:\", rmse0_train)\n",
    "print(\"Pre-train RMSE val   [mua, mus]:\", rmse0_val)\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Trial training (few epochs)\n",
    "# ----------------------------\n",
    "_ = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=3,          # TRIAL RUN\n",
    "    device=device,\n",
    "    save_path=\"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/CNN_initial_saved_pytorch_model_weights/best_trial_TRIAL.pt\",\n",
    "    eps=cfg[\"eps\"],\n",
    "    print_every=1,\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Post-train sanity RMSE\n",
    "# ----------------------------\n",
    "rmse1_train = quick_eval_lin_rmse(model, train_loader, device, eps=cfg[\"eps\"])\n",
    "rmse1_val = quick_eval_lin_rmse(model, val_loader, device, eps=cfg[\"eps\"])\n",
    "print(\"Post-train RMSE train [mua, mus]:\", rmse1_train)\n",
    "print(\"Post-train RMSE val   [mua, mus]:\", rmse1_val)\n",
    "\n",
    "# ----------------------------\n",
    "# 8) One-batch forward shape check\n",
    "# ----------------------------\n",
    "signals, labels = next(iter(train_loader))\n",
    "out = model(signals.to(device))\n",
    "print(\"One-batch:\")\n",
    "print(\"  signals:\", signals.shape)   # (B,C,T)\n",
    "print(\"  labels :\", labels.shape)    # (B,2)\n",
    "print(\"  output :\", out.shape)       # (B,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908676a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
