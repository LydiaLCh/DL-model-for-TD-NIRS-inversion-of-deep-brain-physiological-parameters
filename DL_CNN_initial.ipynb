{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b73156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import random \n",
    "import torch \n",
    "from torch import nn \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset, DataLoader,Subset\n",
    "from scipy.signal import savgol_filter \n",
    "import h5py\n",
    "random.seed(0)\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18ef4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Savitzky Golay filter parameters \n",
    "order = 1\n",
    "frame_length = 21\n",
    "eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b40d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b358256",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTOFDataset(Dataset):\n",
    "    \"\"\"\n",
    "        DTOF dataset for MATLAB v7.3 (.mat, HDF5) files.\n",
    "\n",
    "        Required datasets inside .mat:\n",
    "            X : (Nt, N) or (N, Nt)  reflectance DTOFs\n",
    "            y : (2, N)  or (N, 2)   [mua, mus']\n",
    "            t : (Nt,)              time vector in seconds (~1e-12 resolution)\n",
    "\n",
    "        Preprocessing:\n",
    "            - convert t from seconds -> ns\n",
    "            - crop [0, crop_t_max] ns\n",
    "            - Savitzky–Golay smoothing\n",
    "            - clip small values to eps\n",
    "            - input representation:\n",
    "                * \"raw\"      -> use reflectance (smoothed+clipped)\n",
    "                * \"log\"      -> use log(reflectance)\n",
    "                * \"raw_log\"  -> concatenate raw and log along channel dimension\n",
    "            - channel construction:\n",
    "                * \"single\"         -> 1 channel (full)\n",
    "                * \"early_mid_late\" -> 3 channels (early/mid/late masks)\n",
    "                * \"hybrid_4ch\"     -> 4 channels (full + early/mid/late masks)\n",
    "\n",
    "        Returns:\n",
    "            signal: (C, T) float32 tensor\n",
    "            label:  (2,) float32 tensor [mua, mus']  (raw labels for now)\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, mat_path: str, cfg: dict):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # ---------- load HDF5 (.mat v7.3) ----------\n",
    "        with h5py.File(mat_path, \"r\") as f:\n",
    "            X = np.array(f[\"X\"], dtype=np.float32)\n",
    "            y = np.array(f[\"y\"], dtype=np.float32)\n",
    "            t = np.array(f[\"t\"], dtype=np.float32).squeeze()\n",
    "\n",
    "        # ---------- normalise shapes ----------\n",
    "        # X -> (N, Nt)\n",
    "        if X.shape[0] == t.shape[0]:\n",
    "            X = X.T\n",
    "\n",
    "        # y -> (N, 2)\n",
    "        if y.shape[0] == 2:\n",
    "            y = y.T\n",
    "\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError(f\"Expected X to be 2D, got {X.shape}\")\n",
    "        if y.ndim != 2 or y.shape[1] != 2:\n",
    "            raise ValueError(f\"Expected y to be (N,2), got {y.shape}\")\n",
    "        if t.ndim != 1:\n",
    "            raise ValueError(f\"Expected t to be (Nt,), got {t.shape}\")\n",
    "        if X.shape[1] != t.shape[0]:\n",
    "            raise ValueError(f\"X and t mismatch: X Nt={X.shape[1]} vs t Nt={t.shape[0]}\")\n",
    "\n",
    "        # ---------- time: seconds -> ns ----------\n",
    "        t_ns = t * 1e9\n",
    "\n",
    "        # ---------- crop ----------\n",
    "        crop_t_max = float(cfg[\"crop_t_max\"])  # ns\n",
    "        t_mask = (t_ns >= 0.0) & (t_ns <= crop_t_max)\n",
    "        if not np.any(t_mask):\n",
    "            raise ValueError(\n",
    "                f\"Cropping removed all points. \"\n",
    "                f\"t_ns range=[{t_ns.min():.3g}, {t_ns.max():.3g}] ns, crop_t_max={crop_t_max}\"\n",
    "            )\n",
    "\n",
    "        t_ns = t_ns[t_mask]              # (T,)\n",
    "        dtof = X[:, t_mask]              # (N,T)\n",
    "\n",
    "        N, T = dtof.shape\n",
    "\n",
    "        # ---------- Savitzky–Golay ----------\n",
    "        sg_window = int(cfg[\"sg_window\"])\n",
    "        sg_order = int(cfg[\"sg_order\"])\n",
    "\n",
    "        # enforce validity (odd, > order, <= T)\n",
    "        if sg_window % 2 == 0:\n",
    "            sg_window += 1\n",
    "        if sg_window <= sg_order:\n",
    "            sg_window = sg_order + 2\n",
    "            if sg_window % 2 == 0:\n",
    "                sg_window += 1\n",
    "        if sg_window > T:\n",
    "            sg_window = T if (T % 2 == 1) else (T - 1)\n",
    "\n",
    "        if sg_window >= 3:\n",
    "            dtof = savgol_filter(dtof, sg_window, sg_order, axis=1)\n",
    "\n",
    "        # ---------- clip ----------\n",
    "        eps = float(cfg.get(\"eps\", 1e-12))\n",
    "        dtof[dtof < eps] = eps\n",
    "\n",
    "        # ---------- choose representation ----------\n",
    "        input_rep = cfg.get(\"input_rep\", \"log\")  # \"raw\" | \"log\" | \"raw_log\"\n",
    "\n",
    "        dtof_raw = dtof.astype(np.float32)\n",
    "        dtof_log = np.log(dtof_raw).astype(np.float32)\n",
    "\n",
    "        # ---------- build channels ----------\n",
    "        if input_rep == \"raw\":\n",
    "            channels = self.build_channels(t_ns, dtof_raw, cfg[\"channel_mode\"])  # (N,C,T)\n",
    "\n",
    "        elif input_rep == \"log\":\n",
    "            channels = self.build_channels(t_ns, dtof_log, cfg[\"channel_mode\"])  # (N,C,T)\n",
    "\n",
    "        elif input_rep == \"raw_log\":\n",
    "            ch_raw = self.build_channels(t_ns, dtof_raw, cfg[\"channel_mode\"])    # (N,C,T)\n",
    "            ch_log = self.build_channels(t_ns, dtof_log, cfg[\"channel_mode\"])    # (N,C,T)\n",
    "            channels = np.concatenate([ch_raw, ch_log], axis=1)                  # (N,2C,T)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown input_rep: {input_rep}\")\n",
    "\n",
    "        # ---------- to torch ----------\n",
    "        self.signals = torch.tensor(channels, dtype=torch.float32)  # (N,C,T)\n",
    "        self.labels = torch.tensor(y, dtype=torch.float32)          # (N,2)\n",
    "\n",
    "        self.N, self.C, self.T = self.signals.shape\n",
    "\n",
    "    def build_channels(self, t_ns: np.ndarray, dtof: np.ndarray, mode: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Channel masks in ns:\n",
    "            early: 0–0.5 ns\n",
    "            mid:   0.5–4 ns\n",
    "            late:  4–crop_t_max ns\n",
    "        \"\"\"\n",
    "        N, T = dtof.shape\n",
    "        crop_t_max = float(self.cfg[\"crop_t_max\"])\n",
    "\n",
    "        if mode == \"single\":\n",
    "            return dtof[:, None, :]  # (N,1,T)\n",
    "\n",
    "        early = ((t_ns >= 0.0) & (t_ns < 0.5)).astype(np.float32)\n",
    "        mid   = ((t_ns >= 0.5) & (t_ns < 4.0)).astype(np.float32)\n",
    "        late  = ((t_ns >= 4.0) & (t_ns <= crop_t_max)).astype(np.float32)\n",
    "\n",
    "        masks = np.stack([early, mid, late], axis=0)  # (3,T)\n",
    "\n",
    "        if mode == \"early_mid_late\":\n",
    "            return dtof[:, None, :] * masks[None, :, :]  # (N,3,T)\n",
    "\n",
    "        if mode == \"hybrid_4ch\":\n",
    "            full = dtof[:, None, :]                         # (N,1,T)\n",
    "            gated = dtof[:, None, :] * masks[None, :, :]    # (N,3,T)\n",
    "            return np.concatenate([full, gated], axis=1)    # (N,4,T)\n",
    "\n",
    "        raise ValueError(f\"Unknown channel_mode: {mode}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.signals[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e584e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN for 1D DTOF signals with flexible input channels.\n",
    "\n",
    "    Channel counts (C) depend on:\n",
    "        channel_mode:\n",
    "            - \"single\"         -> 1\n",
    "            - \"early_mid_late\" -> 3\n",
    "            - \"hybrid_4ch\"     -> 4\n",
    "        input_rep:\n",
    "            - \"raw\" / \"log\"    -> multiplier 1\n",
    "            - \"raw_log\"        -> multiplier 2\n",
    "\n",
    "    So:\n",
    "        C = base_C * (2 if input_rep == \"raw_log\" else 1)\n",
    "\n",
    "    Optional tunables in cfg:\n",
    "        cfg[\"use_dilation\"] = True / False\n",
    "        cfg[\"kernels\"]      = [3, 5, 5]      # keep final kernel smaller to reduce over-smoothing\n",
    "        cfg[\"dilations\"]    = [1, 2, 4]      # increasing dilation expands receptive field\n",
    "        cfg[\"channels\"]     = [32, 32, 16]   # out_channels per block\n",
    "        cfg[\"pool_k\"]       = 2              # MaxPool kernel\n",
    "        cfg[\"pool_s\"]       = 2              # MaxPool stride\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg: dict, input_length: int = 3000, output_dim: int = 2):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # -----------------------------\n",
    "        # Infer input channels from cfg\n",
    "        # -----------------------------\n",
    "        base_C = {\"single\": 1, \"early_mid_late\": 3, \"hybrid_4ch\": 4}[cfg[\"channel_mode\"]]\n",
    "        mult = 2 if cfg.get(\"input_rep\", \"log\") == \"raw_log\" else 1\n",
    "        in_channels = base_C * mult\n",
    "\n",
    "        # -----------------------------\n",
    "        # Optional dilation settings\n",
    "        # -----------------------------\n",
    "        use_dilation = bool(cfg.get(\"use_dilation\", False))\n",
    "\n",
    "        # Kernels: increasing early->late but keep the final kernel modest\n",
    "        kernels = cfg.get(\"kernels\", [3, 5, 5])\n",
    "\n",
    "        # Dilations: increase only when use_dilation=True\n",
    "        dilations = cfg.get(\"dilations\", [1, 2, 4]) if use_dilation else [1, 1, 1]\n",
    "\n",
    "        # Out channels per conv block\n",
    "        chs = cfg.get(\"channels\", [32, 32, 16])\n",
    "\n",
    "        # Pooling\n",
    "        pool_k = int(cfg.get(\"pool_k\", 2))\n",
    "        pool_s = int(cfg.get(\"pool_s\", 2))\n",
    "\n",
    "        # Unpack (THIS IS REQUIRED)\n",
    "        k1, k2, k3 = kernels\n",
    "        d1, d2, d3 = dilations\n",
    "\n",
    "        # -----------------------------\n",
    "        # Helper: SAME padding for 1D conv\n",
    "        # padding = dilation * (kernel - 1) / 2 (requires odd kernel)\n",
    "        # -----------------------------\n",
    "        def same_padding(kernel: int, dilation: int) -> int:\n",
    "            if kernel % 2 == 0:\n",
    "                raise ValueError(f\"Kernel size must be odd for SAME padding. Got kernel={kernel}.\")\n",
    "            return (dilation * (kernel - 1)) // 2\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convolution blocks\n",
    "        # -----------------------------\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=chs[0],\n",
    "            kernel_size=k1,\n",
    "            dilation=d1,\n",
    "            padding=same_padding(k1, d1),\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(chs[0])\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=pool_k, stride=pool_s)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=chs[0],\n",
    "            out_channels=chs[1],\n",
    "            kernel_size=k2,\n",
    "            dilation=d2,\n",
    "            padding=same_padding(k2, d2),\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(chs[1])\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=pool_k, stride=pool_s)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(\n",
    "            in_channels=chs[1],\n",
    "            out_channels=chs[2],\n",
    "            kernel_size=k3,\n",
    "            dilation=d3,\n",
    "            padding=same_padding(k3, d3),\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm1d(chs[2])\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=pool_k, stride=pool_s)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Dynamic flatten dimension\n",
    "        # -----------------------------\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, input_length)\n",
    "            feat = self._forward_features(dummy)\n",
    "            self.flatten_dim = feat.shape[1]\n",
    "\n",
    "        # -----------------------------\n",
    "        # Fully connected head\n",
    "        # -----------------------------\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def _forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool1(self.act(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(self.act(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(self.act(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self._forward_features(x)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a581ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    save_path=None,\n",
    "    eps=1e-12,\n",
    "    print_every=1,\n",
    "    exp_clip=20.0,   # exp(20) ~ 4.85e8, safety for overflow\n",
    "    patience = 20, \n",
    "    min_delta = 0.0, \n",
    "):\n",
    "    model.to(device)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # -------------------------\n",
    "        # TRAIN\n",
    "        # -------------------------\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        tr_sum_sq = torch.zeros(2, device=device)\n",
    "        tr_count = 0\n",
    "\n",
    "        for signals, labels in train_loader:\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device).float()                 # (B,2)\n",
    "\n",
    "            log_labels = torch.log(labels.clamp_min(eps))      # (B,2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds_log = model(signals).view_as(log_labels)     # (B,2)\n",
    "            loss = loss_fn(preds_log, log_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # RMSE in original units\n",
    "            with torch.no_grad():\n",
    "                preds_lin = torch.exp(preds_log.clamp(-exp_clip, exp_clip))\n",
    "                err = preds_lin - labels\n",
    "                tr_sum_sq += (err ** 2).sum(dim=0)\n",
    "                tr_count += labels.shape[0]\n",
    "\n",
    "        train_loss = running_loss / max(1, len(train_loader))\n",
    "        train_rmse = torch.sqrt(tr_sum_sq / max(1, tr_count)).detach().cpu().numpy()\n",
    "\n",
    "        # -------------------------\n",
    "        # VALIDATE\n",
    "        # -------------------------\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "\n",
    "        va_sum_sq = torch.zeros(2, device=device)\n",
    "        va_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in val_loader:\n",
    "                signals = signals.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                log_labels = torch.log(labels.clamp_min(eps))\n",
    "                preds_log = model(signals).view_as(log_labels)\n",
    "\n",
    "                loss = loss_fn(preds_log, log_labels)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "                preds_lin = torch.exp(preds_log.clamp(-exp_clip, exp_clip))\n",
    "                err = preds_lin - labels\n",
    "                va_sum_sq += (err ** 2).sum(dim=0)\n",
    "                va_count += labels.shape[0]\n",
    "\n",
    "        val_loss = val_running_loss / max(1, len(val_loader))\n",
    "        val_rmse = torch.sqrt(va_sum_sq / max(1, va_count)).detach().cpu().numpy()\n",
    "\n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "            print(f\"Train Loss (log-MSE): {train_loss:.6f} | Train RMSE [mua, mus]: {train_rmse}\")\n",
    "            print(f\"Val   Loss (log-MSE): {val_loss:.6f} | Val   RMSE [mua, mus]: {val_rmse}\")\n",
    "\n",
    "        if val_loss < (best_val_loss - min_delta):\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            if save_path is not None:\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\" -> Best validation so far, saved.\")\n",
    "            else: \n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience: \n",
    "                    print(f\"\\nEarly stopping at epoch {epoch + 1}:\"\n",
    "                          f\"no val improvement for {patience} epochs.\")\n",
    "                    break\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1bb93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_val_loaders(dataset, batch_size=32, val_frac=0.2, seed=42, shuffle_train=True):\n",
    "    n = len(dataset)\n",
    "    idx = np.arange(n)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    split = int(n * (1 - val_frac))\n",
    "    train_idx = idx[:split]\n",
    "    val_idx = idx[split:]\n",
    "\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle_train)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5483d70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dilation enabled: True\n",
      "kernels: [3, 5, 5] dilations: [1, 2, 4]\n",
      "sample: torch.Size([8, 3000]) torch.Size([2])\n",
      "model out: torch.Size([1, 2])\n",
      "signals: torch.Size([32, 8, 3000])\n",
      "labels: torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "# Trial run\n",
    "\n",
    "matlab_path = \"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/Pre-obtained data/dataset_homo_small.mat\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = {\n",
    "        \"crop_t_max\": 6.0,\n",
    "        \"sg_window\": frame_length,\n",
    "        \"sg_order\": order,\n",
    "        \"eps\": 1e-12,\n",
    "        \"channel_mode\": \"hybrid_4ch\",  # \"single\" | \"early_mid_late\" | \"hybrid_4ch\"\n",
    "        \"input_rep\": \"raw_log\",        # \"raw\" | \"log\" | \"raw_log\"\n",
    "\n",
    "        # ---- OPTIONAL DILATION EXPERIMENT ----\n",
    "        \"use_dilation\": True,          # <-- set False for baseline comparison\n",
    "        \"kernels\": [3, 5, 5],          # increasing kernels but smaller final kernel\n",
    "        \"dilations\": [1, 2, 4],        # increasing dilation\n",
    "        \"channels\": [32, 32, 16],      # optional: keep your original channels\n",
    "        \"pool_k\": 2,\n",
    "        \"pool_s\": 2,\n",
    "    }\n",
    "\n",
    "    print(\"Dilation enabled:\", cfg[\"use_dilation\"])\n",
    "    if cfg[\"use_dilation\"]:\n",
    "        print(\"kernels:\", cfg[\"kernels\"], \"dilations:\", cfg[\"dilations\"])\n",
    "\n",
    "    # Dataset sanity check \n",
    "\n",
    "    ds = DTOFDataset(matlab_path, cfg)\n",
    "    x, y = ds[0]\n",
    "    print(\"sample:\", x.shape, y.shape)\n",
    "\n",
    "    # Model sanity check\n",
    "\n",
    "    model = Net(cfg, input_length=ds.T, output_dim=2).to(device)\n",
    "    x = x.to(device)\n",
    "    out = model(x.unsqueeze(0))\n",
    "    print(\"model out:\", out.shape)\n",
    "\n",
    "    # Loader sanity check \n",
    "    \n",
    "    train_loader, val_loader = make_train_val_loaders(ds, batch_size=32, val_frac=0.2, seed=42)\n",
    "\n",
    "    signals, labels = next(iter(train_loader))\n",
    "    print(\"signals:\", signals.shape)  # (B, C, T)\n",
    "    print(\"labels:\", labels.shape)    # (B, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "414ed861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator: \n",
    "    \"\"\"\n",
    "    Evaluates a trained model that outputs log(mua), log(mus).\n",
    "    Reports MAE/RMSE in original units by exp().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, device, eps=1e-12):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.eps = eps\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        all_preds_lin = []\n",
    "        all_labels_lin = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in data_loader:\n",
    "                signals = signals.to(self.device)\n",
    "                labels = labels.to(self.device).float()              # (B,2) linear\n",
    "\n",
    "                preds_log = self.model(signals)                      # (B,2) log\n",
    "                preds_log = preds_log.view_as(labels)\n",
    "\n",
    "                preds_lin = torch.exp(preds_log)                     # back to linear\n",
    "\n",
    "                all_preds_lin.append(preds_lin.cpu())\n",
    "                all_labels_lin.append(labels.cpu())\n",
    "\n",
    "        preds = torch.cat(all_preds_lin, dim=0)\n",
    "        labs  = torch.cat(all_labels_lin, dim=0)\n",
    "\n",
    "        abs_err = torch.abs(preds - labs)\n",
    "        sq_err  = (preds - labs) ** 2\n",
    "\n",
    "        mae = abs_err.mean(dim=0)\n",
    "        rmse = torch.sqrt(sq_err.mean(dim=0))\n",
    "\n",
    "        return {\n",
    "            \"MAE\": mae.numpy(),\n",
    "            \"RMSE\": rmse.numpy(),\n",
    "            \"preds\": preds.numpy(),\n",
    "            \"labels\": labs.numpy(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15bd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Total samples: 500\n",
      "Train samples: 400\n",
      "Val samples  : 100\n",
      "Signal shape : torch.Size([8, 3000]) Label shape: torch.Size([2])\n",
      "steps_per_epoch: 13\n",
      "target_steps   : 50000\n",
      "num_epochs     : 800\n",
      "\n",
      "======================================================================\n",
      "EXPERIMENT: baseline_no_dilation\n",
      "use_dilation=False | kernels=[3, 5, 5] | dilations=[1, 2, 4]\n",
      "======================================================================\n",
      "Pre-train RMSE train [mua, mus]: [ 2.0325139 13.771048 ]\n",
      "Pre-train RMSE val   [mua, mus]: [ 1.8580582 13.71551  ]\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# RUN SCRIPT (baseline vs dilated) + auto epoch scheduling + early stopping\n",
    "# ============================\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def make_train_val_loaders(dataset, batch_size=32, val_frac=0.2, seed=42):\n",
    "    n = len(dataset)\n",
    "    idx = np.arange(n)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    split = int(n * (1 - val_frac))\n",
    "    train_idx = idx[:split]\n",
    "    val_idx = idx[split:]\n",
    "\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def quick_eval_lin_rmse(model, loader, device, eps=1e-12, exp_clip=20.0):\n",
    "    \"\"\"Compute RMSE in original units (model outputs log-space).\"\"\"\n",
    "    model.eval()\n",
    "    sum_sq = torch.zeros(2, device=device)\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).float()\n",
    "            ylog = torch.log(y.clamp_min(eps))\n",
    "            plog = model(x).view_as(ylog)\n",
    "            plin = torch.exp(plog.clamp(-exp_clip, exp_clip))\n",
    "            err = plin - y\n",
    "            sum_sq += (err ** 2).sum(dim=0)\n",
    "            n += y.shape[0]\n",
    "    return torch.sqrt(sum_sq / max(1, n)).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Paths + base config\n",
    "# ----------------------------\n",
    "mat_path = r\"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/Pre-obtained data/dataset_homo_small.mat\"\n",
    "\n",
    "base_cfg = {\n",
    "    \"crop_t_max\": 6.0,\n",
    "    \"sg_window\": 21,\n",
    "    \"sg_order\": 1,\n",
    "    \"eps\": 1e-12,\n",
    "    \"channel_mode\": \"hybrid_4ch\",\n",
    "    \"input_rep\": \"raw_log\",\n",
    "\n",
    "    # ---- DILATION EXPERIMENT DEFAULTS (OFF unless enabled below) ----\n",
    "    \"use_dilation\": False,\n",
    "    \"kernels\": [3, 5, 5],      # increasing kernels, smaller final kernel\n",
    "    \"dilations\": [1, 2, 4],    # increasing dilation (only used if use_dilation=True)\n",
    "    \"channels\": [32, 32, 16],\n",
    "    \"pool_k\": 2,\n",
    "    \"pool_s\": 2,\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Device\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Dataset + split (DO THIS ONCE so both models share identical split)\n",
    "# ----------------------------\n",
    "dataset = DTOFDataset(mat_path, base_cfg)\n",
    "\n",
    "batch_size = 32\n",
    "val_frac = 0.2\n",
    "seed = 42\n",
    "\n",
    "train_loader, val_loader = make_train_val_loaders(dataset, batch_size=batch_size, val_frac=val_frac, seed=seed)\n",
    "\n",
    "N_total = len(dataset)\n",
    "N_train = len(train_loader.dataset)\n",
    "N_val = len(val_loader.dataset)\n",
    "\n",
    "print(\"Total samples:\", N_total)\n",
    "print(\"Train samples:\", N_train)\n",
    "print(\"Val samples  :\", N_val)\n",
    "print(\"Signal shape :\", dataset[0][0].shape, \"Label shape:\", dataset[0][1].shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Epoch scheduling (scaled by dataset size via target optimiser steps)\n",
    "# ----------------------------\n",
    "target_steps = 50_000  # adjust later\n",
    "steps_per_epoch = math.ceil(N_train / batch_size)\n",
    "num_epochs = math.ceil(target_steps / steps_per_epoch)\n",
    "\n",
    "# Optional cap (if you want a hard max like 800)\n",
    "num_epochs = min(num_epochs, 800)\n",
    "\n",
    "print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "print(f\"target_steps   : {target_steps}\")\n",
    "print(f\"num_epochs     : {num_epochs}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Run function (so we can compare baseline vs dilated cleanly)\n",
    "# ----------------------------\n",
    "def run_experiment(cfg, tag):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"EXPERIMENT: {tag}\")\n",
    "    print(f\"use_dilation={cfg.get('use_dilation', False)} | kernels={cfg.get('kernels')} | dilations={cfg.get('dilations')}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    model = Net(cfg, input_length=dataset.T, output_dim=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Pre-train sanity RMSE\n",
    "    rmse0_train = quick_eval_lin_rmse(model, train_loader, device, eps=cfg[\"eps\"])\n",
    "    rmse0_val = quick_eval_lin_rmse(model, val_loader, device, eps=cfg[\"eps\"])\n",
    "    print(\"Pre-train RMSE train [mua, mus]:\", rmse0_train)\n",
    "    print(\"Pre-train RMSE val   [mua, mus]:\", rmse0_val)\n",
    "\n",
    "    save_path = f\"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/CNN_initial_saved_pytorch_model_weights/best_{tag}.pt\"\n",
    "\n",
    "    _ = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device,\n",
    "        save_path=save_path,\n",
    "        eps=cfg[\"eps\"],\n",
    "        print_every=1,\n",
    "        # if your train_model includes early stopping:\n",
    "        patience=20,\n",
    "        min_delta=1e-4,\n",
    "    )\n",
    "\n",
    "    # Post-train RMSE\n",
    "    rmse1_train = quick_eval_lin_rmse(model, train_loader, device, eps=cfg[\"eps\"])\n",
    "    rmse1_val = quick_eval_lin_rmse(model, val_loader, device, eps=cfg[\"eps\"])\n",
    "    print(\"Post-train RMSE train [mua, mus]:\", rmse1_train)\n",
    "    print(\"Post-train RMSE val   [mua, mus]:\", rmse1_val)\n",
    "\n",
    "    # One-batch forward shape check\n",
    "    signals, labels = next(iter(train_loader))\n",
    "    out = model(signals.to(device))\n",
    "    print(\"One-batch shapes:\")\n",
    "    print(\"  signals:\", signals.shape)\n",
    "    print(\"  labels :\", labels.shape)\n",
    "    print(\"  output :\", out.shape)\n",
    "\n",
    "    return {\n",
    "        \"tag\": tag,\n",
    "        \"rmse_train\": rmse1_train,\n",
    "        \"rmse_val\": rmse1_val,\n",
    "        \"save_path\": save_path,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Baseline vs Dilated configs\n",
    "# ----------------------------\n",
    "cfg_baseline = dict(base_cfg)\n",
    "cfg_baseline[\"use_dilation\"] = False\n",
    "\n",
    "cfg_dilated = dict(base_cfg)\n",
    "cfg_dilated[\"use_dilation\"] = True\n",
    "# kernels/dilations already present in base_cfg; tweak here if desired:\n",
    "# cfg_dilated[\"kernels\"] = [3, 5, 5]\n",
    "# cfg_dilated[\"dilations\"] = [1, 2, 4]\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Run both experiments\n",
    "# ----------------------------\n",
    "res_base = run_experiment(cfg_baseline, tag=\"baseline_no_dilation\")\n",
    "res_dil  = run_experiment(cfg_dilated,  tag=\"dilated_1_2_4\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY (Post-train RMSE)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Baseline RMSE val [mua, mus]:\", res_base[\"rmse_val\"])\n",
    "print(\"Dilated  RMSE val [mua, mus]:\", res_dil[\"rmse_val\"])\n",
    "print(\"=\" * 70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7485de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4) Model + optimizer\n",
    "# ----------------------------\n",
    "model = Net(cfg, input_length=dataset.T, output_dim=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Choose epochs based on target optimiser steps\n",
    "# ----------------------------\n",
    "target_steps = 50_000   # adjust later (e.g., 20k for quick, 100k+ for full)\n",
    "steps_per_epoch = math.ceil(N_train / batch_size)\n",
    "\n",
    "num_epochs = 80\n",
    "#num_epochs = math.ceil(target_steps / steps_per_epoch)\n",
    "\n",
    "print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "print(f\"target_steps   : {target_steps}\")\n",
    "print(f\"num_epochs     : {num_epochs}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Pre-train sanity RMSE (random model)\n",
    "# ----------------------------\n",
    "rmse0_train = quick_eval_lin_rmse(model, train_loader, device, eps=cfg[\"eps\"])\n",
    "rmse0_val = quick_eval_lin_rmse(model, val_loader, device, eps=cfg[\"eps\"])\n",
    "print(\"Pre-train RMSE train [mua, mus]:\", rmse0_train)\n",
    "print(\"Pre-train RMSE val   [mua, mus]:\", rmse0_val)\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Train\n",
    "# ----------------------------\n",
    "_ = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    save_path=\"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/CNN_initial_saved_pytorch_model_weights/best_trial_TRIAL.pt\",\n",
    "    eps=cfg[\"eps\"],\n",
    "    print_every=1,\n",
    "    # if you added early stopping:\n",
    "    # patience=20,\n",
    "    # min_delta=1e-4,\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 8) Post-train sanity RMSE\n",
    "# ----------------------------\n",
    "rmse1_train = quick_eval_lin_rmse(model, train_loader, device, eps=cfg[\"eps\"])\n",
    "rmse1_val = quick_eval_lin_rmse(model, val_loader, device, eps=cfg[\"eps\"])\n",
    "print(\"Post-train RMSE train [mua, mus]:\", rmse1_train)\n",
    "print(\"Post-train RMSE val   [mua, mus]:\", rmse1_val)\n",
    "\n",
    "# ----------------------------\n",
    "# 9) One-batch forward shape check\n",
    "# ----------------------------\n",
    "signals, labels = next(iter(train_loader))\n",
    "out = model(signals.to(device))\n",
    "print(\"One-batch:\")\n",
    "print(\"  signals:\", signals.shape)\n",
    "print(\"  labels :\", labels.shape)\n",
    "print(\"  output :\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908676a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
