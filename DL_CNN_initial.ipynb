{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b73156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import random \n",
    "import torch \n",
    "from torch import nn \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset, DataLoader,Subset\n",
    "from scipy.signal import savgol_filter \n",
    "import h5py\n",
    "random.seed(0)\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f18ef4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Savitzky Golay filter parameters \n",
    "order = 1\n",
    "frame_length = 21\n",
    "eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b40d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b358256",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTOFDataset(Dataset):\n",
    "    \"\"\"\n",
    "        DTOF dataset for MATLAB v7.3 (.mat, HDF5) files.\n",
    "\n",
    "        Required datasets inside .mat:\n",
    "            X : (Nt, N) or (N, Nt)  reflectance DTOFs\n",
    "            y : (2, N)  or (N, 2)   [mua, mus']\n",
    "            t : (Nt,)              time vector in seconds (~1e-12 resolution)\n",
    "\n",
    "        Preprocessing:\n",
    "            - convert t from seconds -> ns\n",
    "            - crop [0, crop_t_max] ns\n",
    "            - Savitzky–Golay smoothing\n",
    "            - clip small values to eps\n",
    "            - input representation:\n",
    "                * \"raw\"      -> use reflectance (smoothed+clipped)\n",
    "                * \"log\"      -> use log(reflectance)\n",
    "                * \"raw_log\"  -> concatenate raw and log along channel dimension\n",
    "            - channel construction:\n",
    "                * \"single\"         -> 1 channel (full)\n",
    "                * \"early_mid_late\" -> 3 channels (early/mid/late masks)\n",
    "                * \"hybrid_4ch\"     -> 4 channels (full + early/mid/late masks)\n",
    "\n",
    "        Returns:\n",
    "            signal: (C, T) float32 tensor\n",
    "            label:  (2,) float32 tensor [mua, mus']  (raw labels for now)\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, mat_path: str, cfg: dict):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # ---------- load HDF5 (.mat v7.3) ----------\n",
    "        with h5py.File(mat_path, \"r\") as f:\n",
    "            X = np.array(f[\"X\"], dtype=np.float32)\n",
    "            y = np.array(f[\"y\"], dtype=np.float32)\n",
    "            t = np.array(f[\"t\"], dtype=np.float32).squeeze()\n",
    "\n",
    "        # ---------- normalise shapes ----------\n",
    "        # X -> (N, Nt)\n",
    "        if X.shape[0] == t.shape[0]:\n",
    "            X = X.T\n",
    "\n",
    "        # y -> (N, 2)\n",
    "        if y.shape[0] == 2:\n",
    "            y = y.T\n",
    "\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError(f\"Expected X to be 2D, got {X.shape}\")\n",
    "        if y.ndim != 2 or y.shape[1] != 2:\n",
    "            raise ValueError(f\"Expected y to be (N,2), got {y.shape}\")\n",
    "        if t.ndim != 1:\n",
    "            raise ValueError(f\"Expected t to be (Nt,), got {t.shape}\")\n",
    "        if X.shape[1] != t.shape[0]:\n",
    "            raise ValueError(f\"X and t mismatch: X Nt={X.shape[1]} vs t Nt={t.shape[0]}\")\n",
    "\n",
    "        # ---------- time: seconds -> ns ----------\n",
    "        t_ns = t * 1e9\n",
    "\n",
    "        # ---------- crop ----------\n",
    "        crop_t_max = float(cfg[\"crop_t_max\"])  # ns\n",
    "        t_mask = (t_ns >= 0.0) & (t_ns <= crop_t_max)\n",
    "        if not np.any(t_mask):\n",
    "            raise ValueError(\n",
    "                f\"Cropping removed all points. \"\n",
    "                f\"t_ns range=[{t_ns.min():.3g}, {t_ns.max():.3g}] ns, crop_t_max={crop_t_max}\"\n",
    "            )\n",
    "\n",
    "        t_ns = t_ns[t_mask]              # (T,)\n",
    "        dtof = X[:, t_mask]              # (N,T)\n",
    "\n",
    "        N, T = dtof.shape\n",
    "\n",
    "        # ---------- Savitzky–Golay ----------\n",
    "        sg_window = int(cfg[\"sg_window\"])\n",
    "        sg_order = int(cfg[\"sg_order\"])\n",
    "\n",
    "        # enforce validity (odd, > order, <= T)\n",
    "        if sg_window % 2 == 0:\n",
    "            sg_window += 1\n",
    "        if sg_window <= sg_order:\n",
    "            sg_window = sg_order + 2\n",
    "            if sg_window % 2 == 0:\n",
    "                sg_window += 1\n",
    "        if sg_window > T:\n",
    "            sg_window = T if (T % 2 == 1) else (T - 1)\n",
    "\n",
    "        if sg_window >= 3:\n",
    "            dtof = savgol_filter(dtof, sg_window, sg_order, axis=1)\n",
    "\n",
    "        # ---------- clip ----------\n",
    "        eps = float(cfg.get(\"eps\", 1e-12))\n",
    "        dtof[dtof < eps] = eps\n",
    "\n",
    "        # ---------- choose representation ----------\n",
    "        input_rep = cfg.get(\"input_rep\", \"log\")  # \"raw\" | \"log\" | \"raw_log\"\n",
    "\n",
    "        dtof_raw = dtof.astype(np.float32)\n",
    "        dtof_log = np.log(dtof_raw).astype(np.float32)\n",
    "\n",
    "        # ---------- build channels ----------\n",
    "        if input_rep == \"raw\":\n",
    "            channels = self.build_channels(t_ns, dtof_raw, cfg[\"channel_mode\"])  # (N,C,T)\n",
    "\n",
    "        elif input_rep == \"log\":\n",
    "            channels = self.build_channels(t_ns, dtof_log, cfg[\"channel_mode\"])  # (N,C,T)\n",
    "\n",
    "        elif input_rep == \"raw_log\":\n",
    "            ch_raw = self.build_channels(t_ns, dtof_raw, cfg[\"channel_mode\"])    # (N,C,T)\n",
    "            ch_log = self.build_channels(t_ns, dtof_log, cfg[\"channel_mode\"])    # (N,C,T)\n",
    "            channels = np.concatenate([ch_raw, ch_log], axis=1)                  # (N,2C,T)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown input_rep: {input_rep}\")\n",
    "\n",
    "        # ---------- to torch ----------\n",
    "        self.signals = torch.tensor(channels, dtype=torch.float32)  # (N,C,T)\n",
    "        self.labels = torch.tensor(y, dtype=torch.float32)          # (N,2)\n",
    "\n",
    "        self.N, self.C, self.T = self.signals.shape\n",
    "\n",
    "    def build_channels(self, t_ns: np.ndarray, dtof: np.ndarray, mode: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Channel masks in ns:\n",
    "            early: 0–0.5 ns\n",
    "            mid:   0.5–4 ns\n",
    "            late:  4–crop_t_max ns\n",
    "        \"\"\"\n",
    "        N, T = dtof.shape\n",
    "        crop_t_max = float(self.cfg[\"crop_t_max\"])\n",
    "\n",
    "        if mode == \"single\":\n",
    "            return dtof[:, None, :]  # (N,1,T)\n",
    "\n",
    "        early = ((t_ns >= 0.0) & (t_ns < 0.5)).astype(np.float32)\n",
    "        mid   = ((t_ns >= 0.5) & (t_ns < 4.0)).astype(np.float32)\n",
    "        late  = ((t_ns >= 4.0) & (t_ns <= crop_t_max)).astype(np.float32)\n",
    "\n",
    "        masks = np.stack([early, mid, late], axis=0)  # (3,T)\n",
    "\n",
    "        if mode == \"early_mid_late\":\n",
    "            return dtof[:, None, :] * masks[None, :, :]  # (N,3,T)\n",
    "\n",
    "        if mode == \"hybrid_4ch\":\n",
    "            full = dtof[:, None, :]                         # (N,1,T)\n",
    "            gated = dtof[:, None, :] * masks[None, :, :]    # (N,3,T)\n",
    "            return np.concatenate([full, gated], axis=1)    # (N,4,T)\n",
    "\n",
    "        raise ValueError(f\"Unknown channel_mode: {mode}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.signals[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e584e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN for 1D DTOF signals with flexible input channels.\n",
    "\n",
    "    Channel counts (C) depend on:\n",
    "        channel_mode:\n",
    "            - \"single\"         -> 1\n",
    "            - \"early_mid_late\" -> 3\n",
    "            - \"hybrid_4ch\"     -> 4\n",
    "        input_rep:\n",
    "            - \"raw\" / \"log\"    -> multiplier 1\n",
    "            - \"raw_log\"        -> multiplier 2\n",
    "\n",
    "    So:\n",
    "        C = base_C * (2 if input_rep == \"raw_log\" else 1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg: dict, input_length: int = 3000, output_dim: int = 2):\n",
    "        super().__init__()\n",
    "\n",
    "        base_C = {\"single\": 1, \"early_mid_late\": 3, \"hybrid_4ch\": 4}[cfg[\"channel_mode\"]]\n",
    "        mult = 2 if cfg.get(\"input_rep\", \"log\") == \"raw_log\" else 1\n",
    "        in_channels = base_C * mult\n",
    "\n",
    "        # Convolution blocks\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=32, kernel_size=3, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=7, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(16)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        # Compute flattened feature size dynamically\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, input_length)\n",
    "            feat = self._forward_features(dummy)\n",
    "            self.flatten_dim = feat.shape[1]\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        # Block 1\n",
    "        x = self.pool1(self.act(self.bn1(self.conv1(x))))\n",
    "        # Block 2\n",
    "        x = self.pool2(self.act(self.bn2(self.conv2(x))))\n",
    "        # Block 3\n",
    "        x = self.pool3(self.act(self.bn3(self.conv3(x))))\n",
    "        # Flatten\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a581ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    save_path=None,\n",
    "    eps=1e-12,\n",
    "    print_every=1,\n",
    "    exp_clip=20.0,   # exp(20) ~ 4.85e8, safety for overflow\n",
    "    patience = 20, \n",
    "    min_delta = 0.0, \n",
    "):\n",
    "    model.to(device)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # -------------------------\n",
    "        # TRAIN\n",
    "        # -------------------------\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        tr_sum_sq = torch.zeros(2, device=device)\n",
    "        tr_count = 0\n",
    "\n",
    "        for signals, labels in train_loader:\n",
    "            signals = signals.to(device)\n",
    "            labels = labels.to(device).float()                 # (B,2)\n",
    "\n",
    "            log_labels = torch.log(labels.clamp_min(eps))      # (B,2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds_log = model(signals).view_as(log_labels)     # (B,2)\n",
    "            loss = loss_fn(preds_log, log_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # RMSE in original units\n",
    "            with torch.no_grad():\n",
    "                preds_lin = torch.exp(preds_log.clamp(-exp_clip, exp_clip))\n",
    "                err = preds_lin - labels\n",
    "                tr_sum_sq += (err ** 2).sum(dim=0)\n",
    "                tr_count += labels.shape[0]\n",
    "\n",
    "        train_loss = running_loss / max(1, len(train_loader))\n",
    "        train_rmse = torch.sqrt(tr_sum_sq / max(1, tr_count)).detach().cpu().numpy()\n",
    "\n",
    "        # -------------------------\n",
    "        # VALIDATE\n",
    "        # -------------------------\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "\n",
    "        va_sum_sq = torch.zeros(2, device=device)\n",
    "        va_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in val_loader:\n",
    "                signals = signals.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "\n",
    "                log_labels = torch.log(labels.clamp_min(eps))\n",
    "                preds_log = model(signals).view_as(log_labels)\n",
    "\n",
    "                loss = loss_fn(preds_log, log_labels)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "                preds_lin = torch.exp(preds_log.clamp(-exp_clip, exp_clip))\n",
    "                err = preds_lin - labels\n",
    "                va_sum_sq += (err ** 2).sum(dim=0)\n",
    "                va_count += labels.shape[0]\n",
    "\n",
    "        val_loss = val_running_loss / max(1, len(val_loader))\n",
    "        val_rmse = torch.sqrt(va_sum_sq / max(1, va_count)).detach().cpu().numpy()\n",
    "\n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "            print(f\"Train Loss (log-MSE): {train_loss:.6f} | Train RMSE [mua, mus]: {train_rmse}\")\n",
    "            print(f\"Val   Loss (log-MSE): {val_loss:.6f} | Val   RMSE [mua, mus]: {val_rmse}\")\n",
    "\n",
    "        if val_loss < (best_val_loss - min_delta):\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            if save_path is not None:\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\" -> Best validation so far, saved.\")\n",
    "            else: \n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience: \n",
    "                    print(f\"\\nEarly stopping at epoch {epoch + 1}:\"\n",
    "                          f\"no val improvement for {patience} epochs.\")\n",
    "                    break\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1bb93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_val_loaders(dataset, batch_size=32, val_frac=0.2, seed=42, shuffle_train=True):\n",
    "    n = len(dataset)\n",
    "    idx = np.arange(n)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    split = int(n * (1 - val_frac))\n",
    "    train_idx = idx[:split]\n",
    "    val_idx = idx[split:]\n",
    "\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle_train)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5483d70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: torch.Size([8, 3000]) torch.Size([2])\n",
      "model out: torch.Size([1, 2])\n",
      "signals: torch.Size([32, 8, 3000])\n",
      "labels: torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "# Trial run\n",
    "\n",
    "matlab_path = \"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/Pre-obtained data/dataset_homo_small.mat\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = {\n",
    "        \"crop_t_max\": 6.0,\n",
    "        \"sg_window\": frame_length,\n",
    "        \"sg_order\": order,\n",
    "        \"eps\": 1e-12,\n",
    "        \"channel_mode\": \"hybrid_4ch\",  # \"single\" | \"early_mid_late\" | \"hybrid_4ch\"\n",
    "        \"input_rep\": \"raw_log\",        # \"raw\" | \"log\" | \"raw_log\"\n",
    "    }\n",
    "\n",
    "    ds = DTOFDataset(matlab_path, cfg)\n",
    "    x, y = ds[0]\n",
    "    print(\"sample:\", x.shape, y.shape)\n",
    "\n",
    "    model = Net(cfg, input_length=ds.T, output_dim=2).to(device)\n",
    "    out = model(x.unsqueeze(0))\n",
    "    print(\"model out:\", out.shape)\n",
    "\n",
    "    train_loader, val_loader = make_train_val_loaders(ds, batch_size=32, val_frac=0.2, seed=42)\n",
    "\n",
    "    signals, labels = next(iter(train_loader))\n",
    "    print(\"signals:\", signals.shape)  # (B, C, T)\n",
    "    print(\"labels:\", labels.shape)    # (B, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414ed861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator: \n",
    "    \"\"\"\n",
    "    Evaluates a trained model that outputs log(mua), log(mus).\n",
    "    Reports MAE/RMSE in original units by exp().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, device, eps=1e-12):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.eps = eps\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        all_preds_lin = []\n",
    "        all_labels_lin = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in data_loader:\n",
    "                signals = signals.to(self.device)\n",
    "                labels = labels.to(self.device).float()              # (B,2) linear\n",
    "\n",
    "                preds_log = self.model(signals)                      # (B,2) log\n",
    "                preds_log = preds_log.view_as(labels)\n",
    "\n",
    "                preds_lin = torch.exp(preds_log)                     # back to linear\n",
    "\n",
    "                all_preds_lin.append(preds_lin.cpu())\n",
    "                all_labels_lin.append(labels.cpu())\n",
    "\n",
    "        preds = torch.cat(all_preds_lin, dim=0)\n",
    "        labs  = torch.cat(all_labels_lin, dim=0)\n",
    "\n",
    "        abs_err = torch.abs(preds - labs)\n",
    "        sq_err  = (preds - labs) ** 2\n",
    "\n",
    "        mae = abs_err.mean(dim=0)\n",
    "        rmse = torch.sqrt(sq_err.mean(dim=0))\n",
    "\n",
    "        return {\n",
    "            \"MAE\": mae.numpy(),\n",
    "            \"RMSE\": rmse.numpy(),\n",
    "            \"preds\": preds.numpy(),\n",
    "            \"labels\": labs.numpy(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15bd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Total samples: 500\n",
      "Train samples: 400\n",
      "Val samples  : 100\n",
      "Signal shape : torch.Size([8, 3000]) Label shape: torch.Size([2])\n",
      "steps_per_epoch: 13\n",
      "target_steps   : 50000\n",
      "num_epochs     : 3847\n",
      "Pre-train RMSE train [mua, mus]: [ 1.2259294 13.752475 ]\n",
      "Pre-train RMSE val   [mua, mus]: [ 1.1722105 13.688775 ]\n",
      "\n",
      "Epoch 1/3847\n",
      "Train Loss (log-MSE): 2.224561 | Train RMSE [mua, mus]: [ 0.30347875 10.434857  ]\n",
      "Val   Loss (log-MSE): 3.912572 | Val   RMSE [mua, mus]: [ 0.19102694 12.617171  ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 2/3847\n",
      "Train Loss (log-MSE): 0.195658 | Train RMSE [mua, mus]: [ 0.01387672 11.672562  ]\n",
      "Val   Loss (log-MSE): 0.645825 | Val   RMSE [mua, mus]: [0.03196168 8.192657  ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 3/3847\n",
      "Train Loss (log-MSE): 0.235209 | Train RMSE [mua, mus]: [0.02188006 3.9205337 ]\n",
      "Val   Loss (log-MSE): 0.134619 | Val   RMSE [mua, mus]: [0.01512351 4.3076487 ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 4/3847\n",
      "Train Loss (log-MSE): 0.165115 | Train RMSE [mua, mus]: [0.01179801 6.245989  ]\n",
      "Val   Loss (log-MSE): 0.097756 | Val   RMSE [mua, mus]: [0.01638312 4.857108  ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 5/3847\n",
      "Train Loss (log-MSE): 0.228975 | Train RMSE [mua, mus]: [0.01684635 9.49087   ]\n",
      "Val   Loss (log-MSE): 0.090927 | Val   RMSE [mua, mus]: [0.00824246 3.0885224 ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 6/3847\n",
      "Train Loss (log-MSE): 0.201368 | Train RMSE [mua, mus]: [0.01465518 7.236531  ]\n",
      "Val   Loss (log-MSE): 0.046738 | Val   RMSE [mua, mus]: [0.00651661 4.4785547 ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 7/3847\n",
      "Train Loss (log-MSE): 0.133945 | Train RMSE [mua, mus]: [0.01306405 6.6213546 ]\n",
      "Val   Loss (log-MSE): 0.052499 | Val   RMSE [mua, mus]: [3.3213543e-03 4.3362684e+00]\n",
      "\n",
      "Epoch 8/3847\n",
      "Train Loss (log-MSE): 0.084533 | Train RMSE [mua, mus]: [0.00864713 4.9785485 ]\n",
      "Val   Loss (log-MSE): 0.074585 | Val   RMSE [mua, mus]: [0.01375182 4.8336487 ]\n",
      "\n",
      "Epoch 9/3847\n",
      "Train Loss (log-MSE): 0.060395 | Train RMSE [mua, mus]: [0.0123454 3.1595237]\n",
      "Val   Loss (log-MSE): 0.023451 | Val   RMSE [mua, mus]: [0.00431751 3.257779  ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 10/3847\n",
      "Train Loss (log-MSE): 0.053977 | Train RMSE [mua, mus]: [0.00747189 3.2486243 ]\n",
      "Val   Loss (log-MSE): 0.056745 | Val   RMSE [mua, mus]: [0.00604172 3.0451503 ]\n",
      "\n",
      "Epoch 11/3847\n",
      "Train Loss (log-MSE): 0.065831 | Train RMSE [mua, mus]: [0.0101781 3.766813 ]\n",
      "Val   Loss (log-MSE): 0.032062 | Val   RMSE [mua, mus]: [0.00780967 2.5899746 ]\n",
      "\n",
      "Epoch 12/3847\n",
      "Train Loss (log-MSE): 0.077018 | Train RMSE [mua, mus]: [0.01099706 2.8431888 ]\n",
      "Val   Loss (log-MSE): 0.068212 | Val   RMSE [mua, mus]: [0.01086178 2.283894  ]\n",
      "\n",
      "Epoch 13/3847\n",
      "Train Loss (log-MSE): 0.039996 | Train RMSE [mua, mus]: [0.00647757 2.7547328 ]\n",
      "Val   Loss (log-MSE): 0.008526 | Val   RMSE [mua, mus]: [0.00295053 2.2356768 ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 14/3847\n",
      "Train Loss (log-MSE): 0.033700 | Train RMSE [mua, mus]: [0.00634078 3.2167637 ]\n",
      "Val   Loss (log-MSE): 0.017597 | Val   RMSE [mua, mus]: [0.00307504 2.692015  ]\n",
      "\n",
      "Epoch 15/3847\n",
      "Train Loss (log-MSE): 0.057775 | Train RMSE [mua, mus]: [0.00687797 3.1444814 ]\n",
      "Val   Loss (log-MSE): 0.060712 | Val   RMSE [mua, mus]: [0.01150219 1.9965976 ]\n",
      "\n",
      "Epoch 16/3847\n",
      "Train Loss (log-MSE): 0.093546 | Train RMSE [mua, mus]: [0.01174289 3.25081   ]\n",
      "Val   Loss (log-MSE): 0.035751 | Val   RMSE [mua, mus]: [0.00681087 3.7160962 ]\n",
      "\n",
      "Epoch 17/3847\n",
      "Train Loss (log-MSE): 0.046769 | Train RMSE [mua, mus]: [0.00851904 2.296358  ]\n",
      "Val   Loss (log-MSE): 0.033499 | Val   RMSE [mua, mus]: [0.00518647 2.2833593 ]\n",
      "\n",
      "Epoch 18/3847\n",
      "Train Loss (log-MSE): 0.063282 | Train RMSE [mua, mus]: [0.00835548 2.4944348 ]\n",
      "Val   Loss (log-MSE): 0.020548 | Val   RMSE [mua, mus]: [0.00589283 2.038018  ]\n",
      "\n",
      "Epoch 19/3847\n",
      "Train Loss (log-MSE): 0.133632 | Train RMSE [mua, mus]: [0.01564401 4.4862823 ]\n",
      "Val   Loss (log-MSE): 0.130661 | Val   RMSE [mua, mus]: [0.01279839 4.2556095 ]\n",
      "\n",
      "Epoch 20/3847\n",
      "Train Loss (log-MSE): 0.075569 | Train RMSE [mua, mus]: [0.01113336 4.139139  ]\n",
      "Val   Loss (log-MSE): 0.013645 | Val   RMSE [mua, mus]: [0.00504044 2.4672253 ]\n",
      "\n",
      "Epoch 21/3847\n",
      "Train Loss (log-MSE): 0.033021 | Train RMSE [mua, mus]: [0.00634192 2.0964305 ]\n",
      "Val   Loss (log-MSE): 0.021790 | Val   RMSE [mua, mus]: [0.00388404 2.7061696 ]\n",
      "\n",
      "Epoch 22/3847\n",
      "Train Loss (log-MSE): 0.027632 | Train RMSE [mua, mus]: [0.00551253 2.7807722 ]\n",
      "Val   Loss (log-MSE): 0.018411 | Val   RMSE [mua, mus]: [0.0061159 1.9020281]\n",
      "\n",
      "Epoch 23/3847\n",
      "Train Loss (log-MSE): 0.040547 | Train RMSE [mua, mus]: [0.0062246 3.3429384]\n",
      "Val   Loss (log-MSE): 0.055498 | Val   RMSE [mua, mus]: [0.00774886 3.6432817 ]\n",
      "\n",
      "Epoch 24/3847\n",
      "Train Loss (log-MSE): 0.068962 | Train RMSE [mua, mus]: [0.00703152 3.6593876 ]\n",
      "Val   Loss (log-MSE): 0.041994 | Val   RMSE [mua, mus]: [0.00590809 2.6031055 ]\n",
      "\n",
      "Epoch 25/3847\n",
      "Train Loss (log-MSE): 0.060836 | Train RMSE [mua, mus]: [0.0104811 3.3928022]\n",
      "Val   Loss (log-MSE): 0.023612 | Val   RMSE [mua, mus]: [0.00789674 2.9004495 ]\n",
      "\n",
      "Epoch 26/3847\n",
      "Train Loss (log-MSE): 0.038679 | Train RMSE [mua, mus]: [0.01010159 3.3548915 ]\n",
      "Val   Loss (log-MSE): 0.013143 | Val   RMSE [mua, mus]: [0.00499449 1.4057148 ]\n",
      "\n",
      "Epoch 27/3847\n",
      "Train Loss (log-MSE): 0.020202 | Train RMSE [mua, mus]: [0.00507879 2.317016  ]\n",
      "Val   Loss (log-MSE): 0.010492 | Val   RMSE [mua, mus]: [0.0033714 1.6966827]\n",
      "\n",
      "Epoch 28/3847\n",
      "Train Loss (log-MSE): 0.028512 | Train RMSE [mua, mus]: [0.00390866 2.6355588 ]\n",
      "Val   Loss (log-MSE): 0.010580 | Val   RMSE [mua, mus]: [0.0019219 1.4812931]\n",
      "\n",
      "Epoch 29/3847\n",
      "Train Loss (log-MSE): 0.025101 | Train RMSE [mua, mus]: [0.00535489 2.3765404 ]\n",
      "Val   Loss (log-MSE): 0.009548 | Val   RMSE [mua, mus]: [0.00507623 1.6224878 ]\n",
      "\n",
      "Epoch 30/3847\n",
      "Train Loss (log-MSE): 0.020468 | Train RMSE [mua, mus]: [0.00606953 2.67081   ]\n",
      "Val   Loss (log-MSE): 0.009295 | Val   RMSE [mua, mus]: [1.9965817e-03 2.3749485e+00]\n",
      "\n",
      "Epoch 31/3847\n",
      "Train Loss (log-MSE): 0.026980 | Train RMSE [mua, mus]: [0.00582167 2.2683003 ]\n",
      "Val   Loss (log-MSE): 0.035049 | Val   RMSE [mua, mus]: [0.00735738 2.9946692 ]\n",
      "\n",
      "Epoch 32/3847\n",
      "Train Loss (log-MSE): 0.037486 | Train RMSE [mua, mus]: [0.00642107 3.2185957 ]\n",
      "Val   Loss (log-MSE): 0.056434 | Val   RMSE [mua, mus]: [0.00830146 4.0916867 ]\n",
      "\n",
      "Epoch 33/3847\n",
      "Train Loss (log-MSE): 0.037145 | Train RMSE [mua, mus]: [0.00834996 3.3939612 ]\n",
      "Val   Loss (log-MSE): 0.006979 | Val   RMSE [mua, mus]: [0.00346651 1.2918453 ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 34/3847\n",
      "Train Loss (log-MSE): 0.022512 | Train RMSE [mua, mus]: [0.0068637 2.0881248]\n",
      "Val   Loss (log-MSE): 0.007975 | Val   RMSE [mua, mus]: [0.00197345 1.3450844 ]\n",
      "\n",
      "Epoch 35/3847\n",
      "Train Loss (log-MSE): 0.026672 | Train RMSE [mua, mus]: [0.00554497 2.299202  ]\n",
      "Val   Loss (log-MSE): 0.014428 | Val   RMSE [mua, mus]: [0.00255604 1.1924984 ]\n",
      "\n",
      "Epoch 36/3847\n",
      "Train Loss (log-MSE): 0.020494 | Train RMSE [mua, mus]: [0.00491789 1.7680386 ]\n",
      "Val   Loss (log-MSE): 0.074126 | Val   RMSE [mua, mus]: [0.0075766 3.0451293]\n",
      "\n",
      "Epoch 37/3847\n",
      "Train Loss (log-MSE): 0.041428 | Train RMSE [mua, mus]: [0.00834745 2.5284586 ]\n",
      "Val   Loss (log-MSE): 0.114712 | Val   RMSE [mua, mus]: [0.01443904 5.288742  ]\n",
      "\n",
      "Epoch 38/3847\n",
      "Train Loss (log-MSE): 0.058209 | Train RMSE [mua, mus]: [0.01546946 3.5911145 ]\n",
      "Val   Loss (log-MSE): 0.013891 | Val   RMSE [mua, mus]: [0.00654938 2.0611217 ]\n",
      "\n",
      "Epoch 39/3847\n",
      "Train Loss (log-MSE): 0.043071 | Train RMSE [mua, mus]: [0.0082553 3.1498067]\n",
      "Val   Loss (log-MSE): 0.020338 | Val   RMSE [mua, mus]: [0.00630801 3.2732542 ]\n",
      "\n",
      "Epoch 40/3847\n",
      "Train Loss (log-MSE): 0.041535 | Train RMSE [mua, mus]: [0.00981565 2.4276087 ]\n",
      "Val   Loss (log-MSE): 0.047214 | Val   RMSE [mua, mus]: [0.01512139 1.7735304 ]\n",
      "\n",
      "Epoch 41/3847\n",
      "Train Loss (log-MSE): 0.037003 | Train RMSE [mua, mus]: [0.00785322 2.9461668 ]\n",
      "Val   Loss (log-MSE): 0.012357 | Val   RMSE [mua, mus]: [0.00267877 2.014784  ]\n",
      "\n",
      "Epoch 42/3847\n",
      "Train Loss (log-MSE): 0.026319 | Train RMSE [mua, mus]: [0.00580925 1.9831358 ]\n",
      "Val   Loss (log-MSE): 0.008346 | Val   RMSE [mua, mus]: [0.0031985 1.8566492]\n",
      "\n",
      "Epoch 43/3847\n",
      "Train Loss (log-MSE): 0.023650 | Train RMSE [mua, mus]: [0.00408004 2.3815787 ]\n",
      "Val   Loss (log-MSE): 0.011319 | Val   RMSE [mua, mus]: [0.00250962 1.7993381 ]\n",
      "\n",
      "Epoch 44/3847\n",
      "Train Loss (log-MSE): 0.014558 | Train RMSE [mua, mus]: [0.00414201 2.332163  ]\n",
      "Val   Loss (log-MSE): 0.009262 | Val   RMSE [mua, mus]: [0.00238891 1.5188384 ]\n",
      "\n",
      "Epoch 45/3847\n",
      "Train Loss (log-MSE): 0.021160 | Train RMSE [mua, mus]: [0.01154281 1.6914915 ]\n",
      "Val   Loss (log-MSE): 0.020077 | Val   RMSE [mua, mus]: [0.01062085 1.5532948 ]\n",
      "\n",
      "Epoch 46/3847\n",
      "Train Loss (log-MSE): 0.030954 | Train RMSE [mua, mus]: [0.00951183 1.8173114 ]\n",
      "Val   Loss (log-MSE): 0.014457 | Val   RMSE [mua, mus]: [0.0026243 1.509344 ]\n",
      "\n",
      "Epoch 47/3847\n",
      "Train Loss (log-MSE): 0.025159 | Train RMSE [mua, mus]: [0.00734593 2.3676758 ]\n",
      "Val   Loss (log-MSE): 0.013408 | Val   RMSE [mua, mus]: [0.00280817 1.4474403 ]\n",
      "\n",
      "Epoch 48/3847\n",
      "Train Loss (log-MSE): 0.016104 | Train RMSE [mua, mus]: [0.0040715 1.8720033]\n",
      "Val   Loss (log-MSE): 0.005180 | Val   RMSE [mua, mus]: [0.00250047 1.7298687 ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 49/3847\n",
      "Train Loss (log-MSE): 0.012625 | Train RMSE [mua, mus]: [0.00381369 1.5030601 ]\n",
      "Val   Loss (log-MSE): 0.011096 | Val   RMSE [mua, mus]: [0.00357026 1.49884   ]\n",
      "\n",
      "Epoch 50/3847\n",
      "Train Loss (log-MSE): 0.040070 | Train RMSE [mua, mus]: [0.00556675 2.3250651 ]\n",
      "Val   Loss (log-MSE): 0.025319 | Val   RMSE [mua, mus]: [0.00254987 1.9202294 ]\n",
      "\n",
      "Epoch 51/3847\n",
      "Train Loss (log-MSE): 0.036590 | Train RMSE [mua, mus]: [0.00698311 2.9786546 ]\n",
      "Val   Loss (log-MSE): 0.019676 | Val   RMSE [mua, mus]: [0.00540515 1.4311154 ]\n",
      "\n",
      "Epoch 52/3847\n",
      "Train Loss (log-MSE): 0.038862 | Train RMSE [mua, mus]: [0.00598121 2.9836802 ]\n",
      "Val   Loss (log-MSE): 0.010033 | Val   RMSE [mua, mus]: [0.00181939 1.4949212 ]\n",
      "\n",
      "Epoch 53/3847\n",
      "Train Loss (log-MSE): 0.031127 | Train RMSE [mua, mus]: [0.00603322 3.4536552 ]\n",
      "Val   Loss (log-MSE): 0.031088 | Val   RMSE [mua, mus]: [3.6376403e-03 3.8377721e+00]\n",
      "\n",
      "Epoch 54/3847\n",
      "Train Loss (log-MSE): 0.014426 | Train RMSE [mua, mus]: [0.00350199 1.8928521 ]\n",
      "Val   Loss (log-MSE): 0.009656 | Val   RMSE [mua, mus]: [0.00249178 2.0581214 ]\n",
      "\n",
      "Epoch 55/3847\n",
      "Train Loss (log-MSE): 0.014366 | Train RMSE [mua, mus]: [0.00410926 1.9856038 ]\n",
      "Val   Loss (log-MSE): 0.012104 | Val   RMSE [mua, mus]: [0.00227931 2.0159416 ]\n",
      "\n",
      "Epoch 56/3847\n",
      "Train Loss (log-MSE): 0.011656 | Train RMSE [mua, mus]: [0.0037783 1.6403593]\n",
      "Val   Loss (log-MSE): 0.005713 | Val   RMSE [mua, mus]: [0.00174955 1.580829  ]\n",
      "\n",
      "Epoch 57/3847\n",
      "Train Loss (log-MSE): 0.009169 | Train RMSE [mua, mus]: [0.00279193 1.4645008 ]\n",
      "Val   Loss (log-MSE): 0.011579 | Val   RMSE [mua, mus]: [0.0021003 1.6091762]\n",
      "\n",
      "Epoch 58/3847\n",
      "Train Loss (log-MSE): 0.015266 | Train RMSE [mua, mus]: [0.00421296 1.9808844 ]\n",
      "Val   Loss (log-MSE): 0.007992 | Val   RMSE [mua, mus]: [0.00280726 1.3538576 ]\n",
      "\n",
      "Epoch 59/3847\n",
      "Train Loss (log-MSE): 0.009385 | Train RMSE [mua, mus]: [0.003294  1.9260377]\n",
      "Val   Loss (log-MSE): 0.004832 | Val   RMSE [mua, mus]: [1.2273575e-03 1.3380815e+00]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 60/3847\n",
      "Train Loss (log-MSE): 0.008240 | Train RMSE [mua, mus]: [0.0033014 1.4036688]\n",
      "Val   Loss (log-MSE): 0.004485 | Val   RMSE [mua, mus]: [0.00344073 1.6031885 ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 61/3847\n",
      "Train Loss (log-MSE): 0.010926 | Train RMSE [mua, mus]: [0.0038002 1.3625606]\n",
      "Val   Loss (log-MSE): 0.009159 | Val   RMSE [mua, mus]: [0.00235377 2.0275335 ]\n",
      "\n",
      "Epoch 62/3847\n",
      "Train Loss (log-MSE): 0.008511 | Train RMSE [mua, mus]: [0.00262134 1.5524031 ]\n",
      "Val   Loss (log-MSE): 0.003151 | Val   RMSE [mua, mus]: [1.0601901e-03 1.0667694e+00]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 63/3847\n",
      "Train Loss (log-MSE): 0.006265 | Train RMSE [mua, mus]: [0.00251068 1.2411793 ]\n",
      "Val   Loss (log-MSE): 0.004623 | Val   RMSE [mua, mus]: [0.00177379 1.0554382 ]\n",
      "\n",
      "Epoch 64/3847\n",
      "Train Loss (log-MSE): 0.007663 | Train RMSE [mua, mus]: [0.00302185 1.3837868 ]\n",
      "Val   Loss (log-MSE): 0.014747 | Val   RMSE [mua, mus]: [0.00221081 1.8169968 ]\n",
      "\n",
      "Epoch 65/3847\n",
      "Train Loss (log-MSE): 0.014783 | Train RMSE [mua, mus]: [0.00559696 1.8568116 ]\n",
      "Val   Loss (log-MSE): 0.011088 | Val   RMSE [mua, mus]: [0.00392718 1.486886  ]\n",
      "\n",
      "Epoch 66/3847\n",
      "Train Loss (log-MSE): 0.007974 | Train RMSE [mua, mus]: [0.00358147 1.2992955 ]\n",
      "Val   Loss (log-MSE): 0.006296 | Val   RMSE [mua, mus]: [0.00289768 1.443136  ]\n",
      "\n",
      "Epoch 67/3847\n",
      "Train Loss (log-MSE): 0.008646 | Train RMSE [mua, mus]: [0.00295407 1.3398609 ]\n",
      "Val   Loss (log-MSE): 0.010146 | Val   RMSE [mua, mus]: [1.7810399e-03 1.8359168e+00]\n",
      "\n",
      "Epoch 68/3847\n",
      "Train Loss (log-MSE): 0.009196 | Train RMSE [mua, mus]: [0.00301627 1.5968403 ]\n",
      "Val   Loss (log-MSE): 0.009674 | Val   RMSE [mua, mus]: [0.00244939 1.0958107 ]\n",
      "\n",
      "Epoch 69/3847\n",
      "Train Loss (log-MSE): 0.010870 | Train RMSE [mua, mus]: [0.00187519 1.7187715 ]\n",
      "Val   Loss (log-MSE): 0.008812 | Val   RMSE [mua, mus]: [0.00413951 1.0329715 ]\n",
      "\n",
      "Epoch 70/3847\n",
      "Train Loss (log-MSE): 0.016234 | Train RMSE [mua, mus]: [0.00395699 2.2322624 ]\n",
      "Val   Loss (log-MSE): 0.005911 | Val   RMSE [mua, mus]: [0.00259763 1.9124346 ]\n",
      "\n",
      "Epoch 71/3847\n",
      "Train Loss (log-MSE): 0.006921 | Train RMSE [mua, mus]: [0.00241715 1.4271047 ]\n",
      "Val   Loss (log-MSE): 0.004573 | Val   RMSE [mua, mus]: [0.00179793 1.2499741 ]\n",
      "\n",
      "Epoch 72/3847\n",
      "Train Loss (log-MSE): 0.007137 | Train RMSE [mua, mus]: [0.00296061 1.353511  ]\n",
      "Val   Loss (log-MSE): 0.005989 | Val   RMSE [mua, mus]: [0.00222926 1.3068851 ]\n",
      "\n",
      "Epoch 73/3847\n",
      "Train Loss (log-MSE): 0.009479 | Train RMSE [mua, mus]: [0.00448492 1.3111062 ]\n",
      "Val   Loss (log-MSE): 0.009328 | Val   RMSE [mua, mus]: [0.00201791 0.97444624]\n",
      "\n",
      "Epoch 74/3847\n",
      "Train Loss (log-MSE): 0.010074 | Train RMSE [mua, mus]: [0.00531053 1.3447466 ]\n",
      "Val   Loss (log-MSE): 0.013314 | Val   RMSE [mua, mus]: [0.00572982 0.945494  ]\n",
      "\n",
      "Epoch 75/3847\n",
      "Train Loss (log-MSE): 0.012031 | Train RMSE [mua, mus]: [0.00500167 1.1959502 ]\n",
      "Val   Loss (log-MSE): 0.010012 | Val   RMSE [mua, mus]: [0.00217385 1.662117  ]\n",
      "\n",
      "Epoch 76/3847\n",
      "Train Loss (log-MSE): 0.011355 | Train RMSE [mua, mus]: [0.00403852 1.9390941 ]\n",
      "Val   Loss (log-MSE): 0.008365 | Val   RMSE [mua, mus]: [1.4571284e-03 2.7053180e+00]\n",
      "\n",
      "Epoch 77/3847\n",
      "Train Loss (log-MSE): 0.015964 | Train RMSE [mua, mus]: [0.00390946 2.0832179 ]\n",
      "Val   Loss (log-MSE): 0.011206 | Val   RMSE [mua, mus]: [0.00435888 1.5404661 ]\n",
      "\n",
      "Epoch 78/3847\n",
      "Train Loss (log-MSE): 0.012876 | Train RMSE [mua, mus]: [0.00345668 1.7028133 ]\n",
      "Val   Loss (log-MSE): 0.004616 | Val   RMSE [mua, mus]: [0.00363745 0.9202649 ]\n",
      "\n",
      "Epoch 79/3847\n",
      "Train Loss (log-MSE): 0.011145 | Train RMSE [mua, mus]: [0.00353399 1.7222673 ]\n",
      "Val   Loss (log-MSE): 0.008316 | Val   RMSE [mua, mus]: [1.6670747e-03 1.9687320e+00]\n",
      "\n",
      "Epoch 80/3847\n",
      "Train Loss (log-MSE): 0.006747 | Train RMSE [mua, mus]: [0.00292891 1.3125466 ]\n",
      "Val   Loss (log-MSE): 0.003315 | Val   RMSE [mua, mus]: [1.1495315e-03 1.1507992e+00]\n",
      "\n",
      "Epoch 81/3847\n",
      "Train Loss (log-MSE): 0.008264 | Train RMSE [mua, mus]: [0.00340459 1.3125395 ]\n",
      "Val   Loss (log-MSE): 0.014676 | Val   RMSE [mua, mus]: [0.00380066 1.3560542 ]\n",
      "\n",
      "Epoch 82/3847\n",
      "Train Loss (log-MSE): 0.007481 | Train RMSE [mua, mus]: [0.00300375 1.3095167 ]\n",
      "Val   Loss (log-MSE): 0.004024 | Val   RMSE [mua, mus]: [0.00279097 1.2812274 ]\n",
      "\n",
      "Epoch 83/3847\n",
      "Train Loss (log-MSE): 0.008312 | Train RMSE [mua, mus]: [0.00454471 1.6611851 ]\n",
      "Val   Loss (log-MSE): 0.008325 | Val   RMSE [mua, mus]: [0.00379096 1.9199878 ]\n",
      "\n",
      "Epoch 84/3847\n",
      "Train Loss (log-MSE): 0.006921 | Train RMSE [mua, mus]: [0.0030649 1.4030371]\n",
      "Val   Loss (log-MSE): 0.007114 | Val   RMSE [mua, mus]: [0.00201939 1.7057493 ]\n",
      "\n",
      "Epoch 85/3847\n",
      "Train Loss (log-MSE): 0.007927 | Train RMSE [mua, mus]: [0.00235328 1.6315385 ]\n",
      "Val   Loss (log-MSE): 0.009633 | Val   RMSE [mua, mus]: [0.00215107 0.88313925]\n",
      "\n",
      "Epoch 86/3847\n",
      "Train Loss (log-MSE): 0.009101 | Train RMSE [mua, mus]: [0.00243731 1.9498389 ]\n",
      "Val   Loss (log-MSE): 0.010874 | Val   RMSE [mua, mus]: [1.5206420e-03 2.3728762e+00]\n",
      "\n",
      "Epoch 87/3847\n",
      "Train Loss (log-MSE): 0.011102 | Train RMSE [mua, mus]: [0.00351371 1.7150571 ]\n",
      "Val   Loss (log-MSE): 0.014491 | Val   RMSE [mua, mus]: [0.00728309 1.6945523 ]\n",
      "\n",
      "Epoch 88/3847\n",
      "Train Loss (log-MSE): 0.009657 | Train RMSE [mua, mus]: [0.00385681 1.8236418 ]\n",
      "Val   Loss (log-MSE): 0.008029 | Val   RMSE [mua, mus]: [0.0017865 1.3207682]\n",
      "\n",
      "Epoch 89/3847\n",
      "Train Loss (log-MSE): 0.009425 | Train RMSE [mua, mus]: [0.00333323 1.6723173 ]\n",
      "Val   Loss (log-MSE): 0.012143 | Val   RMSE [mua, mus]: [0.00601054 1.9867871 ]\n",
      "\n",
      "Epoch 90/3847\n",
      "Train Loss (log-MSE): 0.008386 | Train RMSE [mua, mus]: [0.00394151 1.4355108 ]\n",
      "Val   Loss (log-MSE): 0.004178 | Val   RMSE [mua, mus]: [0.00169803 1.435942  ]\n",
      "\n",
      "Epoch 91/3847\n",
      "Train Loss (log-MSE): 0.010565 | Train RMSE [mua, mus]: [0.00412474 1.3749408 ]\n",
      "Val   Loss (log-MSE): 0.007903 | Val   RMSE [mua, mus]: [0.00240584 1.2942113 ]\n",
      "\n",
      "Epoch 92/3847\n",
      "Train Loss (log-MSE): 0.009217 | Train RMSE [mua, mus]: [0.00248218 1.575698  ]\n",
      "Val   Loss (log-MSE): 0.021357 | Val   RMSE [mua, mus]: [2.2830949e-03 3.4301815e+00]\n",
      "\n",
      "Epoch 93/3847\n",
      "Train Loss (log-MSE): 0.008930 | Train RMSE [mua, mus]: [0.00300633 1.4513271 ]\n",
      "Val   Loss (log-MSE): 0.003942 | Val   RMSE [mua, mus]: [0.003326  0.9767317]\n",
      "\n",
      "Epoch 94/3847\n",
      "Train Loss (log-MSE): 0.015818 | Train RMSE [mua, mus]: [0.00459815 1.8498267 ]\n",
      "Val   Loss (log-MSE): 0.010745 | Val   RMSE [mua, mus]: [0.00275976 1.7262683 ]\n",
      "\n",
      "Epoch 95/3847\n",
      "Train Loss (log-MSE): 0.008531 | Train RMSE [mua, mus]: [0.00292679 1.2923478 ]\n",
      "Val   Loss (log-MSE): 0.019596 | Val   RMSE [mua, mus]: [0.00202831 1.6115744 ]\n",
      "\n",
      "Epoch 96/3847\n",
      "Train Loss (log-MSE): 0.007633 | Train RMSE [mua, mus]: [0.00554471 0.963795  ]\n",
      "Val   Loss (log-MSE): 0.014941 | Val   RMSE [mua, mus]: [0.00578974 2.0054967 ]\n",
      "\n",
      "Epoch 97/3847\n",
      "Train Loss (log-MSE): 0.005755 | Train RMSE [mua, mus]: [0.00235399 1.2669684 ]\n",
      "Val   Loss (log-MSE): 0.004153 | Val   RMSE [mua, mus]: [0.00247505 1.8437428 ]\n",
      "\n",
      "Epoch 98/3847\n",
      "Train Loss (log-MSE): 0.006834 | Train RMSE [mua, mus]: [0.00319265 1.1898451 ]\n",
      "Val   Loss (log-MSE): 0.009377 | Val   RMSE [mua, mus]: [0.00224481 0.9949616 ]\n",
      "\n",
      "Epoch 99/3847\n",
      "Train Loss (log-MSE): 0.012683 | Train RMSE [mua, mus]: [0.00355776 1.9315333 ]\n",
      "Val   Loss (log-MSE): 0.002521 | Val   RMSE [mua, mus]: [9.7062258e-04 1.0593317e+00]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 100/3847\n",
      "Train Loss (log-MSE): 0.006569 | Train RMSE [mua, mus]: [0.00266985 1.3509754 ]\n",
      "Val   Loss (log-MSE): 0.009318 | Val   RMSE [mua, mus]: [0.00443686 2.425635  ]\n",
      "\n",
      "Epoch 101/3847\n",
      "Train Loss (log-MSE): 0.008248 | Train RMSE [mua, mus]: [0.0030071 1.9276816]\n",
      "Val   Loss (log-MSE): 0.005871 | Val   RMSE [mua, mus]: [0.00212496 1.1113179 ]\n",
      "\n",
      "Epoch 102/3847\n",
      "Train Loss (log-MSE): 0.006698 | Train RMSE [mua, mus]: [0.00218675 1.5564752 ]\n",
      "Val   Loss (log-MSE): 0.015150 | Val   RMSE [mua, mus]: [0.00364897 0.9763316 ]\n",
      "\n",
      "Epoch 103/3847\n",
      "Train Loss (log-MSE): 0.007095 | Train RMSE [mua, mus]: [0.00231726 1.8871456 ]\n",
      "Val   Loss (log-MSE): 0.006773 | Val   RMSE [mua, mus]: [2.0323086e-03 2.0511158e+00]\n",
      "\n",
      "Epoch 104/3847\n",
      "Train Loss (log-MSE): 0.005929 | Train RMSE [mua, mus]: [0.00279174 1.3120555 ]\n",
      "Val   Loss (log-MSE): 0.008244 | Val   RMSE [mua, mus]: [0.00458287 1.137762  ]\n",
      "\n",
      "Epoch 105/3847\n",
      "Train Loss (log-MSE): 0.008067 | Train RMSE [mua, mus]: [0.00279293 1.126934  ]\n",
      "Val   Loss (log-MSE): 0.010417 | Val   RMSE [mua, mus]: [0.00190819 1.0141134 ]\n",
      "\n",
      "Epoch 106/3847\n",
      "Train Loss (log-MSE): 0.006131 | Train RMSE [mua, mus]: [0.00213766 1.1118798 ]\n",
      "Val   Loss (log-MSE): 0.007421 | Val   RMSE [mua, mus]: [0.00338279 1.0710444 ]\n",
      "\n",
      "Epoch 107/3847\n",
      "Train Loss (log-MSE): 0.003599 | Train RMSE [mua, mus]: [0.00149991 1.0082128 ]\n",
      "Val   Loss (log-MSE): 0.005768 | Val   RMSE [mua, mus]: [0.00229903 1.5983413 ]\n",
      "\n",
      "Epoch 108/3847\n",
      "Train Loss (log-MSE): 0.004633 | Train RMSE [mua, mus]: [0.00225428 1.0970026 ]\n",
      "Val   Loss (log-MSE): 0.002885 | Val   RMSE [mua, mus]: [0.00116157 0.91619587]\n",
      "\n",
      "Epoch 109/3847\n",
      "Train Loss (log-MSE): 0.006041 | Train RMSE [mua, mus]: [0.00308286 1.254273  ]\n",
      "Val   Loss (log-MSE): 0.002734 | Val   RMSE [mua, mus]: [0.00138072 0.9998501 ]\n",
      "\n",
      "Epoch 110/3847\n",
      "Train Loss (log-MSE): 0.005982 | Train RMSE [mua, mus]: [0.00277261 1.3737786 ]\n",
      "Val   Loss (log-MSE): 0.002790 | Val   RMSE [mua, mus]: [0.00108021 0.90580046]\n",
      "\n",
      "Epoch 111/3847\n",
      "Train Loss (log-MSE): 0.004046 | Train RMSE [mua, mus]: [0.00201971 0.9713537 ]\n",
      "Val   Loss (log-MSE): 0.004829 | Val   RMSE [mua, mus]: [0.00120116 0.85649276]\n",
      "\n",
      "Epoch 112/3847\n",
      "Train Loss (log-MSE): 0.004281 | Train RMSE [mua, mus]: [0.00232838 1.241072  ]\n",
      "Val   Loss (log-MSE): 0.006004 | Val   RMSE [mua, mus]: [0.00259271 1.1377268 ]\n",
      "\n",
      "Epoch 113/3847\n",
      "Train Loss (log-MSE): 0.004634 | Train RMSE [mua, mus]: [0.002025  1.0622326]\n",
      "Val   Loss (log-MSE): 0.003398 | Val   RMSE [mua, mus]: [0.00198715 0.9075679 ]\n",
      "\n",
      "Epoch 114/3847\n",
      "Train Loss (log-MSE): 0.006163 | Train RMSE [mua, mus]: [0.00182713 1.1486413 ]\n",
      "Val   Loss (log-MSE): 0.010052 | Val   RMSE [mua, mus]: [0.00282919 1.552472  ]\n",
      "\n",
      "Epoch 115/3847\n",
      "Train Loss (log-MSE): 0.005826 | Train RMSE [mua, mus]: [0.0030361 1.2856562]\n",
      "Val   Loss (log-MSE): 0.008033 | Val   RMSE [mua, mus]: [1.9870955e-03 2.0564806e+00]\n",
      "\n",
      "Epoch 116/3847\n",
      "Train Loss (log-MSE): 0.003421 | Train RMSE [mua, mus]: [0.00137235 0.96940166]\n",
      "Val   Loss (log-MSE): 0.001922 | Val   RMSE [mua, mus]: [8.3755632e-04 1.0938735e+00]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 117/3847\n",
      "Train Loss (log-MSE): 0.003714 | Train RMSE [mua, mus]: [0.00175236 1.04245   ]\n",
      "Val   Loss (log-MSE): 0.008682 | Val   RMSE [mua, mus]: [0.00161773 1.1050376 ]\n",
      "\n",
      "Epoch 118/3847\n",
      "Train Loss (log-MSE): 0.005991 | Train RMSE [mua, mus]: [0.00296932 0.8936428 ]\n",
      "Val   Loss (log-MSE): 0.016466 | Val   RMSE [mua, mus]: [0.00588743 1.0171273 ]\n",
      "\n",
      "Epoch 119/3847\n",
      "Train Loss (log-MSE): 0.006948 | Train RMSE [mua, mus]: [0.00330353 1.103043  ]\n",
      "Val   Loss (log-MSE): 0.006389 | Val   RMSE [mua, mus]: [0.00437322 1.2061889 ]\n",
      "\n",
      "Epoch 120/3847\n",
      "Train Loss (log-MSE): 0.004691 | Train RMSE [mua, mus]: [0.00293826 1.0936667 ]\n",
      "Val   Loss (log-MSE): 0.004347 | Val   RMSE [mua, mus]: [0.00409551 1.4169879 ]\n",
      "\n",
      "Epoch 121/3847\n",
      "Train Loss (log-MSE): 0.004732 | Train RMSE [mua, mus]: [0.00342608 0.9656974 ]\n",
      "Val   Loss (log-MSE): 0.005042 | Val   RMSE [mua, mus]: [0.00244298 0.99865454]\n",
      "\n",
      "Epoch 122/3847\n",
      "Train Loss (log-MSE): 0.004673 | Train RMSE [mua, mus]: [0.00244408 1.3373638 ]\n",
      "Val   Loss (log-MSE): 0.013180 | Val   RMSE [mua, mus]: [0.00480143 1.8937129 ]\n",
      "\n",
      "Epoch 123/3847\n",
      "Train Loss (log-MSE): 0.008087 | Train RMSE [mua, mus]: [0.00271225 1.4316658 ]\n",
      "Val   Loss (log-MSE): 0.004867 | Val   RMSE [mua, mus]: [0.00379874 1.3307134 ]\n",
      "\n",
      "Epoch 124/3847\n",
      "Train Loss (log-MSE): 0.006314 | Train RMSE [mua, mus]: [0.00333974 1.3658209 ]\n",
      "Val   Loss (log-MSE): 0.009248 | Val   RMSE [mua, mus]: [0.00390592 2.2983034 ]\n",
      "\n",
      "Epoch 125/3847\n",
      "Train Loss (log-MSE): 0.006923 | Train RMSE [mua, mus]: [0.00287606 1.2416778 ]\n",
      "Val   Loss (log-MSE): 0.010001 | Val   RMSE [mua, mus]: [0.00235139 1.4380043 ]\n",
      "\n",
      "Epoch 126/3847\n",
      "Train Loss (log-MSE): 0.007004 | Train RMSE [mua, mus]: [0.00238267 1.2451217 ]\n",
      "Val   Loss (log-MSE): 0.006209 | Val   RMSE [mua, mus]: [1.9424115e-03 2.1553440e+00]\n",
      "\n",
      "Epoch 127/3847\n",
      "Train Loss (log-MSE): 0.007694 | Train RMSE [mua, mus]: [0.00344488 1.1826961 ]\n",
      "Val   Loss (log-MSE): 0.021825 | Val   RMSE [mua, mus]: [0.00450682 1.3213826 ]\n",
      "\n",
      "Epoch 128/3847\n",
      "Train Loss (log-MSE): 0.013597 | Train RMSE [mua, mus]: [0.00488065 1.9853293 ]\n",
      "Val   Loss (log-MSE): 0.009906 | Val   RMSE [mua, mus]: [0.00388236 1.1401007 ]\n",
      "\n",
      "Epoch 129/3847\n",
      "Train Loss (log-MSE): 0.013335 | Train RMSE [mua, mus]: [0.0047893 1.955697 ]\n",
      "Val   Loss (log-MSE): 0.005049 | Val   RMSE [mua, mus]: [0.00297608 1.2525147 ]\n",
      "\n",
      "Epoch 130/3847\n",
      "Train Loss (log-MSE): 0.011306 | Train RMSE [mua, mus]: [0.0045568 2.3217592]\n",
      "Val   Loss (log-MSE): 0.008799 | Val   RMSE [mua, mus]: [0.00366107 2.4691842 ]\n",
      "\n",
      "Epoch 131/3847\n",
      "Train Loss (log-MSE): 0.011255 | Train RMSE [mua, mus]: [0.00363208 1.5375096 ]\n",
      "Val   Loss (log-MSE): 0.007280 | Val   RMSE [mua, mus]: [0.00297343 1.7104787 ]\n",
      "\n",
      "Epoch 132/3847\n",
      "Train Loss (log-MSE): 0.015828 | Train RMSE [mua, mus]: [0.00338045 1.823989  ]\n",
      "Val   Loss (log-MSE): 0.006483 | Val   RMSE [mua, mus]: [0.00169692 1.5838192 ]\n",
      "\n",
      "Epoch 133/3847\n",
      "Train Loss (log-MSE): 0.015337 | Train RMSE [mua, mus]: [0.00356883 2.1206605 ]\n",
      "Val   Loss (log-MSE): 0.010607 | Val   RMSE [mua, mus]: [0.00207829 1.029344  ]\n",
      "\n",
      "Epoch 134/3847\n",
      "Train Loss (log-MSE): 0.010735 | Train RMSE [mua, mus]: [0.00381258 2.0205905 ]\n",
      "Val   Loss (log-MSE): 0.014833 | Val   RMSE [mua, mus]: [0.00369749 2.1091683 ]\n",
      "\n",
      "Epoch 135/3847\n",
      "Train Loss (log-MSE): 0.008266 | Train RMSE [mua, mus]: [0.00262442 1.2548879 ]\n",
      "Val   Loss (log-MSE): 0.009000 | Val   RMSE [mua, mus]: [0.00363506 1.4399709 ]\n",
      "\n",
      "Epoch 136/3847\n",
      "Train Loss (log-MSE): 0.007428 | Train RMSE [mua, mus]: [0.00326112 1.2877735 ]\n",
      "Val   Loss (log-MSE): 0.004899 | Val   RMSE [mua, mus]: [0.00312148 1.4768755 ]\n",
      "\n",
      "Epoch 137/3847\n",
      "Train Loss (log-MSE): 0.007869 | Train RMSE [mua, mus]: [0.00347576 1.1843202 ]\n",
      "Val   Loss (log-MSE): 0.010005 | Val   RMSE [mua, mus]: [0.00549172 2.3705814 ]\n",
      "\n",
      "Epoch 138/3847\n",
      "Train Loss (log-MSE): 0.009236 | Train RMSE [mua, mus]: [0.00444729 1.4981515 ]\n",
      "Val   Loss (log-MSE): 0.016839 | Val   RMSE [mua, mus]: [0.00428113 1.7845619 ]\n",
      "\n",
      "Epoch 139/3847\n",
      "Train Loss (log-MSE): 0.016190 | Train RMSE [mua, mus]: [0.00481256 1.1410841 ]\n",
      "Val   Loss (log-MSE): 0.029243 | Val   RMSE [mua, mus]: [0.00545163 1.0447842 ]\n",
      "\n",
      "Epoch 140/3847\n",
      "Train Loss (log-MSE): 0.010674 | Train RMSE [mua, mus]: [0.00376569 1.5135798 ]\n",
      "Val   Loss (log-MSE): 0.016829 | Val   RMSE [mua, mus]: [0.00471091 1.7174516 ]\n",
      "\n",
      "Epoch 141/3847\n",
      "Train Loss (log-MSE): 0.005797 | Train RMSE [mua, mus]: [0.00347203 1.2005908 ]\n",
      "Val   Loss (log-MSE): 0.004519 | Val   RMSE [mua, mus]: [0.00250248 1.6505353 ]\n",
      "\n",
      "Epoch 142/3847\n",
      "Train Loss (log-MSE): 0.004093 | Train RMSE [mua, mus]: [0.00305639 1.0306889 ]\n",
      "Val   Loss (log-MSE): 0.003086 | Val   RMSE [mua, mus]: [0.00261969 1.227812  ]\n",
      "\n",
      "Epoch 143/3847\n",
      "Train Loss (log-MSE): 0.005843 | Train RMSE [mua, mus]: [0.00265094 1.0991877 ]\n",
      "Val   Loss (log-MSE): 0.010107 | Val   RMSE [mua, mus]: [0.00336374 1.4654131 ]\n",
      "\n",
      "Epoch 144/3847\n",
      "Train Loss (log-MSE): 0.006105 | Train RMSE [mua, mus]: [0.00248513 1.0706623 ]\n",
      "Val   Loss (log-MSE): 0.010027 | Val   RMSE [mua, mus]: [0.00229488 1.7078586 ]\n",
      "\n",
      "Epoch 145/3847\n",
      "Train Loss (log-MSE): 0.010530 | Train RMSE [mua, mus]: [0.00399097 1.2094032 ]\n",
      "Val   Loss (log-MSE): 0.002120 | Val   RMSE [mua, mus]: [8.1543799e-04 1.2740555e+00]\n",
      "\n",
      "Epoch 146/3847\n",
      "Train Loss (log-MSE): 0.006563 | Train RMSE [mua, mus]: [0.00345352 0.9599292 ]\n",
      "Val   Loss (log-MSE): 0.003567 | Val   RMSE [mua, mus]: [0.00126954 0.77084994]\n",
      "\n",
      "Epoch 147/3847\n",
      "Train Loss (log-MSE): 0.007849 | Train RMSE [mua, mus]: [0.00321447 0.8906674 ]\n",
      "Val   Loss (log-MSE): 0.005844 | Val   RMSE [mua, mus]: [0.00348663 1.1954323 ]\n",
      "\n",
      "Epoch 148/3847\n",
      "Train Loss (log-MSE): 0.010188 | Train RMSE [mua, mus]: [0.00417871 1.0728014 ]\n",
      "Val   Loss (log-MSE): 0.001655 | Val   RMSE [mua, mus]: [0.00130137 0.8549457 ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 149/3847\n",
      "Train Loss (log-MSE): 0.013491 | Train RMSE [mua, mus]: [0.00384039 1.0862881 ]\n",
      "Val   Loss (log-MSE): 0.005382 | Val   RMSE [mua, mus]: [0.00145075 1.2638314 ]\n",
      "\n",
      "Epoch 150/3847\n",
      "Train Loss (log-MSE): 0.006437 | Train RMSE [mua, mus]: [0.00246914 1.0164803 ]\n",
      "Val   Loss (log-MSE): 0.003702 | Val   RMSE [mua, mus]: [0.00175887 1.0233487 ]\n",
      "\n",
      "Epoch 151/3847\n",
      "Train Loss (log-MSE): 0.005127 | Train RMSE [mua, mus]: [0.00284298 0.9829997 ]\n",
      "Val   Loss (log-MSE): 0.011721 | Val   RMSE [mua, mus]: [0.0063919 0.9524241]\n",
      "\n",
      "Epoch 152/3847\n",
      "Train Loss (log-MSE): 0.004356 | Train RMSE [mua, mus]: [0.00290773 0.8488969 ]\n",
      "Val   Loss (log-MSE): 0.003377 | Val   RMSE [mua, mus]: [0.00194539 0.7793288 ]\n",
      "\n",
      "Epoch 153/3847\n",
      "Train Loss (log-MSE): 0.003609 | Train RMSE [mua, mus]: [0.0023853 0.9010039]\n",
      "Val   Loss (log-MSE): 0.006546 | Val   RMSE [mua, mus]: [0.00394794 1.0558021 ]\n",
      "\n",
      "Epoch 154/3847\n",
      "Train Loss (log-MSE): 0.003472 | Train RMSE [mua, mus]: [0.00239151 0.81922877]\n",
      "Val   Loss (log-MSE): 0.003307 | Val   RMSE [mua, mus]: [0.00187527 0.96739894]\n",
      "\n",
      "Epoch 155/3847\n",
      "Train Loss (log-MSE): 0.003814 | Train RMSE [mua, mus]: [0.00185556 0.88584906]\n",
      "Val   Loss (log-MSE): 0.003608 | Val   RMSE [mua, mus]: [0.00254086 0.8384487 ]\n",
      "\n",
      "Epoch 156/3847\n",
      "Train Loss (log-MSE): 0.003999 | Train RMSE [mua, mus]: [0.00178857 1.163323  ]\n",
      "Val   Loss (log-MSE): 0.001556 | Val   RMSE [mua, mus]: [0.00123956 0.8593237 ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 157/3847\n",
      "Train Loss (log-MSE): 0.003071 | Train RMSE [mua, mus]: [0.00168169 0.97072417]\n",
      "Val   Loss (log-MSE): 0.003435 | Val   RMSE [mua, mus]: [0.00230841 1.4278435 ]\n",
      "\n",
      "Epoch 158/3847\n",
      "Train Loss (log-MSE): 0.003118 | Train RMSE [mua, mus]: [0.00182823 0.88582313]\n",
      "Val   Loss (log-MSE): 0.003324 | Val   RMSE [mua, mus]: [0.00308847 1.4244454 ]\n",
      "\n",
      "Epoch 159/3847\n",
      "Train Loss (log-MSE): 0.003959 | Train RMSE [mua, mus]: [0.00238884 0.79982877]\n",
      "Val   Loss (log-MSE): 0.006437 | Val   RMSE [mua, mus]: [0.00348276 1.335099  ]\n",
      "\n",
      "Epoch 160/3847\n",
      "Train Loss (log-MSE): 0.003901 | Train RMSE [mua, mus]: [0.00230906 0.7751702 ]\n",
      "Val   Loss (log-MSE): 0.004622 | Val   RMSE [mua, mus]: [1.3191043e-03 1.3717446e+00]\n",
      "\n",
      "Epoch 161/3847\n",
      "Train Loss (log-MSE): 0.004700 | Train RMSE [mua, mus]: [0.00287482 0.8864316 ]\n",
      "Val   Loss (log-MSE): 0.006941 | Val   RMSE [mua, mus]: [0.00151132 0.88018155]\n",
      "\n",
      "Epoch 162/3847\n",
      "Train Loss (log-MSE): 0.004167 | Train RMSE [mua, mus]: [0.0025401 0.7501735]\n",
      "Val   Loss (log-MSE): 0.005075 | Val   RMSE [mua, mus]: [0.00451677 0.95492697]\n",
      "\n",
      "Epoch 163/3847\n",
      "Train Loss (log-MSE): 0.007671 | Train RMSE [mua, mus]: [0.00368166 1.2164972 ]\n",
      "Val   Loss (log-MSE): 0.036647 | Val   RMSE [mua, mus]: [0.00476354 2.5090344 ]\n",
      "\n",
      "Epoch 164/3847\n",
      "Train Loss (log-MSE): 0.011111 | Train RMSE [mua, mus]: [0.00436479 1.0861388 ]\n",
      "Val   Loss (log-MSE): 0.022653 | Val   RMSE [mua, mus]: [0.00751446 1.4232763 ]\n",
      "\n",
      "Epoch 165/3847\n",
      "Train Loss (log-MSE): 0.006400 | Train RMSE [mua, mus]: [0.00249399 1.086101  ]\n",
      "Val   Loss (log-MSE): 0.003981 | Val   RMSE [mua, mus]: [0.0017496  0.80984384]\n",
      "\n",
      "Epoch 166/3847\n",
      "Train Loss (log-MSE): 0.007790 | Train RMSE [mua, mus]: [0.00275888 1.2519668 ]\n",
      "Val   Loss (log-MSE): 0.006415 | Val   RMSE [mua, mus]: [0.00240971 1.3512433 ]\n",
      "\n",
      "Epoch 167/3847\n",
      "Train Loss (log-MSE): 0.008859 | Train RMSE [mua, mus]: [0.00433098 1.3826575 ]\n",
      "Val   Loss (log-MSE): 0.003421 | Val   RMSE [mua, mus]: [0.00143328 1.0463624 ]\n",
      "\n",
      "Epoch 168/3847\n",
      "Train Loss (log-MSE): 0.010134 | Train RMSE [mua, mus]: [0.00429012 1.4996184 ]\n",
      "Val   Loss (log-MSE): 0.011004 | Val   RMSE [mua, mus]: [0.00247302 1.2557292 ]\n",
      "\n",
      "Epoch 169/3847\n",
      "Train Loss (log-MSE): 0.007772 | Train RMSE [mua, mus]: [0.00345412 1.5574934 ]\n",
      "Val   Loss (log-MSE): 0.017665 | Val   RMSE [mua, mus]: [0.0028508 2.689816 ]\n",
      "\n",
      "Epoch 170/3847\n",
      "Train Loss (log-MSE): 0.009130 | Train RMSE [mua, mus]: [0.0027359 1.6673605]\n",
      "Val   Loss (log-MSE): 0.004896 | Val   RMSE [mua, mus]: [0.00249006 0.85981345]\n",
      "\n",
      "Epoch 171/3847\n",
      "Train Loss (log-MSE): 0.006482 | Train RMSE [mua, mus]: [0.0029949 1.2808009]\n",
      "Val   Loss (log-MSE): 0.014436 | Val   RMSE [mua, mus]: [0.00412524 1.604041  ]\n",
      "\n",
      "Epoch 172/3847\n",
      "Train Loss (log-MSE): 0.010523 | Train RMSE [mua, mus]: [0.0035285 1.6960166]\n",
      "Val   Loss (log-MSE): 0.018035 | Val   RMSE [mua, mus]: [0.00803215 1.1444341 ]\n",
      "\n",
      "Epoch 173/3847\n",
      "Train Loss (log-MSE): 0.008325 | Train RMSE [mua, mus]: [0.00383365 1.6223018 ]\n",
      "Val   Loss (log-MSE): 0.006296 | Val   RMSE [mua, mus]: [1.7539148e-03 2.1218436e+00]\n",
      "\n",
      "Epoch 174/3847\n",
      "Train Loss (log-MSE): 0.004926 | Train RMSE [mua, mus]: [0.00242404 1.54431   ]\n",
      "Val   Loss (log-MSE): 0.003820 | Val   RMSE [mua, mus]: [0.00195289 1.0430319 ]\n",
      "\n",
      "Epoch 175/3847\n",
      "Train Loss (log-MSE): 0.005811 | Train RMSE [mua, mus]: [0.00256378 1.5174153 ]\n",
      "Val   Loss (log-MSE): 0.007412 | Val   RMSE [mua, mus]: [0.00201512 1.4695987 ]\n",
      "\n",
      "Epoch 176/3847\n",
      "Train Loss (log-MSE): 0.005045 | Train RMSE [mua, mus]: [0.00262095 1.3501573 ]\n",
      "Val   Loss (log-MSE): 0.002550 | Val   RMSE [mua, mus]: [0.00140373 1.2357109 ]\n",
      "\n",
      "Epoch 177/3847\n",
      "Train Loss (log-MSE): 0.003269 | Train RMSE [mua, mus]: [0.00161733 1.1508461 ]\n",
      "Val   Loss (log-MSE): 0.003277 | Val   RMSE [mua, mus]: [0.00182478 1.097583  ]\n",
      "\n",
      "Epoch 178/3847\n",
      "Train Loss (log-MSE): 0.004365 | Train RMSE [mua, mus]: [0.00213897 1.2317218 ]\n",
      "Val   Loss (log-MSE): 0.003704 | Val   RMSE [mua, mus]: [8.8827318e-04 1.1235689e+00]\n",
      "\n",
      "Epoch 179/3847\n",
      "Train Loss (log-MSE): 0.003465 | Train RMSE [mua, mus]: [0.00172371 1.2569178 ]\n",
      "Val   Loss (log-MSE): 0.003411 | Val   RMSE [mua, mus]: [8.4237207e-04 1.0064236e+00]\n",
      "\n",
      "Epoch 180/3847\n",
      "Train Loss (log-MSE): 0.008842 | Train RMSE [mua, mus]: [0.00338499 1.0442456 ]\n",
      "Val   Loss (log-MSE): 0.003049 | Val   RMSE [mua, mus]: [0.00315103 1.4413867 ]\n",
      "\n",
      "Epoch 181/3847\n",
      "Train Loss (log-MSE): 0.005727 | Train RMSE [mua, mus]: [0.00306628 1.1325028 ]\n",
      "Val   Loss (log-MSE): 0.004073 | Val   RMSE [mua, mus]: [1.8612777e-03 2.0243530e+00]\n",
      "\n",
      "Epoch 182/3847\n",
      "Train Loss (log-MSE): 0.006069 | Train RMSE [mua, mus]: [0.00272412 1.1523263 ]\n",
      "Val   Loss (log-MSE): 0.008418 | Val   RMSE [mua, mus]: [0.00239591 0.8025929 ]\n",
      "\n",
      "Epoch 183/3847\n",
      "Train Loss (log-MSE): 0.009765 | Train RMSE [mua, mus]: [0.00495222 1.2078384 ]\n",
      "Val   Loss (log-MSE): 0.009254 | Val   RMSE [mua, mus]: [0.00573939 0.7432248 ]\n",
      "\n",
      "Epoch 184/3847\n",
      "Train Loss (log-MSE): 0.011823 | Train RMSE [mua, mus]: [0.00456001 1.653481  ]\n",
      "Val   Loss (log-MSE): 0.006911 | Val   RMSE [mua, mus]: [0.00382693 1.0156457 ]\n",
      "\n",
      "Epoch 185/3847\n",
      "Train Loss (log-MSE): 0.007013 | Train RMSE [mua, mus]: [0.00403176 1.2627405 ]\n",
      "Val   Loss (log-MSE): 0.025991 | Val   RMSE [mua, mus]: [0.00361864 2.997072  ]\n",
      "\n",
      "Epoch 186/3847\n",
      "Train Loss (log-MSE): 0.007225 | Train RMSE [mua, mus]: [0.00394741 1.2755558 ]\n",
      "Val   Loss (log-MSE): 0.008627 | Val   RMSE [mua, mus]: [1.7731143e-03 1.8316976e+00]\n",
      "\n",
      "Epoch 187/3847\n",
      "Train Loss (log-MSE): 0.004922 | Train RMSE [mua, mus]: [0.00224178 1.1078568 ]\n",
      "Val   Loss (log-MSE): 0.012181 | Val   RMSE [mua, mus]: [0.0048083 1.3827747]\n",
      "\n",
      "Epoch 188/3847\n",
      "Train Loss (log-MSE): 0.008061 | Train RMSE [mua, mus]: [0.00327209 1.0894902 ]\n",
      "Val   Loss (log-MSE): 0.003902 | Val   RMSE [mua, mus]: [0.00181141 0.8761843 ]\n",
      "\n",
      "Epoch 189/3847\n",
      "Train Loss (log-MSE): 0.004077 | Train RMSE [mua, mus]: [0.00241259 0.84897095]\n",
      "Val   Loss (log-MSE): 0.006321 | Val   RMSE [mua, mus]: [0.00179085 1.190952  ]\n",
      "\n",
      "Epoch 190/3847\n",
      "Train Loss (log-MSE): 0.002853 | Train RMSE [mua, mus]: [0.00203593 0.7759719 ]\n",
      "Val   Loss (log-MSE): 0.002453 | Val   RMSE [mua, mus]: [0.00182081 1.3693434 ]\n",
      "\n",
      "Epoch 191/3847\n",
      "Train Loss (log-MSE): 0.003854 | Train RMSE [mua, mus]: [0.0024644  0.85087293]\n",
      "Val   Loss (log-MSE): 0.003468 | Val   RMSE [mua, mus]: [0.00174994 1.3288351 ]\n",
      "\n",
      "Epoch 192/3847\n",
      "Train Loss (log-MSE): 0.004301 | Train RMSE [mua, mus]: [0.00244582 1.131135  ]\n",
      "Val   Loss (log-MSE): 0.004354 | Val   RMSE [mua, mus]: [1.0532141e-03 1.6407865e+00]\n",
      "\n",
      "Epoch 193/3847\n",
      "Train Loss (log-MSE): 0.003961 | Train RMSE [mua, mus]: [0.0020232 0.9733471]\n",
      "Val   Loss (log-MSE): 0.003476 | Val   RMSE [mua, mus]: [0.00182954 1.6886377 ]\n",
      "\n",
      "Epoch 194/3847\n",
      "Train Loss (log-MSE): 0.006264 | Train RMSE [mua, mus]: [0.00212463 1.0324095 ]\n",
      "Val   Loss (log-MSE): 0.006522 | Val   RMSE [mua, mus]: [0.00275592 1.9481648 ]\n",
      "\n",
      "Epoch 195/3847\n",
      "Train Loss (log-MSE): 0.006080 | Train RMSE [mua, mus]: [0.00238717 1.1703442 ]\n",
      "Val   Loss (log-MSE): 0.001828 | Val   RMSE [mua, mus]: [0.00108811 0.83897436]\n",
      "\n",
      "Epoch 196/3847\n",
      "Train Loss (log-MSE): 0.003701 | Train RMSE [mua, mus]: [0.0021415  0.79649204]\n",
      "Val   Loss (log-MSE): 0.004667 | Val   RMSE [mua, mus]: [0.00298039 1.036348  ]\n",
      "\n",
      "Epoch 197/3847\n",
      "Train Loss (log-MSE): 0.003685 | Train RMSE [mua, mus]: [0.00260672 1.0987278 ]\n",
      "Val   Loss (log-MSE): 0.004192 | Val   RMSE [mua, mus]: [0.00223611 1.1031798 ]\n",
      "\n",
      "Epoch 198/3847\n",
      "Train Loss (log-MSE): 0.004218 | Train RMSE [mua, mus]: [0.00256937 1.2161651 ]\n",
      "Val   Loss (log-MSE): 0.002375 | Val   RMSE [mua, mus]: [0.00298674 0.8241788 ]\n",
      "\n",
      "Epoch 199/3847\n",
      "Train Loss (log-MSE): 0.003451 | Train RMSE [mua, mus]: [0.00241314 0.7194204 ]\n",
      "Val   Loss (log-MSE): 0.002646 | Val   RMSE [mua, mus]: [0.00264813 0.8972169 ]\n",
      "\n",
      "Epoch 200/3847\n",
      "Train Loss (log-MSE): 0.004534 | Train RMSE [mua, mus]: [0.00244883 1.0644499 ]\n",
      "Val   Loss (log-MSE): 0.002491 | Val   RMSE [mua, mus]: [1.0389824e-03 1.3557662e+00]\n",
      "\n",
      "Epoch 201/3847\n",
      "Train Loss (log-MSE): 0.003306 | Train RMSE [mua, mus]: [0.00216568 0.98253554]\n",
      "Val   Loss (log-MSE): 0.005644 | Val   RMSE [mua, mus]: [1.3875306e-03 2.2825449e+00]\n",
      "\n",
      "Epoch 202/3847\n",
      "Train Loss (log-MSE): 0.003179 | Train RMSE [mua, mus]: [0.00173021 1.1632735 ]\n",
      "Val   Loss (log-MSE): 0.003832 | Val   RMSE [mua, mus]: [1.718253e-03 1.939495e+00]\n",
      "\n",
      "Epoch 203/3847\n",
      "Train Loss (log-MSE): 0.003497 | Train RMSE [mua, mus]: [0.00167159 1.2005062 ]\n",
      "Val   Loss (log-MSE): 0.009425 | Val   RMSE [mua, mus]: [0.00272976 2.1366563 ]\n",
      "\n",
      "Epoch 204/3847\n",
      "Train Loss (log-MSE): 0.003461 | Train RMSE [mua, mus]: [0.00185585 1.4196213 ]\n",
      "Val   Loss (log-MSE): 0.004954 | Val   RMSE [mua, mus]: [0.00356125 0.839509  ]\n",
      "\n",
      "Epoch 205/3847\n",
      "Train Loss (log-MSE): 0.003878 | Train RMSE [mua, mus]: [0.00237848 1.071052  ]\n",
      "Val   Loss (log-MSE): 0.003772 | Val   RMSE [mua, mus]: [9.8992663e-04 1.0934138e+00]\n",
      "\n",
      "Epoch 206/3847\n",
      "Train Loss (log-MSE): 0.003437 | Train RMSE [mua, mus]: [0.00146089 1.1903923 ]\n",
      "Val   Loss (log-MSE): 0.004369 | Val   RMSE [mua, mus]: [0.00194414 0.7424444 ]\n",
      "\n",
      "Epoch 207/3847\n",
      "Train Loss (log-MSE): 0.003273 | Train RMSE [mua, mus]: [0.00222282 0.9211156 ]\n",
      "Val   Loss (log-MSE): 0.004137 | Val   RMSE [mua, mus]: [0.00278742 0.9311306 ]\n",
      "\n",
      "Epoch 208/3847\n",
      "Train Loss (log-MSE): 0.003576 | Train RMSE [mua, mus]: [0.00194061 1.1165148 ]\n",
      "Val   Loss (log-MSE): 0.005123 | Val   RMSE [mua, mus]: [0.00301205 0.8778983 ]\n",
      "\n",
      "Epoch 209/3847\n",
      "Train Loss (log-MSE): 0.004692 | Train RMSE [mua, mus]: [0.00275558 0.9090149 ]\n",
      "Val   Loss (log-MSE): 0.009389 | Val   RMSE [mua, mus]: [0.00293519 1.033788  ]\n",
      "\n",
      "Epoch 210/3847\n",
      "Train Loss (log-MSE): 0.007876 | Train RMSE [mua, mus]: [0.00329695 1.0816969 ]\n",
      "Val   Loss (log-MSE): 0.003847 | Val   RMSE [mua, mus]: [0.00183303 1.1693709 ]\n",
      "\n",
      "Epoch 211/3847\n",
      "Train Loss (log-MSE): 0.008526 | Train RMSE [mua, mus]: [0.00328427 1.4775488 ]\n",
      "Val   Loss (log-MSE): 0.003138 | Val   RMSE [mua, mus]: [0.0022609  0.94143605]\n",
      "\n",
      "Epoch 212/3847\n",
      "Train Loss (log-MSE): 0.004489 | Train RMSE [mua, mus]: [0.0021564 0.9952744]\n",
      "Val   Loss (log-MSE): 0.004781 | Val   RMSE [mua, mus]: [0.0033362 0.9543923]\n",
      "\n",
      "Epoch 213/3847\n",
      "Train Loss (log-MSE): 0.007403 | Train RMSE [mua, mus]: [0.00328904 1.1880283 ]\n",
      "Val   Loss (log-MSE): 0.017165 | Val   RMSE [mua, mus]: [0.00429204 1.7864904 ]\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# TRIAL RUN\n",
    "# dataset -> split -> auto epochs -> metrics sanity checks\n",
    "# ============================\n",
    "\n",
    "def make_train_val_loaders(dataset, batch_size=32, val_frac=0.2, seed=42):\n",
    "    n = len(dataset)\n",
    "    idx = np.arange(n)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    split = int(n * (1 - val_frac))\n",
    "    train_idx = idx[:split]\n",
    "    val_idx = idx[split:]\n",
    "\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def quick_eval_lin_rmse(model, loader, device, eps=1e-12, exp_clip=20.0):\n",
    "    \"\"\"Compute RMSE in original units on a loader (model outputs log-space).\"\"\"\n",
    "    model.eval()\n",
    "    sum_sq = torch.zeros(2, device=device)\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).float()\n",
    "            ylog = torch.log(y.clamp_min(eps))\n",
    "            plog = model(x).view_as(ylog)\n",
    "            plin = torch.exp(plog.clamp(-exp_clip, exp_clip))\n",
    "            err = plin - y\n",
    "            sum_sq += (err ** 2).sum(dim=0)\n",
    "            n += y.shape[0]\n",
    "    return torch.sqrt(sum_sq / max(1, n)).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Paths + config\n",
    "# ----------------------------\n",
    "mat_path = r\"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/Pre-obtained data/dataset_homo_small.mat\"\n",
    "\n",
    "cfg = {\n",
    "    \"crop_t_max\": 6.0,\n",
    "    \"sg_window\": 21,\n",
    "    \"sg_order\": 1,\n",
    "    \"eps\": 1e-12,\n",
    "    \"channel_mode\": \"hybrid_4ch\",\n",
    "    \"input_rep\": \"raw_log\",\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Device\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Dataset + split\n",
    "# ----------------------------\n",
    "dataset = DTOFDataset(mat_path, cfg)\n",
    "\n",
    "batch_size = 32\n",
    "val_frac = 0.2\n",
    "seed = 42\n",
    "\n",
    "train_loader, val_loader = make_train_val_loaders(dataset, batch_size=batch_size, val_frac=val_frac, seed=seed)\n",
    "\n",
    "N_total = len(dataset)\n",
    "N_train = len(train_loader.dataset)\n",
    "N_val = len(val_loader.dataset)\n",
    "\n",
    "print(\"Total samples:\", N_total)\n",
    "print(\"Train samples:\", N_train)\n",
    "print(\"Val samples  :\", N_val)\n",
    "print(\"Signal shape :\", dataset[0][0].shape, \"Label shape:\", dataset[0][1].shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Model + optimizer\n",
    "# ----------------------------\n",
    "model = Net(cfg, input_length=dataset.T, output_dim=2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Choose epochs based on target optimiser steps\n",
    "# ----------------------------\n",
    "target_steps = 50_000   # adjust later (e.g., 20k for quick, 100k+ for full)\n",
    "steps_per_epoch = math.ceil(N_train / batch_size)\n",
    "\n",
    "num_epochs = math.ceil(target_steps / steps_per_epoch)\n",
    "\n",
    "print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "print(f\"target_steps   : {target_steps}\")\n",
    "print(f\"num_epochs     : {num_epochs}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Pre-train sanity RMSE (random model)\n",
    "# ----------------------------\n",
    "rmse0_train = quick_eval_lin_rmse(model, train_loader, device, eps=cfg[\"eps\"])\n",
    "rmse0_val = quick_eval_lin_rmse(model, val_loader, device, eps=cfg[\"eps\"])\n",
    "print(\"Pre-train RMSE train [mua, mus]:\", rmse0_train)\n",
    "print(\"Pre-train RMSE val   [mua, mus]:\", rmse0_val)\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Train\n",
    "# ----------------------------\n",
    "_ = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    save_path=\"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/CNN_initial_saved_pytorch_model_weights/best_trial_TRIAL.pt\",\n",
    "    eps=cfg[\"eps\"],\n",
    "    print_every=1,\n",
    "    # if you added early stopping:\n",
    "    # patience=20,\n",
    "    # min_delta=1e-4,\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 8) Post-train sanity RMSE\n",
    "# ----------------------------\n",
    "rmse1_train = quick_eval_lin_rmse(model, train_loader, device, eps=cfg[\"eps\"])\n",
    "rmse1_val = quick_eval_lin_rmse(model, val_loader, device, eps=cfg[\"eps\"])\n",
    "print(\"Post-train RMSE train [mua, mus]:\", rmse1_train)\n",
    "print(\"Post-train RMSE val   [mua, mus]:\", rmse1_val)\n",
    "\n",
    "# ----------------------------\n",
    "# 9) One-batch forward shape check\n",
    "# ----------------------------\n",
    "signals, labels = next(iter(train_loader))\n",
    "out = model(signals.to(device))\n",
    "print(\"One-batch:\")\n",
    "print(\"  signals:\", signals.shape)\n",
    "print(\"  labels :\", labels.shape)\n",
    "print(\"  output :\", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8908676a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
