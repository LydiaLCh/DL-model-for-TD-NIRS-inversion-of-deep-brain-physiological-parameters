{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b73156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import random \n",
    "import torch \n",
    "from torch import nn \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset, DataLoader,Subset\n",
    "from scipy.signal import savgol_filter \n",
    "import h5py\n",
    "random.seed(0)\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18ef4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Savitzky Golay filter parameters \n",
    "order = 1\n",
    "frame_length = 21\n",
    "eps = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b40d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b358256",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTOFDataset(Dataset):\n",
    "    \"\"\"\n",
    "        DTOF dataset for MATLAB v7.3 (.mat, HDF5) files.\n",
    "\n",
    "        Required datasets inside .mat:\n",
    "            X : (Nt, N) or (N, Nt)  reflectance DTOFs\n",
    "            y : (2, N)  or (N, 2)   [mua, mus']\n",
    "            t : (Nt,)              time vector in seconds (~1e-12 resolution)\n",
    "\n",
    "        Preprocessing:\n",
    "            - convert t from seconds -> ns\n",
    "            - crop [0, crop_t_max] ns\n",
    "            - Savitzky–Golay smoothing\n",
    "            - clip small values to eps\n",
    "            - input representation:\n",
    "                * \"raw\"      -> use reflectance (smoothed+clipped)\n",
    "                * \"log\"      -> use log(reflectance)\n",
    "                * \"raw_log\"  -> concatenate raw and log along channel dimension\n",
    "            - channel construction:\n",
    "                * \"single\"         -> 1 channel (full)\n",
    "                * \"early_mid_late\" -> 3 channels (early/mid/late masks)\n",
    "                * \"hybrid_4ch\"     -> 4 channels (full + early/mid/late masks)\n",
    "\n",
    "        Returns:\n",
    "            signal: (C, T) float32 tensor\n",
    "            label:  (2,) float32 tensor [mua, mus']  (raw labels for now)\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, mat_path: str, cfg: dict):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # ---------- load HDF5 (.mat v7.3) ----------\n",
    "        with h5py.File(mat_path, \"r\") as f:\n",
    "            X = np.array(f[\"X\"], dtype=np.float32)\n",
    "            y = np.array(f[\"y\"], dtype=np.float32)\n",
    "            t = np.array(f[\"t\"], dtype=np.float32).squeeze()\n",
    "\n",
    "        # ---------- normalise shapes ----------\n",
    "        # X -> (N, Nt)\n",
    "        if X.shape[0] == t.shape[0]:\n",
    "            X = X.T\n",
    "\n",
    "        # y -> (N, 2)\n",
    "        if y.shape[0] == 2:\n",
    "            y = y.T\n",
    "\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError(f\"Expected X to be 2D, got {X.shape}\")\n",
    "        if y.ndim != 2 or y.shape[1] != 2:\n",
    "            raise ValueError(f\"Expected y to be (N,2), got {y.shape}\")\n",
    "        if t.ndim != 1:\n",
    "            raise ValueError(f\"Expected t to be (Nt,), got {t.shape}\")\n",
    "        if X.shape[1] != t.shape[0]:\n",
    "            raise ValueError(f\"X and t mismatch: X Nt={X.shape[1]} vs t Nt={t.shape[0]}\")\n",
    "\n",
    "        # ---------- time: seconds -> ns ----------\n",
    "        t_ns = t * 1e9\n",
    "\n",
    "        # ---------- crop ----------\n",
    "        crop_t_max = float(cfg[\"crop_t_max\"])  # ns\n",
    "        t_mask = (t_ns >= 0.0) & (t_ns <= crop_t_max)\n",
    "        if not np.any(t_mask):\n",
    "            raise ValueError(\n",
    "                f\"Cropping removed all points. \"\n",
    "                f\"t_ns range=[{t_ns.min():.3g}, {t_ns.max():.3g}] ns, crop_t_max={crop_t_max}\"\n",
    "            )\n",
    "\n",
    "        t_ns = t_ns[t_mask]              # (T,)\n",
    "        dtof = X[:, t_mask]              # (N,T)\n",
    "\n",
    "        N, T = dtof.shape\n",
    "\n",
    "        # ---------- Savitzky–Golay ----------\n",
    "        sg_window = int(cfg[\"sg_window\"])\n",
    "        sg_order = int(cfg[\"sg_order\"])\n",
    "\n",
    "        # enforce validity (odd, > order, <= T)\n",
    "        if sg_window % 2 == 0:\n",
    "            sg_window += 1\n",
    "        if sg_window <= sg_order:\n",
    "            sg_window = sg_order + 2\n",
    "            if sg_window % 2 == 0:\n",
    "                sg_window += 1\n",
    "        if sg_window > T:\n",
    "            sg_window = T if (T % 2 == 1) else (T - 1)\n",
    "\n",
    "        if sg_window >= 3:\n",
    "            dtof = savgol_filter(dtof, sg_window, sg_order, axis=1)\n",
    "\n",
    "        # ---------- clip ----------\n",
    "        eps = float(cfg.get(\"eps\", 1e-12))\n",
    "        dtof[dtof < eps] = eps\n",
    "\n",
    "        # ---------- choose representation ----------\n",
    "        input_rep = cfg.get(\"input_rep\", \"log\")  # \"raw\" | \"log\" | \"raw_log\"\n",
    "\n",
    "        dtof_raw = dtof.astype(np.float32)\n",
    "        dtof_log = np.log(dtof_raw).astype(np.float32)\n",
    "\n",
    "        # ---------- build channels ----------\n",
    "        if input_rep == \"raw\":\n",
    "            channels = self.build_channels(t_ns, dtof_raw, cfg[\"channel_mode\"])  # (N,C,T)\n",
    "\n",
    "        elif input_rep == \"log\":\n",
    "            channels = self.build_channels(t_ns, dtof_log, cfg[\"channel_mode\"])  # (N,C,T)\n",
    "\n",
    "        elif input_rep == \"raw_log\":\n",
    "            ch_raw = self.build_channels(t_ns, dtof_raw, cfg[\"channel_mode\"])    # (N,C,T)\n",
    "            ch_log = self.build_channels(t_ns, dtof_log, cfg[\"channel_mode\"])    # (N,C,T)\n",
    "            channels = np.concatenate([ch_raw, ch_log], axis=1)                  # (N,2C,T)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown input_rep: {input_rep}\")\n",
    "\n",
    "        # ---------- to torch ----------\n",
    "        self.signals = torch.tensor(channels, dtype=torch.float32)  # (N,C,T)\n",
    "        self.labels = torch.tensor(y, dtype=torch.float32)          # (N,2)\n",
    "\n",
    "        self.N, self.C, self.T = self.signals.shape\n",
    "\n",
    "    def build_channels(self, t_ns: np.ndarray, dtof: np.ndarray, mode: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Channel masks in ns:\n",
    "            early: 0–0.5 ns\n",
    "            mid:   0.5–4 ns\n",
    "            late:  4–crop_t_max ns\n",
    "        \"\"\"\n",
    "        N, T = dtof.shape\n",
    "        crop_t_max = float(self.cfg[\"crop_t_max\"])\n",
    "\n",
    "        if mode == \"single\":\n",
    "            return dtof[:, None, :]  # (N,1,T)\n",
    "\n",
    "        early = ((t_ns >= 0.0) & (t_ns < 0.5)).astype(np.float32)\n",
    "        mid   = ((t_ns >= 0.5) & (t_ns < 4.0)).astype(np.float32)\n",
    "        late  = ((t_ns >= 4.0) & (t_ns <= crop_t_max)).astype(np.float32)\n",
    "\n",
    "        masks = np.stack([early, mid, late], axis=0)  # (3,T)\n",
    "\n",
    "        if mode == \"early_mid_late\":\n",
    "            return dtof[:, None, :] * masks[None, :, :]  # (N,3,T)\n",
    "\n",
    "        if mode == \"hybrid_4ch\":\n",
    "            full = dtof[:, None, :]                         # (N,1,T)\n",
    "            gated = dtof[:, None, :] * masks[None, :, :]    # (N,3,T)\n",
    "            return np.concatenate([full, gated], axis=1)    # (N,4,T)\n",
    "\n",
    "        raise ValueError(f\"Unknown channel_mode: {mode}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.N\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.signals[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN for 1D DTOF signals with flexible input channels.\n",
    "\n",
    "    Channel counts (C) depend on:\n",
    "        channel_mode:\n",
    "            - \"single\"         -> 1\n",
    "            - \"early_mid_late\" -> 3\n",
    "            - \"hybrid_4ch\"     -> 4\n",
    "        input_rep:\n",
    "            - \"raw\" / \"log\"    -> multiplier 1\n",
    "            - \"raw_log\"        -> multiplier 2\n",
    "\n",
    "    So:\n",
    "        C = base_C * (2 if input_rep == \"raw_log\" else 1)\n",
    "\n",
    "    Optional tunables in cfg:\n",
    "        cfg[\"use_dilation\"] = True / False\n",
    "        cfg[\"kernels\"]      = [3, 5, 5]      # keep final kernel smaller to reduce over-smoothing\n",
    "        cfg[\"dilations\"]    = [1, 2, 4]      # increasing dilation expands receptive field\n",
    "        cfg[\"channels\"]     = [32, 32, 16]   # out_channels per block\n",
    "        cfg[\"pool_k\"]       = 2              # MaxPool kernel\n",
    "        cfg[\"pool_s\"]       = 2              # MaxPool stride\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg: dict, input_length: int = 3000, output_dim: int = 2):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # -----------------------------\n",
    "        # Infer input channels from cfg\n",
    "        # -----------------------------\n",
    "        base_C = {\"single\": 1, \"early_mid_late\": 3, \"hybrid_4ch\": 4}[cfg[\"channel_mode\"]]\n",
    "        mult = 2 if cfg.get(\"input_rep\", \"log\") == \"raw_log\" else 1\n",
    "        in_channels = base_C * mult\n",
    "\n",
    "        # -----------------------------\n",
    "        # Optional dilation settings\n",
    "        # -----------------------------\n",
    "        use_dilation = bool(cfg.get(\"use_dilation\", False))\n",
    "\n",
    "        # Kernels: increasing early->late but keep the final kernel modest\n",
    "        kernels = cfg.get(\"kernels\", [3, 5, 5])\n",
    "\n",
    "        # Dilations: increase only when use_dilation=True\n",
    "        dilations = cfg.get(\"dilations\", [1, 2, 4]) if use_dilation else [1, 1, 1]\n",
    "\n",
    "        # Out channels per conv block\n",
    "        chs = cfg.get(\"channels\", [32, 32, 16])\n",
    "\n",
    "        # Pooling\n",
    "        pool_k = int(cfg.get(\"pool_k\", 2))\n",
    "        pool_s = int(cfg.get(\"pool_s\", 2))\n",
    "\n",
    "        # Unpack \n",
    "        k1, k2, k3 = kernels\n",
    "        d1, d2, d3 = dilations\n",
    "\n",
    "        # -----------------------------\n",
    "        # Helper: SAME padding for 1D conv\n",
    "        # padding = dilation * (kernel - 1) / 2 (requires odd kernel)\n",
    "        # -----------------------------\n",
    "        def same_padding(kernel: int, dilation: int) -> int:\n",
    "            if kernel % 2 == 0:\n",
    "                raise ValueError(f\"Kernel size must be odd for SAME padding. Got kernel={kernel}.\")\n",
    "            return (dilation * (kernel - 1)) // 2\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convolution blocks\n",
    "        # -----------------------------\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=chs[0],\n",
    "            kernel_size=k1,\n",
    "            dilation=d1,\n",
    "            padding=same_padding(k1, d1),\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(chs[0])\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=pool_k, stride=pool_s)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=chs[0],\n",
    "            out_channels=chs[1],\n",
    "            kernel_size=k2,\n",
    "            dilation=d2,\n",
    "            padding=same_padding(k2, d2),\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(chs[1])\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=pool_k, stride=pool_s)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(\n",
    "            in_channels=chs[1],\n",
    "            out_channels=chs[2],\n",
    "            kernel_size=k3,\n",
    "            dilation=d3,\n",
    "            padding=same_padding(k3, d3),\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm1d(chs[2])\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=pool_k, stride=pool_s)\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Dynamic flatten dimension\n",
    "        # -----------------------------\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, input_length)\n",
    "            feat = self._forward_features(dummy)\n",
    "            self.flatten_dim = feat.shape[1]\n",
    "\n",
    "        # -----------------------------\n",
    "        # Fully connected head\n",
    "        # -----------------------------\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def _forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool1(self.act(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(self.act(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(self.act(self.bn3(self.conv3(x))))\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self._forward_features(x)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a581ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    save_path=None,\n",
    "    eps=1e-12,\n",
    "    print_every=1,\n",
    "    exp_clip=20.0,    # exp(20) ~ 4.85e8, safety for overflow\n",
    "    patience=20,\n",
    "    min_delta=0.0,\n",
    "    plot_path=None,   # optional: where to save loss curve png\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a model that predicts log(mua), log(mus').\n",
    "    - Optimizes log-MSE loss\n",
    "    - Reports RMSE and mean absolute % error in original (linear) units\n",
    "    - Early stopping + optional best checkpoint saving\n",
    "    - Tracks and plots train/val loss curves over epochs\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # -------------------------\n",
    "        # TRAIN\n",
    "        # -------------------------\n",
    "        model.train()\n",
    "\n",
    "        tr_loss_sum = 0.0\n",
    "        tr_loss_count = 0\n",
    "\n",
    "        tr_sum_sq  = torch.zeros(2, device=device)\n",
    "        tr_pct_sum = torch.zeros(2, device=device)\n",
    "        tr_count = 0\n",
    "\n",
    "        for signals, labels in train_loader:\n",
    "            signals = signals.to(device)\n",
    "            labels  = labels.to(device).float()                 # (B,2) linear\n",
    "            B = labels.shape[0]\n",
    "\n",
    "            log_labels = torch.log(labels.clamp_min(eps))       # (B,2) log\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds_log = model(signals).view_as(log_labels)      # (B,2)\n",
    "            loss = loss_fn(preds_log, log_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # per-sample accurate averaging\n",
    "            tr_loss_sum += loss.item() * B\n",
    "            tr_loss_count += B\n",
    "\n",
    "            # Metrics in original units\n",
    "            with torch.no_grad():\n",
    "                preds_lin = torch.exp(preds_log.clamp(-exp_clip, exp_clip))\n",
    "                err = preds_lin - labels\n",
    "\n",
    "                abs_pct_err = (100.0 * err / labels.clamp_min(eps)).abs()  # (B,2)\n",
    "\n",
    "                tr_sum_sq  += (err ** 2).sum(dim=0)\n",
    "                tr_pct_sum += abs_pct_err.sum(dim=0)\n",
    "                tr_count   += B\n",
    "\n",
    "        train_loss = tr_loss_sum / max(1, tr_loss_count)\n",
    "        train_rmse = torch.sqrt(tr_sum_sq / max(1, tr_count)).detach().cpu().numpy()\n",
    "        train_pct_err = (tr_pct_sum / max(1, tr_count)).detach().cpu().numpy()\n",
    "\n",
    "        # -------------------------\n",
    "        # VALIDATE\n",
    "        # -------------------------\n",
    "        model.eval()\n",
    "\n",
    "        va_loss_sum = 0.0\n",
    "        va_loss_count = 0\n",
    "\n",
    "        va_sum_sq  = torch.zeros(2, device=device)\n",
    "        va_pct_sum = torch.zeros(2, device=device)\n",
    "        va_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in val_loader:\n",
    "                signals = signals.to(device)\n",
    "                labels  = labels.to(device).float()\n",
    "                B = labels.shape[0]\n",
    "\n",
    "                log_labels = torch.log(labels.clamp_min(eps))\n",
    "                preds_log  = model(signals).view_as(log_labels)\n",
    "\n",
    "                loss = loss_fn(preds_log, log_labels)\n",
    "                va_loss_sum += loss.item() * B\n",
    "                va_loss_count += B\n",
    "\n",
    "                preds_lin = torch.exp(preds_log.clamp(-exp_clip, exp_clip))\n",
    "                err = preds_lin - labels\n",
    "\n",
    "                abs_pct_err = (100.0 * err / labels.clamp_min(eps)).abs()\n",
    "\n",
    "                va_sum_sq  += (err ** 2).sum(dim=0)\n",
    "                va_pct_sum += abs_pct_err.sum(dim=0)\n",
    "                va_count   += B\n",
    "\n",
    "        val_loss = va_loss_sum / max(1, va_loss_count)\n",
    "        val_rmse = torch.sqrt(va_sum_sq / max(1, va_count)).detach().cpu().numpy()\n",
    "        val_pct_err = (va_pct_sum / max(1, va_count)).detach().cpu().numpy()\n",
    "\n",
    "        # Track loss curves\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Print\n",
    "        if (epoch + 1) % print_every == 0:\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "            print(f\"Train Loss (log-MSE): {train_loss:.6f} | Train RMSE [μa, μs′]: {train_rmse}\")\n",
    "            print(f\"Train Mean Abs %Err [μa, μs′]: {train_pct_err}\")\n",
    "            print(f\"Val   Loss (log-MSE): {val_loss:.6f} | Val   RMSE [μa, μs′]: {val_rmse}\")\n",
    "            print(f\"Val   Mean Abs %Err [μa, μs′]: {val_pct_err}\")\n",
    "\n",
    "        # Early stopping + checkpoint\n",
    "        if val_loss < (best_val_loss - min_delta):\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            if save_path is not None:\n",
    "                os.makedirs(os.path.dirname(save_path) or \".\", exist_ok=True)\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\" -> Best validation so far, saved.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch + 1}: \"\n",
    "                      f\"no val improvement for {patience} epochs.\")\n",
    "                break\n",
    "\n",
    "    # -------------------------\n",
    "    # Plot loss curves\n",
    "    # -------------------------\n",
    "    if plot_path is None and save_path is not None:\n",
    "        # If caller passed .pt or .pth, this handles both nicely\n",
    "        root, ext = os.path.splitext(save_path)\n",
    "        plot_path = root + \"_loss_curves.png\"\n",
    "\n",
    "    if plot_path is not None:\n",
    "        os.makedirs(os.path.dirname(plot_path) or \".\", exist_ok=True)\n",
    "        plt.figure()\n",
    "        plt.plot(train_losses, label=\"Train log-MSE\")\n",
    "        plt.plot(val_losses,   label=\"Val log-MSE\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training and Validation Loss\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(plot_path, dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "        \"save_path\": save_path,\n",
    "        \"loss_plot\": plot_path,\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1bb93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_val_loaders(dataset, batch_size=32, val_frac=0.2, seed=42, shuffle_train=True):\n",
    "    n = len(dataset)\n",
    "    idx = np.arange(n)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    split = int(n * (1 - val_frac))\n",
    "    train_idx = idx[:split]\n",
    "    val_idx = idx[split:]\n",
    "\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle_train)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5483d70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dilation enabled: True\n",
      "kernels: [3, 5, 5] dilations: [1, 2, 4]\n",
      "sample: torch.Size([8, 3000]) torch.Size([2])\n",
      "model out: torch.Size([1, 2])\n",
      "signals: torch.Size([32, 8, 3000])\n",
      "labels: torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "# Trial run\n",
    "\n",
    "matlab_path = \"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/Pre-obtained data/dataset_homo_small.mat\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = {\n",
    "        \"crop_t_max\": 6.0,\n",
    "        \"sg_window\": frame_length,\n",
    "        \"sg_order\": order,\n",
    "        \"eps\": 1e-12,\n",
    "        \"channel_mode\": \"hybrid_4ch\",  # \"single\" | \"early_mid_late\" | \"hybrid_4ch\"\n",
    "        \"input_rep\": \"raw_log\",        # \"raw\" | \"log\" | \"raw_log\"\n",
    "\n",
    "        # ---- OPTIONAL DILATION EXPERIMENT ----\n",
    "        \"use_dilation\": True,          # <-- set False for baseline comparison\n",
    "        \"kernels\": [3, 5, 5],          # increasing kernels but smaller final kernel\n",
    "        \"dilations\": [1, 2, 4],        # increasing dilation\n",
    "        \"channels\": [32, 32, 16],      # optional: keep your original channels\n",
    "        \"pool_k\": 2,\n",
    "        \"pool_s\": 2,\n",
    "    }\n",
    "\n",
    "    print(\"Dilation enabled:\", cfg[\"use_dilation\"])\n",
    "    if cfg[\"use_dilation\"]:\n",
    "        print(\"kernels:\", cfg[\"kernels\"], \"dilations:\", cfg[\"dilations\"])\n",
    "\n",
    "    # Dataset sanity check \n",
    "\n",
    "    ds = DTOFDataset(matlab_path, cfg)\n",
    "    x, y = ds[0]\n",
    "    print(\"sample:\", x.shape, y.shape)\n",
    "\n",
    "    # Model sanity check\n",
    "\n",
    "    model = Net(cfg, input_length=ds.T, output_dim=2).to(device)\n",
    "    x = x.to(device)\n",
    "    out = model(x.unsqueeze(0))\n",
    "    print(\"model out:\", out.shape)\n",
    "\n",
    "    # Loader sanity check \n",
    "    \n",
    "    train_loader, val_loader = make_train_val_loaders(ds, batch_size=32, val_frac=0.2, seed=42)\n",
    "\n",
    "    signals, labels = next(iter(train_loader))\n",
    "    print(\"signals:\", signals.shape)  # (B, C, T)\n",
    "    print(\"labels:\", labels.shape)    # (B, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "414ed861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator: \n",
    "    \"\"\"\n",
    "    Evaluates a trained model that outputs log(mua), log(mus).\n",
    "    Reports MAE/RMSE in original units by exp().\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, device, eps=1e-12):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.eps = eps\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def evaluate(self, data_loader):\n",
    "        all_preds_lin = []\n",
    "        all_labels_lin = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for signals, labels in data_loader:\n",
    "                signals = signals.to(self.device)\n",
    "                labels = labels.to(self.device).float()              # (B,2) linear\n",
    "\n",
    "                preds_log = self.model(signals)                      # (B,2) log\n",
    "                preds_log = preds_log.view_as(labels)\n",
    "\n",
    "                preds_lin = torch.exp(preds_log)                     # back to linear\n",
    "\n",
    "                all_preds_lin.append(preds_lin.cpu())\n",
    "                all_labels_lin.append(labels.cpu())\n",
    "\n",
    "        preds = torch.cat(all_preds_lin, dim=0)\n",
    "        labs  = torch.cat(all_labels_lin, dim=0)\n",
    "\n",
    "        abs_err = torch.abs(preds - labs)\n",
    "        sq_err  = (preds - labs) ** 2\n",
    "\n",
    "        mae = abs_err.mean(dim=0)\n",
    "        rmse = torch.sqrt(sq_err.mean(dim=0))\n",
    "\n",
    "        return {\n",
    "            \"MAE\": mae.numpy(),\n",
    "            \"RMSE\": rmse.numpy(),\n",
    "            \"preds\": preds.numpy(),\n",
    "            \"labels\": labs.numpy(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f15bd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Total samples: 500\n",
      "Train samples: 400\n",
      "Val samples  : 100\n",
      "Signal shape : torch.Size([8, 3000]) Label shape: torch.Size([2])\n",
      "steps_per_epoch: 13\n",
      "target_steps   : 50000\n",
      "num_epochs     : 800\n",
      "\n",
      "======================================================================\n",
      "EXPERIMENT: baseline_no_dilation\n",
      "use_dilation=False | kernels=[3, 5, 5] | dilations=[1, 2, 4]\n",
      "======================================================================\n",
      "Pre-train RMSE train [mua, mus]: [ 4.6593733 13.841332 ]\n",
      "Pre-train RMSE val   [mua, mus]: [ 3.85406  13.790935]\n",
      "\n",
      "Epoch 1/800\n",
      "Train Loss (log-MSE): 2.751207 | Train RMSE [μa, μs′]: [ 0.3076432 10.961098 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [1236.8676   104.04612]\n",
      "Val   Loss (log-MSE): 3.564036 | Val   RMSE [μa, μs′]: [ 0.17821103 12.538977  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [953.43677  63.33407]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 2/800\n",
      "Train Loss (log-MSE): 0.388672 | Train RMSE [μa, μs′]: [0.02745555 6.278013  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [64.05608  44.462616]\n",
      "Val   Loss (log-MSE): 0.671356 | Val   RMSE [μa, μs′]: [0.03568224 8.792567  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [158.07097   38.202003]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 3/800\n",
      "Train Loss (log-MSE): 0.236031 | Train RMSE [μa, μs′]: [0.02195857 8.5796175 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [46.925827 36.85896 ]\n",
      "Val   Loss (log-MSE): 0.158670 | Val   RMSE [μa, μs′]: [0.02714281 4.1079135 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [63.777054 17.149536]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 4/800\n",
      "Train Loss (log-MSE): 0.109878 | Train RMSE [μa, μs′]: [0.0119871 6.820478 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [25.194012 31.41251 ]\n",
      "Val   Loss (log-MSE): 0.083039 | Val   RMSE [μa, μs′]: [0.0082131 4.1663256]\n",
      "Val   Mean Abs %Err [μa, μs′]: [34.77504  17.937141]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 5/800\n",
      "Train Loss (log-MSE): 0.111461 | Train RMSE [μa, μs′]: [0.00979578 3.9066088 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [34.259365 22.59451 ]\n",
      "Val   Loss (log-MSE): 0.055145 | Val   RMSE [μa, μs′]: [5.3636604e-03 6.0632210e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [16.335749 28.242561]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 6/800\n",
      "Train Loss (log-MSE): 0.075278 | Train RMSE [μa, μs′]: [0.00903531 4.155429  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [24.226082 20.234215]\n",
      "Val   Loss (log-MSE): 0.016328 | Val   RMSE [μa, μs′]: [0.00481778 2.9186954 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 8.457545 12.168645]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 7/800\n",
      "Train Loss (log-MSE): 0.034473 | Train RMSE [μa, μs′]: [0.00591354 3.3196943 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.278582 16.061373]\n",
      "Val   Loss (log-MSE): 0.019107 | Val   RMSE [μa, μs′]: [0.00744866 2.0873218 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [12.742529  9.36601 ]\n",
      "\n",
      "Epoch 8/800\n",
      "Train Loss (log-MSE): 0.045149 | Train RMSE [μa, μs′]: [0.0096525 4.5872188]\n",
      "Train Mean Abs %Err [μa, μs′]: [16.371807 17.592798]\n",
      "Val   Loss (log-MSE): 0.017887 | Val   RMSE [μa, μs′]: [0.00535018 2.4757192 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 8.108468 12.804264]\n",
      "\n",
      "Epoch 9/800\n",
      "Train Loss (log-MSE): 0.044680 | Train RMSE [μa, μs′]: [0.0059679 3.7675836]\n",
      "Train Mean Abs %Err [μa, μs′]: [12.138567 20.566042]\n",
      "Val   Loss (log-MSE): 0.026101 | Val   RMSE [μa, μs′]: [0.0036225 2.8054545]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 7.697974 17.19547 ]\n",
      "\n",
      "Epoch 10/800\n",
      "Train Loss (log-MSE): 0.047060 | Train RMSE [μa, μs′]: [0.00603309 2.9342256 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [19.180462 14.112851]\n",
      "Val   Loss (log-MSE): 0.017654 | Val   RMSE [μa, μs′]: [2.8247007e-03 2.8284822e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [10.595207  9.796272]\n",
      "\n",
      "Epoch 11/800\n",
      "Train Loss (log-MSE): 0.046165 | Train RMSE [μa, μs′]: [0.00850706 2.9266784 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [20.584867 13.251376]\n",
      "Val   Loss (log-MSE): 0.056887 | Val   RMSE [μa, μs′]: [0.00730141 1.7782159 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [24.664845  8.461484]\n",
      "\n",
      "Epoch 12/800\n",
      "Train Loss (log-MSE): 0.057147 | Train RMSE [μa, μs′]: [0.00745989 3.185537  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [19.293432 16.364058]\n",
      "Val   Loss (log-MSE): 0.022712 | Val   RMSE [μa, μs′]: [0.00241496 1.7449127 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [11.105278 13.232807]\n",
      "\n",
      "Epoch 13/800\n",
      "Train Loss (log-MSE): 0.050017 | Train RMSE [μa, μs′]: [0.00777255 2.2917721 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [23.255745 12.751898]\n",
      "Val   Loss (log-MSE): 0.019573 | Val   RMSE [μa, μs′]: [0.0026412 2.5824523]\n",
      "Val   Mean Abs %Err [μa, μs′]: [10.802563 10.751612]\n",
      "\n",
      "Epoch 14/800\n",
      "Train Loss (log-MSE): 0.033185 | Train RMSE [μa, μs′]: [0.00922117 2.4422238 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [16.366621 11.859554]\n",
      "Val   Loss (log-MSE): 0.023999 | Val   RMSE [μa, μs′]: [0.00462342 1.5155525 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [18.915329  8.845465]\n",
      "\n",
      "Epoch 15/800\n",
      "Train Loss (log-MSE): 0.033621 | Train RMSE [μa, μs′]: [0.00707433 2.1078792 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [17.390495 11.130246]\n",
      "Val   Loss (log-MSE): 0.010743 | Val   RMSE [μa, μs′]: [0.00217874 1.9276752 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 6.5957923 10.687262 ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 16/800\n",
      "Train Loss (log-MSE): 0.022230 | Train RMSE [μa, μs′]: [0.00468484 2.2163315 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [10.791211 12.797141]\n",
      "Val   Loss (log-MSE): 0.005932 | Val   RMSE [μa, μs′]: [0.00268547 1.2658608 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [5.707752  6.6008205]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 17/800\n",
      "Train Loss (log-MSE): 0.040667 | Train RMSE [μa, μs′]: [0.00650757 2.3460116 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [20.429934 11.580552]\n",
      "Val   Loss (log-MSE): 0.026954 | Val   RMSE [μa, μs′]: [0.00395224 1.6698198 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [20.409111  8.23643 ]\n",
      "\n",
      "Epoch 18/800\n",
      "Train Loss (log-MSE): 0.035323 | Train RMSE [μa, μs′]: [0.0058687 3.1421235]\n",
      "Train Mean Abs %Err [μa, μs′]: [16.558197 13.932487]\n",
      "Val   Loss (log-MSE): 0.031463 | Val   RMSE [μa, μs′]: [2.9943595e-03 3.0714469e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 9.1789255 21.555351 ]\n",
      "\n",
      "Epoch 19/800\n",
      "Train Loss (log-MSE): 0.029490 | Train RMSE [μa, μs′]: [0.00549356 3.098062  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [12.569529 14.945983]\n",
      "Val   Loss (log-MSE): 0.019160 | Val   RMSE [μa, μs′]: [0.00526293 2.4177232 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 9.190885 13.490366]\n",
      "\n",
      "Epoch 20/800\n",
      "Train Loss (log-MSE): 0.032786 | Train RMSE [μa, μs′]: [0.0072095 2.4518633]\n",
      "Train Mean Abs %Err [μa, μs′]: [15.869528 14.026045]\n",
      "Val   Loss (log-MSE): 0.026792 | Val   RMSE [μa, μs′]: [0.00551838 3.5127704 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [10.260803 13.671772]\n",
      "\n",
      "Epoch 21/800\n",
      "Train Loss (log-MSE): 0.027291 | Train RMSE [μa, μs′]: [0.00578182 2.5387092 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.866705 12.139658]\n",
      "Val   Loss (log-MSE): 0.016757 | Val   RMSE [μa, μs′]: [0.00706005 2.0595932 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [11.529651 12.80528 ]\n",
      "\n",
      "Epoch 22/800\n",
      "Train Loss (log-MSE): 0.020479 | Train RMSE [μa, μs′]: [0.00674351 2.212359  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [12.735482 10.353889]\n",
      "Val   Loss (log-MSE): 0.009272 | Val   RMSE [μa, μs′]: [0.00195336 1.9245833 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [6.4879694 8.4071455]\n",
      "\n",
      "Epoch 23/800\n",
      "Train Loss (log-MSE): 0.035112 | Train RMSE [μa, μs′]: [0.00646917 3.0530934 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [16.746712 13.873318]\n",
      "Val   Loss (log-MSE): 0.051936 | Val   RMSE [μa, μs′]: [2.8185104e-03 3.4473059e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [15.175828 25.490751]\n",
      "\n",
      "Epoch 24/800\n",
      "Train Loss (log-MSE): 0.024819 | Train RMSE [μa, μs′]: [0.00404599 2.6428094 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [12.260834 12.283364]\n",
      "Val   Loss (log-MSE): 0.016724 | Val   RMSE [μa, μs′]: [0.00413783 1.9232495 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [11.996781  8.219721]\n",
      "\n",
      "Epoch 25/800\n",
      "Train Loss (log-MSE): 0.013057 | Train RMSE [μa, μs′]: [0.00350795 1.9193634 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [ 7.8144746 10.002935 ]\n",
      "Val   Loss (log-MSE): 0.006186 | Val   RMSE [μa, μs′]: [0.0013384 1.3218155]\n",
      "Val   Mean Abs %Err [μa, μs′]: [4.918686  7.8754106]\n",
      "\n",
      "Epoch 26/800\n",
      "Train Loss (log-MSE): 0.016455 | Train RMSE [μa, μs′]: [0.00492866 1.5004948 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [12.167411   7.3470917]\n",
      "Val   Loss (log-MSE): 0.012469 | Val   RMSE [μa, μs′]: [0.00338919 1.5271409 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [11.300148  6.765623]\n",
      "\n",
      "Epoch 27/800\n",
      "Train Loss (log-MSE): 0.016185 | Train RMSE [μa, μs′]: [0.00485996 1.7491926 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [11.532202  7.822586]\n",
      "Val   Loss (log-MSE): 0.008743 | Val   RMSE [μa, μs′]: [0.00314107 1.824789  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [8.118917 7.503437]\n",
      "\n",
      "Epoch 28/800\n",
      "Train Loss (log-MSE): 0.011223 | Train RMSE [μa, μs′]: [0.00395178 1.4987578 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [8.181114 8.087423]\n",
      "Val   Loss (log-MSE): 0.012152 | Val   RMSE [μa, μs′]: [0.00345733 2.462355  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [6.6596236 9.120609 ]\n",
      "\n",
      "Epoch 29/800\n",
      "Train Loss (log-MSE): 0.023605 | Train RMSE [μa, μs′]: [0.00527123 2.530007  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [10.220157 10.519248]\n",
      "Val   Loss (log-MSE): 0.026014 | Val   RMSE [μa, μs′]: [0.005137  2.0879374]\n",
      "Val   Mean Abs %Err [μa, μs′]: [19.640203  9.889218]\n",
      "\n",
      "Epoch 30/800\n",
      "Train Loss (log-MSE): 0.011616 | Train RMSE [μa, μs′]: [0.00321254 1.513013  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [9.009599 8.00465 ]\n",
      "Val   Loss (log-MSE): 0.023063 | Val   RMSE [μa, μs′]: [0.00303748 2.135727  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [13.5828495 12.174402 ]\n",
      "\n",
      "Epoch 31/800\n",
      "Train Loss (log-MSE): 0.022346 | Train RMSE [μa, μs′]: [0.00484575 2.2070248 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.666119 10.212597]\n",
      "Val   Loss (log-MSE): 0.027892 | Val   RMSE [μa, μs′]: [0.00893968 1.9283375 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [22.911728  8.298631]\n",
      "\n",
      "Epoch 32/800\n",
      "Train Loss (log-MSE): 0.024263 | Train RMSE [μa, μs′]: [0.00602608 2.2037623 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.748229 10.824106]\n",
      "Val   Loss (log-MSE): 0.010649 | Val   RMSE [μa, μs′]: [0.00224912 2.0923374 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [6.3760176 8.395272 ]\n",
      "\n",
      "Epoch 33/800\n",
      "Train Loss (log-MSE): 0.017882 | Train RMSE [μa, μs′]: [0.00430777 1.766481  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [10.416077  9.420054]\n",
      "Val   Loss (log-MSE): 0.013223 | Val   RMSE [μa, μs′]: [0.00250208 1.3921064 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [11.522774   5.7793217]\n",
      "\n",
      "Epoch 34/800\n",
      "Train Loss (log-MSE): 0.027416 | Train RMSE [μa, μs′]: [0.00432436 2.2605906 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [15.054763 10.868069]\n",
      "Val   Loss (log-MSE): 0.033453 | Val   RMSE [μa, μs′]: [0.00465652 1.420088  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [19.15692   9.705401]\n",
      "\n",
      "Epoch 35/800\n",
      "Train Loss (log-MSE): 0.030653 | Train RMSE [μa, μs′]: [0.00636703 2.2511032 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [17.41864  11.127361]\n",
      "Val   Loss (log-MSE): 0.007097 | Val   RMSE [μa, μs′]: [0.00218144 1.3658015 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [5.0360713 9.080116 ]\n",
      "\n",
      "Epoch 36/800\n",
      "Train Loss (log-MSE): 0.022619 | Train RMSE [μa, μs′]: [0.00366818 2.026127  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [12.094068 10.96447 ]\n",
      "Val   Loss (log-MSE): 0.003636 | Val   RMSE [μa, μs′]: [0.00137952 0.9562278 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [4.0641875 5.351482 ]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 37/800\n",
      "Train Loss (log-MSE): 0.018512 | Train RMSE [μa, μs′]: [0.00457502 1.9556808 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [11.4620495  9.855456 ]\n",
      "Val   Loss (log-MSE): 0.003607 | Val   RMSE [μa, μs′]: [0.00185235 0.95877886]\n",
      "Val   Mean Abs %Err [μa, μs′]: [5.1389813 4.5585093]\n",
      "\n",
      "Epoch 38/800\n",
      "Train Loss (log-MSE): 0.010305 | Train RMSE [μa, μs′]: [0.00279212 1.4601125 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [7.777345 7.550145]\n",
      "Val   Loss (log-MSE): 0.006004 | Val   RMSE [μa, μs′]: [0.00487375 1.2766467 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [8.161312 4.855777]\n",
      "\n",
      "Epoch 39/800\n",
      "Train Loss (log-MSE): 0.013821 | Train RMSE [μa, μs′]: [0.00372666 1.9336282 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [9.250276 9.72085 ]\n",
      "Val   Loss (log-MSE): 0.022022 | Val   RMSE [μa, μs′]: [0.00407524 2.948621  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 8.770095 16.092024]\n",
      "\n",
      "Epoch 40/800\n",
      "Train Loss (log-MSE): 0.016775 | Train RMSE [μa, μs′]: [0.00467246 2.108446  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [10.314655 11.218512]\n",
      "Val   Loss (log-MSE): 0.007003 | Val   RMSE [μa, μs′]: [0.00201936 2.0003917 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [4.134877 8.469693]\n",
      "\n",
      "Epoch 41/800\n",
      "Train Loss (log-MSE): 0.023203 | Train RMSE [μa, μs′]: [0.00508462 3.03518   ]\n",
      "Train Mean Abs %Err [μa, μs′]: [11.496079 14.062427]\n",
      "Val   Loss (log-MSE): 0.006018 | Val   RMSE [μa, μs′]: [0.00283486 1.2267991 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [6.52776  6.574542]\n",
      "\n",
      "Epoch 42/800\n",
      "Train Loss (log-MSE): 0.014861 | Train RMSE [μa, μs′]: [0.00503367 1.7824339 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [10.701988  8.653969]\n",
      "Val   Loss (log-MSE): 0.012581 | Val   RMSE [μa, μs′]: [1.3948346e-03 2.1577094e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 7.237856 10.819666]\n",
      "\n",
      "Epoch 43/800\n",
      "Train Loss (log-MSE): 0.018511 | Train RMSE [μa, μs′]: [0.00451218 2.0932891 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [11.158831 11.110305]\n",
      "Val   Loss (log-MSE): 0.011292 | Val   RMSE [μa, μs′]: [0.00316714 1.6177965 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 6.8553443 12.020434 ]\n",
      "\n",
      "Epoch 44/800\n",
      "Train Loss (log-MSE): 0.014786 | Train RMSE [μa, μs′]: [0.00417599 1.8555866 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [10.311171  8.99946 ]\n",
      "Val   Loss (log-MSE): 0.006132 | Val   RMSE [μa, μs′]: [0.00334   1.7257763]\n",
      "Val   Mean Abs %Err [μa, μs′]: [5.0672255 7.4187036]\n",
      "\n",
      "Epoch 45/800\n",
      "Train Loss (log-MSE): 0.019731 | Train RMSE [μa, μs′]: [0.00472726 1.8364341 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.004553  9.604962]\n",
      "Val   Loss (log-MSE): 0.018266 | Val   RMSE [μa, μs′]: [0.00368008 2.0254872 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [14.669211  9.604961]\n",
      "\n",
      "Epoch 46/800\n",
      "Train Loss (log-MSE): 0.018527 | Train RMSE [μa, μs′]: [0.00370415 2.3172834 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [10.660044 10.483728]\n",
      "Val   Loss (log-MSE): 0.010656 | Val   RMSE [μa, μs′]: [0.00215278 1.5137529 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [9.603961 4.958888]\n",
      "\n",
      "Epoch 47/800\n",
      "Train Loss (log-MSE): 0.014620 | Train RMSE [μa, μs′]: [0.0041831 2.184348 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [9.923456 9.601641]\n",
      "Val   Loss (log-MSE): 0.009768 | Val   RMSE [μa, μs′]: [0.00523058 1.3924068 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [11.333623  6.645709]\n",
      "\n",
      "Epoch 48/800\n",
      "Train Loss (log-MSE): 0.022018 | Train RMSE [μa, μs′]: [0.00522882 1.9758022 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.756618  9.868358]\n",
      "Val   Loss (log-MSE): 0.009755 | Val   RMSE [μa, μs′]: [0.00338345 1.1164181 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [10.55133    5.1288133]\n",
      "\n",
      "Epoch 49/800\n",
      "Train Loss (log-MSE): 0.034268 | Train RMSE [μa, μs′]: [0.00626842 2.486342  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [17.763418 11.926255]\n",
      "Val   Loss (log-MSE): 0.005100 | Val   RMSE [μa, μs′]: [0.00200126 1.4576209 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [5.25305  6.131012]\n",
      "\n",
      "Epoch 50/800\n",
      "Train Loss (log-MSE): 0.007159 | Train RMSE [μa, μs′]: [0.00381126 1.5675322 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [6.717567 6.47946 ]\n",
      "Val   Loss (log-MSE): 0.003485 | Val   RMSE [μa, μs′]: [0.00151091 0.9113574 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [4.697565  4.9840283]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 51/800\n",
      "Train Loss (log-MSE): 0.018641 | Train RMSE [μa, μs′]: [0.00463538 2.0876174 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [11.304173 10.374323]\n",
      "Val   Loss (log-MSE): 0.024346 | Val   RMSE [μa, μs′]: [0.00695263 1.839889  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [19.640686  9.408536]\n",
      "\n",
      "Epoch 52/800\n",
      "Train Loss (log-MSE): 0.021931 | Train RMSE [μa, μs′]: [0.00560593 2.246332  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.907535 11.104402]\n",
      "Val   Loss (log-MSE): 0.017315 | Val   RMSE [μa, μs′]: [0.00361112 2.1906505 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [13.182034  7.279743]\n",
      "\n",
      "Epoch 53/800\n",
      "Train Loss (log-MSE): 0.012884 | Train RMSE [μa, μs′]: [0.0030638 1.9844743]\n",
      "Train Mean Abs %Err [μa, μs′]: [8.695068 9.18385 ]\n",
      "Val   Loss (log-MSE): 0.014747 | Val   RMSE [μa, μs′]: [0.0049166 1.2721413]\n",
      "Val   Mean Abs %Err [μa, μs′]: [15.5971985  5.299547 ]\n",
      "\n",
      "Epoch 54/800\n",
      "Train Loss (log-MSE): 0.011421 | Train RMSE [μa, μs′]: [0.00393081 1.504841  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [9.845277 7.581392]\n",
      "Val   Loss (log-MSE): 0.003407 | Val   RMSE [μa, μs′]: [0.00144055 1.0033851 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [4.7484455 4.382952 ]\n",
      "\n",
      "Epoch 55/800\n",
      "Train Loss (log-MSE): 0.008185 | Train RMSE [μa, μs′]: [0.00278781 1.5952905 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [6.840687 7.354183]\n",
      "Val   Loss (log-MSE): 0.014791 | Val   RMSE [μa, μs′]: [0.00526325 1.0168635 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [16.00263    5.2433553]\n",
      "\n",
      "Epoch 56/800\n",
      "Train Loss (log-MSE): 0.012249 | Train RMSE [μa, μs′]: [0.00500507 1.3277264 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [11.05137   7.126934]\n",
      "Val   Loss (log-MSE): 0.009003 | Val   RMSE [μa, μs′]: [1.4787207e-03 1.9075830e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [7.7207384 6.395396 ]\n",
      "\n",
      "Epoch 57/800\n",
      "Train Loss (log-MSE): 0.007206 | Train RMSE [μa, μs′]: [0.00322748 1.3187715 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [7.431869 6.043093]\n",
      "Val   Loss (log-MSE): 0.007899 | Val   RMSE [μa, μs′]: [0.00400114 1.145737  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [10.607765  5.038477]\n",
      "\n",
      "Epoch 58/800\n",
      "Train Loss (log-MSE): 0.008264 | Train RMSE [μa, μs′]: [0.00270076 1.1786675 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [7.847549 5.741591]\n",
      "Val   Loss (log-MSE): 0.009912 | Val   RMSE [μa, μs′]: [0.00228882 1.9238936 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [8.524955 6.557321]\n",
      "\n",
      "Epoch 59/800\n",
      "Train Loss (log-MSE): 0.021650 | Train RMSE [μa, μs′]: [0.00497238 2.5022097 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [9.103442 9.129307]\n",
      "Val   Loss (log-MSE): 0.083769 | Val   RMSE [μa, μs′]: [0.00754573 3.8103938 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [37.764915 18.26089 ]\n",
      "\n",
      "Epoch 60/800\n",
      "Train Loss (log-MSE): 0.055324 | Train RMSE [μa, μs′]: [0.007632 3.71072 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [22.898989 16.895885]\n",
      "Val   Loss (log-MSE): 0.024154 | Val   RMSE [μa, μs′]: [0.0067433 1.7263339]\n",
      "Val   Mean Abs %Err [μa, μs′]: [16.084913  7.457297]\n",
      "\n",
      "Epoch 61/800\n",
      "Train Loss (log-MSE): 0.033556 | Train RMSE [μa, μs′]: [0.00597835 2.765757  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [15.045889 13.110382]\n",
      "Val   Loss (log-MSE): 0.010592 | Val   RMSE [μa, μs′]: [0.00224943 1.7329326 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [9.603307 6.103466]\n",
      "\n",
      "Epoch 62/800\n",
      "Train Loss (log-MSE): 0.025312 | Train RMSE [μa, μs′]: [0.00782256 1.9570154 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [14.854199  10.3706045]\n",
      "Val   Loss (log-MSE): 0.019127 | Val   RMSE [μa, μs′]: [2.4606648e-03 3.0899348e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 6.690657 11.29769 ]\n",
      "\n",
      "Epoch 63/800\n",
      "Train Loss (log-MSE): 0.030403 | Train RMSE [μa, μs′]: [0.00784546 3.0390265 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [14.825488 14.293858]\n",
      "Val   Loss (log-MSE): 0.034404 | Val   RMSE [μa, μs′]: [0.00553328 4.2253895 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 7.9746075 16.192245 ]\n",
      "\n",
      "Epoch 64/800\n",
      "Train Loss (log-MSE): 0.017128 | Train RMSE [μa, μs′]: [0.0036507 2.3608122]\n",
      "Train Mean Abs %Err [μa, μs′]: [ 7.575723 13.016275]\n",
      "Val   Loss (log-MSE): 0.010292 | Val   RMSE [μa, μs′]: [0.0029661 1.9755101]\n",
      "Val   Mean Abs %Err [μa, μs′]: [5.5721703 9.463166 ]\n",
      "\n",
      "Epoch 65/800\n",
      "Train Loss (log-MSE): 0.014643 | Train RMSE [μa, μs′]: [0.00385897 2.3529975 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [ 9.006447  10.2912855]\n",
      "Val   Loss (log-MSE): 0.007023 | Val   RMSE [μa, μs′]: [0.0026374 1.8220544]\n",
      "Val   Mean Abs %Err [μa, μs′]: [4.633338 8.541492]\n",
      "\n",
      "Epoch 66/800\n",
      "Train Loss (log-MSE): 0.017560 | Train RMSE [μa, μs′]: [0.00479246 1.9541587 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [11.365386  9.298749]\n",
      "Val   Loss (log-MSE): 0.015750 | Val   RMSE [μa, μs′]: [0.00676744 2.2650528 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [13.6905155  9.2038145]\n",
      "\n",
      "Epoch 67/800\n",
      "Train Loss (log-MSE): 0.018161 | Train RMSE [μa, μs′]: [0.00779661 1.7607183 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.6080265  8.496668 ]\n",
      "Val   Loss (log-MSE): 0.005627 | Val   RMSE [μa, μs′]: [0.00253983 1.61124   ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [7.359671  4.2013273]\n",
      "\n",
      "Epoch 68/800\n",
      "Train Loss (log-MSE): 0.008922 | Train RMSE [μa, μs′]: [0.00312897 1.5460067 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [7.267918 7.842488]\n",
      "Val   Loss (log-MSE): 0.007786 | Val   RMSE [μa, μs′]: [0.00274946 1.3854085 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [9.339341 5.363828]\n",
      "\n",
      "Epoch 69/800\n",
      "Train Loss (log-MSE): 0.011327 | Train RMSE [μa, μs′]: [0.00290571 1.6087946 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [7.9369073 7.7155943]\n",
      "Val   Loss (log-MSE): 0.008369 | Val   RMSE [μa, μs′]: [0.00254813 1.2400382 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [7.8100657 7.653545 ]\n",
      "\n",
      "Epoch 70/800\n",
      "Train Loss (log-MSE): 0.011949 | Train RMSE [μa, μs′]: [0.0037368 1.7860944]\n",
      "Train Mean Abs %Err [μa, μs′]: [9.388566  8.3700485]\n",
      "Val   Loss (log-MSE): 0.006426 | Val   RMSE [μa, μs′]: [0.00277237 1.1049496 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [8.085974 5.52652 ]\n",
      "\n",
      "Early stopping at epoch 70: no val improvement for 20 epochs.\n",
      "Saved loss curves to: /Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/CNN_initial_saved_pytorch_model_weights/best_baseline_no_dilation_loss_curves.png\n",
      "Post-train RMSE train [mua, mus]: [0.00360516 0.98652   ]\n",
      "Post-train RMSE val   [mua, mus]: [0.00277237 1.1049496 ]\n",
      "One-batch shapes:\n",
      "  signals: torch.Size([32, 8, 3000])\n",
      "  labels : torch.Size([32, 2])\n",
      "  output : torch.Size([32, 2])\n",
      "\n",
      "======================================================================\n",
      "EXPERIMENT: dilated_1_2_4\n",
      "use_dilation=True | kernels=[3, 5, 5] | dilations=[1, 2, 4]\n",
      "======================================================================\n",
      "Pre-train RMSE train [mua, mus]: [ 1.116818 13.678109]\n",
      "Pre-train RMSE val   [mua, mus]: [ 1.1342984 13.611255 ]\n",
      "\n",
      "Epoch 1/800\n",
      "Train Loss (log-MSE): 2.705375 | Train RMSE [μa, μs′]: [ 0.35097373 10.496552  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [1257.6941    88.53112]\n",
      "Val   Loss (log-MSE): 4.748733 | Val   RMSE [μa, μs′]: [ 0.28105825 12.714069  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [1513.9728    67.01501]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 2/800\n",
      "Train Loss (log-MSE): 0.260740 | Train RMSE [μa, μs′]: [0.01516023 9.240215  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [43.753574 45.996754]\n",
      "Val   Loss (log-MSE): 0.875995 | Val   RMSE [μa, μs′]: [0.0731135 8.759527 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [211.56618   40.997646]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 3/800\n",
      "Train Loss (log-MSE): 0.144511 | Train RMSE [μa, μs′]: [0.01515653 5.1362534 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [35.14891  28.417212]\n",
      "Val   Loss (log-MSE): 0.275150 | Val   RMSE [μa, μs′]: [0.03125442 6.5849557 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [74.27259  34.460533]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 4/800\n",
      "Train Loss (log-MSE): 0.153717 | Train RMSE [μa, μs′]: [0.01638961 3.8724267 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [43.55069  22.405846]\n",
      "Val   Loss (log-MSE): 0.156786 | Val   RMSE [μa, μs′]: [0.02145041 3.3665502 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [68.26467  13.334477]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 5/800\n",
      "Train Loss (log-MSE): 0.130759 | Train RMSE [μa, μs′]: [0.01400992 2.6864305 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [44.960648 13.715455]\n",
      "Val   Loss (log-MSE): 0.027707 | Val   RMSE [μa, μs′]: [0.00649214 1.7513465 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [17.435223  8.409785]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 6/800\n",
      "Train Loss (log-MSE): 0.062628 | Train RMSE [μa, μs′]: [0.01091259 2.5523548 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [21.560898 14.64563 ]\n",
      "Val   Loss (log-MSE): 0.019605 | Val   RMSE [μa, μs′]: [0.00637633 1.651955  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [10.723318  9.353203]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 7/800\n",
      "Train Loss (log-MSE): 0.046840 | Train RMSE [μa, μs′]: [0.008625  3.1239166]\n",
      "Train Mean Abs %Err [μa, μs′]: [20.011543 14.323418]\n",
      "Val   Loss (log-MSE): 0.020059 | Val   RMSE [μa, μs′]: [0.00647051 2.0360608 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [13.564491 10.014956]\n",
      "\n",
      "Epoch 8/800\n",
      "Train Loss (log-MSE): 0.049494 | Train RMSE [μa, μs′]: [0.0109874 2.4603608]\n",
      "Train Mean Abs %Err [μa, μs′]: [23.900747 11.464755]\n",
      "Val   Loss (log-MSE): 0.022098 | Val   RMSE [μa, μs′]: [0.00714238 2.2868724 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [15.626449 10.654219]\n",
      "\n",
      "Epoch 9/800\n",
      "Train Loss (log-MSE): 0.045037 | Train RMSE [μa, μs′]: [0.00694504 2.5474489 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [18.848003 13.80989 ]\n",
      "Val   Loss (log-MSE): 0.010826 | Val   RMSE [μa, μs′]: [0.00608323 1.7112354 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [10.76153    6.5055885]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 10/800\n",
      "Train Loss (log-MSE): 0.038681 | Train RMSE [μa, μs′]: [0.00649129 2.0785437 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [19.005455 11.357862]\n",
      "Val   Loss (log-MSE): 0.021550 | Val   RMSE [μa, μs′]: [0.00454023 1.953905  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [14.122799 10.139012]\n",
      "\n",
      "Epoch 11/800\n",
      "Train Loss (log-MSE): 0.044886 | Train RMSE [μa, μs′]: [0.00900136 2.3114603 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [21.431223 11.384164]\n",
      "Val   Loss (log-MSE): 0.061999 | Val   RMSE [μa, μs′]: [0.01588401 3.3094835 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [36.33501  11.573126]\n",
      "\n",
      "Epoch 12/800\n",
      "Train Loss (log-MSE): 0.052748 | Train RMSE [μa, μs′]: [0.01256739 2.5563745 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [25.629524 12.573943]\n",
      "Val   Loss (log-MSE): 0.011560 | Val   RMSE [μa, μs′]: [0.00565804 1.7169976 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [9.387605  7.8609486]\n",
      "\n",
      "Epoch 13/800\n",
      "Train Loss (log-MSE): 0.032262 | Train RMSE [μa, μs′]: [0.00797354 2.2885902 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [15.766531 11.244755]\n",
      "Val   Loss (log-MSE): 0.025823 | Val   RMSE [μa, μs′]: [0.00613319 3.2528896 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [15.6853075 11.92105  ]\n",
      "\n",
      "Epoch 14/800\n",
      "Train Loss (log-MSE): 0.034396 | Train RMSE [μa, μs′]: [0.00723722 2.204177  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [17.826927 12.833274]\n",
      "Val   Loss (log-MSE): 0.014965 | Val   RMSE [μa, μs′]: [0.00337262 3.2125604 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 6.84223  10.839067]\n",
      "\n",
      "Epoch 15/800\n",
      "Train Loss (log-MSE): 0.068403 | Train RMSE [μa, μs′]: [0.01129647 3.049435  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [26.66878  16.829039]\n",
      "Val   Loss (log-MSE): 0.031648 | Val   RMSE [μa, μs′]: [0.00630103 1.4849522 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [19.359343   7.9994435]\n",
      "\n",
      "Epoch 16/800\n",
      "Train Loss (log-MSE): 0.043757 | Train RMSE [μa, μs′]: [0.00701348 2.784051  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [18.074736 14.092568]\n",
      "Val   Loss (log-MSE): 0.012082 | Val   RMSE [μa, μs′]: [1.8272403e-03 2.0717423e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [9.224383 8.50086 ]\n",
      "\n",
      "Epoch 17/800\n",
      "Train Loss (log-MSE): 0.037425 | Train RMSE [μa, μs′]: [0.00622896 2.4043133 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [18.504244 11.267505]\n",
      "Val   Loss (log-MSE): 0.047498 | Val   RMSE [μa, μs′]: [3.3090611e-03 4.1255174e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [18.901796 17.507784]\n",
      "\n",
      "Epoch 18/800\n",
      "Train Loss (log-MSE): 0.026882 | Train RMSE [μa, μs′]: [0.0062754 1.9885035]\n",
      "Train Mean Abs %Err [μa, μs′]: [15.013764  11.0055275]\n",
      "Val   Loss (log-MSE): 0.012113 | Val   RMSE [μa, μs′]: [0.00429053 1.4788744 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [11.204299   6.9258785]\n",
      "\n",
      "Epoch 19/800\n",
      "Train Loss (log-MSE): 0.017661 | Train RMSE [μa, μs′]: [0.00563264 2.0336235 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [11.586376  8.771886]\n",
      "Val   Loss (log-MSE): 0.019919 | Val   RMSE [μa, μs′]: [0.00630246 2.0880382 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [17.79369   7.614752]\n",
      "\n",
      "Epoch 20/800\n",
      "Train Loss (log-MSE): 0.024010 | Train RMSE [μa, μs′]: [0.00789245 1.6710656 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [17.833649  8.155525]\n",
      "Val   Loss (log-MSE): 0.010555 | Val   RMSE [μa, μs′]: [1.4668327e-03 2.6547112e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 4.950782 10.228909]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 21/800\n",
      "Train Loss (log-MSE): 0.027381 | Train RMSE [μa, μs′]: [0.00655922 2.3270354 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.895991 11.884015]\n",
      "Val   Loss (log-MSE): 0.014284 | Val   RMSE [μa, μs′]: [0.00321105 1.8579533 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [13.859985   6.4297194]\n",
      "\n",
      "Epoch 22/800\n",
      "Train Loss (log-MSE): 0.076435 | Train RMSE [μa, μs′]: [0.0117054 2.6480565]\n",
      "Train Mean Abs %Err [μa, μs′]: [31.031061 14.051702]\n",
      "Val   Loss (log-MSE): 0.036402 | Val   RMSE [μa, μs′]: [0.00837712 3.155739  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [19.371147 16.89755 ]\n",
      "\n",
      "Epoch 23/800\n",
      "Train Loss (log-MSE): 0.058543 | Train RMSE [μa, μs′]: [0.00797294 2.939373  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [23.573895 14.636127]\n",
      "Val   Loss (log-MSE): 0.066652 | Val   RMSE [μa, μs′]: [0.00556202 2.0384037 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [25.957502 10.590662]\n",
      "\n",
      "Epoch 24/800\n",
      "Train Loss (log-MSE): 0.068636 | Train RMSE [μa, μs′]: [0.01131704 4.045857  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [25.463364 14.898259]\n",
      "Val   Loss (log-MSE): 0.182737 | Val   RMSE [μa, μs′]: [0.02265918 6.1084814 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [60.69123  26.075035]\n",
      "\n",
      "Epoch 25/800\n",
      "Train Loss (log-MSE): 0.149196 | Train RMSE [μa, μs′]: [0.02049215 4.5461607 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [46.435772 21.31596 ]\n",
      "Val   Loss (log-MSE): 0.045584 | Val   RMSE [μa, μs′]: [0.01009227 1.7502936 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [31.56163  9.07742]\n",
      "\n",
      "Epoch 26/800\n",
      "Train Loss (log-MSE): 0.048564 | Train RMSE [μa, μs′]: [0.00708973 2.03352   ]\n",
      "Train Mean Abs %Err [μa, μs′]: [22.551907 11.227775]\n",
      "Val   Loss (log-MSE): 0.063584 | Val   RMSE [μa, μs′]: [0.00585583 1.7295088 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [24.380215 11.123086]\n",
      "\n",
      "Epoch 27/800\n",
      "Train Loss (log-MSE): 0.040317 | Train RMSE [μa, μs′]: [0.00780812 1.8110316 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [20.785112  8.795896]\n",
      "Val   Loss (log-MSE): 0.051763 | Val   RMSE [μa, μs′]: [0.0143349  0.97634655]\n",
      "Val   Mean Abs %Err [μa, μs′]: [36.715042  4.489673]\n",
      "\n",
      "Epoch 28/800\n",
      "Train Loss (log-MSE): 0.022458 | Train RMSE [μa, μs′]: [0.00609943 2.4780653 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.991817 10.809595]\n",
      "Val   Loss (log-MSE): 0.009173 | Val   RMSE [μa, μs′]: [0.00278212 1.57676   ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [8.171895  7.0623336]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 29/800\n",
      "Train Loss (log-MSE): 0.027451 | Train RMSE [μa, μs′]: [0.00812028 2.3568273 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [16.74616   9.517425]\n",
      "Val   Loss (log-MSE): 0.010277 | Val   RMSE [μa, μs′]: [0.00342315 1.8911808 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [8.9257555 7.8305793]\n",
      "\n",
      "Epoch 30/800\n",
      "Train Loss (log-MSE): 0.018710 | Train RMSE [μa, μs′]: [0.00696784 1.6736678 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.592051  7.409788]\n",
      "Val   Loss (log-MSE): 0.024214 | Val   RMSE [μa, μs′]: [0.00962071 2.4410195 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [20.78998    7.2783732]\n",
      "\n",
      "Epoch 31/800\n",
      "Train Loss (log-MSE): 0.010702 | Train RMSE [μa, μs′]: [0.0042287 1.7117418]\n",
      "Train Mean Abs %Err [μa, μs′]: [8.890004  7.6683397]\n",
      "Val   Loss (log-MSE): 0.013840 | Val   RMSE [μa, μs′]: [0.00463715 1.4844059 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [15.108729  5.850496]\n",
      "\n",
      "Epoch 32/800\n",
      "Train Loss (log-MSE): 0.024476 | Train RMSE [μa, μs′]: [0.00756337 2.0112765 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [14.630259  8.629462]\n",
      "Val   Loss (log-MSE): 0.025273 | Val   RMSE [μa, μs′]: [1.5280859e-03 4.1587763e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 5.9594097 14.636035 ]\n",
      "\n",
      "Epoch 33/800\n",
      "Train Loss (log-MSE): 0.021911 | Train RMSE [μa, μs′]: [0.00594875 1.6170142 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [15.714873   6.7909365]\n",
      "Val   Loss (log-MSE): 0.003128 | Val   RMSE [μa, μs′]: [1.3218379e-03 1.3474059e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [2.999725  5.0399737]\n",
      " -> Best validation so far, saved.\n",
      "\n",
      "Epoch 34/800\n",
      "Train Loss (log-MSE): 0.021915 | Train RMSE [μa, μs′]: [0.0055613 1.8602763]\n",
      "Train Mean Abs %Err [μa, μs′]: [14.441789  8.828984]\n",
      "Val   Loss (log-MSE): 0.013034 | Val   RMSE [μa, μs′]: [0.00599145 1.9484355 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [13.366962   6.7496953]\n",
      "\n",
      "Epoch 35/800\n",
      "Train Loss (log-MSE): 0.013827 | Train RMSE [μa, μs′]: [0.00520655 1.7131786 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [11.767971   7.1545343]\n",
      "Val   Loss (log-MSE): 0.009418 | Val   RMSE [μa, μs′]: [0.00535244 2.2865806 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [7.6090813 7.980517 ]\n",
      "\n",
      "Epoch 36/800\n",
      "Train Loss (log-MSE): 0.012239 | Train RMSE [μa, μs′]: [0.00419296 1.6824458 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [9.969101 6.912018]\n",
      "Val   Loss (log-MSE): 0.008020 | Val   RMSE [μa, μs′]: [0.00571979 1.496993  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [9.265854  5.9659796]\n",
      "\n",
      "Epoch 37/800\n",
      "Train Loss (log-MSE): 0.011063 | Train RMSE [μa, μs′]: [0.00417527 1.871758  ]\n",
      "Train Mean Abs %Err [μa, μs′]: [9.13284  8.001516]\n",
      "Val   Loss (log-MSE): 0.007438 | Val   RMSE [μa, μs′]: [1.1250871e-03 1.8888576e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [4.350344 8.980269]\n",
      "\n",
      "Epoch 38/800\n",
      "Train Loss (log-MSE): 0.012809 | Train RMSE [μa, μs′]: [0.00541829 1.9138666 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [9.335985 8.63396 ]\n",
      "Val   Loss (log-MSE): 0.057473 | Val   RMSE [μa, μs′]: [0.00615534 3.6441734 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [29.10259  14.968832]\n",
      "\n",
      "Epoch 39/800\n",
      "Train Loss (log-MSE): 0.012655 | Train RMSE [μa, μs′]: [0.00409041 1.5876575 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [10.23676    7.3685217]\n",
      "Val   Loss (log-MSE): 0.056114 | Val   RMSE [μa, μs′]: [0.00933874 3.9074173 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [29.138056 15.407804]\n",
      "\n",
      "Epoch 40/800\n",
      "Train Loss (log-MSE): 0.031011 | Train RMSE [μa, μs′]: [0.00621349 2.1653712 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [18.442646  9.000219]\n",
      "Val   Loss (log-MSE): 0.013738 | Val   RMSE [μa, μs′]: [1.3980503e-03 3.0599513e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 5.777664 10.475034]\n",
      "\n",
      "Epoch 41/800\n",
      "Train Loss (log-MSE): 0.022242 | Train RMSE [μa, μs′]: [0.00675035 1.3774447 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [15.754983  6.60774 ]\n",
      "Val   Loss (log-MSE): 0.041192 | Val   RMSE [μa, μs′]: [0.01119176 2.034182  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [29.633862  8.559089]\n",
      "\n",
      "Epoch 42/800\n",
      "Train Loss (log-MSE): 0.022880 | Train RMSE [μa, μs′]: [0.00648364 1.8834118 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [15.762891  8.296919]\n",
      "Val   Loss (log-MSE): 0.019631 | Val   RMSE [μa, μs′]: [0.00760127 2.8914309 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [13.851915 10.727186]\n",
      "\n",
      "Epoch 43/800\n",
      "Train Loss (log-MSE): 0.016504 | Train RMSE [μa, μs′]: [0.0061398 1.5208919]\n",
      "Train Mean Abs %Err [μa, μs′]: [13.754307   6.8941984]\n",
      "Val   Loss (log-MSE): 0.018652 | Val   RMSE [μa, μs′]: [0.00516397 1.4981078 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [18.15465    5.5167894]\n",
      "\n",
      "Epoch 44/800\n",
      "Train Loss (log-MSE): 0.014856 | Train RMSE [μa, μs′]: [0.00607745 1.6095474 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [12.348947  7.013246]\n",
      "Val   Loss (log-MSE): 0.014055 | Val   RMSE [μa, μs′]: [1.3042565e-03 3.3934033e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [4.914495 9.922536]\n",
      "\n",
      "Epoch 45/800\n",
      "Train Loss (log-MSE): 0.009773 | Train RMSE [μa, μs′]: [0.0042885 1.2783942]\n",
      "Train Mean Abs %Err [μa, μs′]: [8.498292  5.8133636]\n",
      "Val   Loss (log-MSE): 0.017653 | Val   RMSE [μa, μs′]: [0.00396399 1.247518  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [17.183823   5.9908814]\n",
      "\n",
      "Epoch 46/800\n",
      "Train Loss (log-MSE): 0.015191 | Train RMSE [μa, μs′]: [0.00466488 1.5192918 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [12.952476   6.0126796]\n",
      "Val   Loss (log-MSE): 0.007648 | Val   RMSE [μa, μs′]: [1.0314358e-03 2.5211740e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [3.5116632 7.6717625]\n",
      "\n",
      "Epoch 47/800\n",
      "Train Loss (log-MSE): 0.008407 | Train RMSE [μa, μs′]: [0.00441138 1.5332543 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [8.121573  6.2218494]\n",
      "Val   Loss (log-MSE): 0.015996 | Val   RMSE [μa, μs′]: [0.00619999 2.133121  ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [16.016102  6.315048]\n",
      "\n",
      "Epoch 48/800\n",
      "Train Loss (log-MSE): 0.009974 | Train RMSE [μa, μs′]: [0.00474169 1.4798167 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [8.9773855 6.72379  ]\n",
      "Val   Loss (log-MSE): 0.014655 | Val   RMSE [μa, μs′]: [1.7294482e-03 3.1256342e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [ 5.799062 12.606041]\n",
      "\n",
      "Epoch 49/800\n",
      "Train Loss (log-MSE): 0.007920 | Train RMSE [μa, μs′]: [0.00409617 1.2945229 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [8.181081 6.255267]\n",
      "Val   Loss (log-MSE): 0.003466 | Val   RMSE [μa, μs′]: [0.00242587 1.2311745 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [3.9015787 5.632509 ]\n",
      "\n",
      "Epoch 50/800\n",
      "Train Loss (log-MSE): 0.011491 | Train RMSE [μa, μs′]: [0.00565873 1.3107796 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [10.963552   5.8092003]\n",
      "Val   Loss (log-MSE): 0.007231 | Val   RMSE [μa, μs′]: [1.4540765e-03 2.2898281e+00]\n",
      "Val   Mean Abs %Err [μa, μs′]: [3.7173607 8.513267 ]\n",
      "\n",
      "Epoch 51/800\n",
      "Train Loss (log-MSE): 0.016276 | Train RMSE [μa, μs′]: [0.00405906 1.3265793 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [12.963295   6.8002167]\n",
      "Val   Loss (log-MSE): 0.007484 | Val   RMSE [μa, μs′]: [0.00305882 1.6615857 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [7.3371363 5.3031483]\n",
      "\n",
      "Epoch 52/800\n",
      "Train Loss (log-MSE): 0.015359 | Train RMSE [μa, μs′]: [0.00502775 1.6010741 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [11.690407  7.797221]\n",
      "Val   Loss (log-MSE): 0.035162 | Val   RMSE [μa, μs′]: [0.01161493 1.2343408 ]\n",
      "Val   Mean Abs %Err [μa, μs′]: [28.894356   5.3695726]\n",
      "\n",
      "Epoch 53/800\n",
      "Train Loss (log-MSE): 0.019336 | Train RMSE [μa, μs′]: [0.00529138 1.5480309 ]\n",
      "Train Mean Abs %Err [μa, μs′]: [14.36669   7.380923]\n",
      "Val   Loss (log-MSE): 0.017553 | Val   RMSE [μa, μs′]: [0.0032245 2.7109766]\n",
      "Val   Mean Abs %Err [μa, μs′]: [11.464236 11.437409]\n",
      "\n",
      "Early stopping at epoch 53: no val improvement for 20 epochs.\n",
      "Saved loss curves to: /Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/CNN_initial_saved_pytorch_model_weights/best_dilated_1_2_4_loss_curves.png\n",
      "Post-train RMSE train [mua, mus]: [0.00299546 2.596363  ]\n",
      "Post-train RMSE val   [mua, mus]: [0.0032245 2.7109766]\n",
      "One-batch shapes:\n",
      "  signals: torch.Size([32, 8, 3000])\n",
      "  labels : torch.Size([32, 2])\n",
      "  output : torch.Size([32, 2])\n",
      "\n",
      "======================================================================\n",
      "SUMMARY (Post-train RMSE)\n",
      "======================================================================\n",
      "Baseline RMSE val [mua, mus]: [0.00277237 1.1049496 ]\n",
      "Dilated  RMSE val [mua, mus]: [0.0032245 2.7109766]\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# RUN SCRIPT (baseline vs dilated) + auto epoch scheduling + early stopping\n",
    "# ============================\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def make_train_val_loaders(dataset, batch_size=32, val_frac=0.2, seed=42):\n",
    "    n = len(dataset)\n",
    "    idx = np.arange(n)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(idx)\n",
    "\n",
    "    split = int(n * (1 - val_frac))\n",
    "    train_idx = idx[:split]\n",
    "    val_idx = idx[split:]\n",
    "\n",
    "    train_ds = Subset(dataset, train_idx)\n",
    "    val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def quick_eval_lin_rmse(model, loader, device, eps=1e-12, exp_clip=20.0):\n",
    "    \"\"\"Compute RMSE in original units (model outputs log-space).\"\"\"\n",
    "    model.eval()\n",
    "    sum_sq = torch.zeros(2, device=device)\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).float()\n",
    "            ylog = torch.log(y.clamp_min(eps))\n",
    "            plog = model(x).view_as(ylog)\n",
    "            plin = torch.exp(plog.clamp(-exp_clip, exp_clip))\n",
    "            err = plin - y\n",
    "            sum_sq += (err ** 2).sum(dim=0)\n",
    "            n += y.shape[0]\n",
    "    return torch.sqrt(sum_sq / max(1, n)).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Paths + base config\n",
    "# ----------------------------\n",
    "mat_path = r\"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/Pre-obtained data/dataset_homo_small.mat\"\n",
    "\n",
    "base_cfg = {\n",
    "    \"crop_t_max\": 6.0,\n",
    "    \"sg_window\": 31,\n",
    "    \"sg_order\": 1,\n",
    "    \"eps\": 1e-12,\n",
    "    \"channel_mode\": \"hybrid_4ch\",\n",
    "    \"input_rep\": \"raw_log\",\n",
    "\n",
    "    # ---- DILATION EXPERIMENT DEFAULTS (OFF unless enabled below) ----\n",
    "    \"use_dilation\": False,\n",
    "    \"kernels\": [3, 5, 5],      # increasing kernels, smaller final kernel\n",
    "    \"dilations\": [1, 2, 4],    # increasing dilation (only used if use_dilation=True)\n",
    "    \"channels\": [32, 32, 16],\n",
    "    \"pool_k\": 2,\n",
    "    \"pool_s\": 2,\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Device\n",
    "# ----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Dataset + split (DO THIS ONCE so both models share identical split)\n",
    "# ----------------------------\n",
    "dataset = DTOFDataset(mat_path, base_cfg)\n",
    "\n",
    "batch_size = 32\n",
    "val_frac = 0.2\n",
    "seed = 42\n",
    "\n",
    "train_loader, val_loader = make_train_val_loaders(dataset, batch_size=batch_size, val_frac=val_frac, seed=seed)\n",
    "\n",
    "N_total = len(dataset)\n",
    "N_train = len(train_loader.dataset)\n",
    "N_val = len(val_loader.dataset)\n",
    "\n",
    "print(\"Total samples:\", N_total)\n",
    "print(\"Train samples:\", N_train)\n",
    "print(\"Val samples  :\", N_val)\n",
    "print(\"Signal shape :\", dataset[0][0].shape, \"Label shape:\", dataset[0][1].shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Epoch scheduling (scaled by dataset size via target optimiser steps)\n",
    "# ----------------------------\n",
    "target_steps = 50_000  # adjust later\n",
    "steps_per_epoch = math.ceil(N_train / batch_size)\n",
    "num_epochs = math.ceil(target_steps / steps_per_epoch)\n",
    "\n",
    "# Optional cap (if you want a hard max like 800)\n",
    "num_epochs = min(num_epochs, 800)\n",
    "\n",
    "print(f\"steps_per_epoch: {steps_per_epoch}\")\n",
    "print(f\"target_steps   : {target_steps}\")\n",
    "print(f\"num_epochs     : {num_epochs}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Run function (so we can compare baseline vs dilated cleanly)\n",
    "# ----------------------------\n",
    "def run_experiment(cfg, tag):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"EXPERIMENT: {tag}\")\n",
    "    print(f\"use_dilation={cfg.get('use_dilation', False)} | kernels={cfg.get('kernels')} | dilations={cfg.get('dilations')}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    model = Net(cfg, input_length=dataset.T, output_dim=2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Pre-train sanity RMSE\n",
    "    rmse0_train = quick_eval_lin_rmse(model, train_loader, device, eps=cfg[\"eps\"])\n",
    "    rmse0_val = quick_eval_lin_rmse(model, val_loader, device, eps=cfg[\"eps\"])\n",
    "    print(\"Pre-train RMSE train [mua, mus]:\", rmse0_train)\n",
    "    print(\"Pre-train RMSE val   [mua, mus]:\", rmse0_val)\n",
    "\n",
    "    save_path = f\"/Users/lydialichen/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Year 3/Research Project in Biomedical Engineering/Code/CNN_initial_saved_pytorch_model_weights/best_{tag}.pt\"\n",
    "\n",
    "    plot_path = save_path.replace(\".pt\", \"_loss_curves.png\")\n",
    "\n",
    "    train_out = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device,\n",
    "        save_path=save_path,\n",
    "        plot_path=plot_path,     \n",
    "        eps=cfg[\"eps\"],\n",
    "        print_every=1,\n",
    "        patience=20,\n",
    "        min_delta=1e-4,\n",
    "    )\n",
    "\n",
    "    print(\"Saved loss curves to:\", train_out[\"loss_plot\"])\n",
    "\n",
    "    # Post-train RMSE\n",
    "    rmse1_train = quick_eval_lin_rmse(model, train_loader, device, eps=cfg[\"eps\"])\n",
    "    rmse1_val = quick_eval_lin_rmse(model, val_loader, device, eps=cfg[\"eps\"])\n",
    "    print(\"Post-train RMSE train [mua, mus]:\", rmse1_train)\n",
    "    print(\"Post-train RMSE val   [mua, mus]:\", rmse1_val)\n",
    "\n",
    "    # One-batch forward shape check\n",
    "    signals, labels = next(iter(train_loader))\n",
    "    out = model(signals.to(device))\n",
    "    print(\"One-batch shapes:\")\n",
    "    print(\"  signals:\", signals.shape)\n",
    "    print(\"  labels :\", labels.shape)\n",
    "    print(\"  output :\", out.shape)\n",
    "\n",
    "    return {\n",
    "        \"tag\": tag,\n",
    "        \"rmse_train\": rmse1_train,\n",
    "        \"rmse_val\": rmse1_val,\n",
    "        \"save_path\": save_path,\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Baseline vs Dilated configs\n",
    "# ----------------------------\n",
    "cfg_baseline = dict(base_cfg)\n",
    "cfg_baseline[\"use_dilation\"] = False\n",
    "\n",
    "cfg_dilated = dict(base_cfg)\n",
    "cfg_dilated[\"use_dilation\"] = True\n",
    "# kernels/dilations already present in base_cfg; tweak here if desired:\n",
    "# cfg_dilated[\"kernels\"] = [3, 5, 5]\n",
    "# cfg_dilated[\"dilations\"] = [1, 2, 4]\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Run both experiments\n",
    "# ----------------------------\n",
    "res_base = run_experiment(cfg_baseline, tag=\"baseline_no_dilation\")\n",
    "res_dil  = run_experiment(cfg_dilated,  tag=\"dilated_1_2_4\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY (Post-train RMSE)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Baseline RMSE val [mua, mus]:\", res_base[\"rmse_val\"])\n",
    "print(\"Dilated  RMSE val [mua, mus]:\", res_dil[\"rmse_val\"])\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
